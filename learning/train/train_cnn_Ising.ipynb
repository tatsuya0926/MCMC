{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12a1d0b30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import create_param_list, create_train_data_hold_out, create_train_data_CV, inference\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ数:30690\n"
     ]
    }
   ],
   "source": [
    "nconf = 31\n",
    "ndata = 990\n",
    "L = 64\n",
    "T_cr = 2.269  # critical temp for 2d ising\n",
    "t_start = 2.1\n",
    "exclude_T = (2.23, 2.28)\n",
    "\n",
    "prm_list, t_end = create_param_list(nconf=nconf, t_start=t_start, L=L, model_name=\"2d_Ising\")\n",
    "# print(prm_list)\n",
    "print(f\"データ数:{nconf*ndata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApsAAAInCAYAAADXmpJqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPDElEQVR4nO3dfXRcVb3/8U/SNNPSNpM+2KS1j4sHCxal9JnipdAsey8soVpBvXB5uCy5YIqUoEL9CQhLSZSLdOEFKlxsvVeliFeeFcTQVoHS0mDVWgyweGgFklIlSXlo0jb790fNkGlmkjkzZ5+zz5n3a61h0ZmTc/Y+Z38nO/t79j4lxhgjAAAAwILSsAsAAACA+KKzCQAAAGvobAIAAMAaOpsAAACwhs4mAAAArKGzCQAAAGvobAIAAMAaOpsAAACwhs4mAAAArKGzCQAAAGvKwi4AAG/WrFmjV199VQsXLtTChQvDLg4y2Lp1q+6//35VVlZq+fLlYRfHuj/+8Y966KGH9Nvf/lbbtm3TW2+9pUQiocmTJ+uUU07RsmXLdNRRR+W9/1dffVVPPvmkmpqa9Nxzz+n3v/+99uzZI0l65ZVXNGXKFJ9qAsCGEp6NDkTLwoULtWHDBl177bX65je/GXZxkMGaNWt0wQUXaPLkyXr11VfDLo5VP/nJT3TOOeekvZdMJvXOO+/owIEDkqTy8nLdcsst+o//+I+8jnH++efrRz/6UcbP6GwC7iONDgDI2759+5RIJHTOOefokUceUXt7u9ra2vTee+/pN7/5jaZPn66uri5dcskl+s1vfpPXMUpLS3X44YfrrLPOUkNDg+rr632uBQCbSKMDAPI2f/58vfzyyxo/fnza++Xl5Vq0aJF+97vf6eijj1ZLS4saGhpUU1Pj+Rh33nmnBg0alPr3+vXrCy02gAAxsglExJo1a1RSUqINGzZIkq677jqVlJSkvQ5N2T711FM655xzNHnyZA0ZMkTJZFJz5szRd77zHb3zzjsZj3P++eerpKRE559/fuq48+fPVzKZ1MiRI1VTU6Pf/va3qe3379+v73//+5o5c6YqKiqUTCZ16qmn6rnnnsu4//Xr16fKK0lbtmzRZz/7WY0bN05DhgzREUccoa9+9atqa2vr93x0dXXptttu08knn6wxY8aovLxc1dXVOuOMM/SrX/0q68/1HHv9+vXatWuX6urqdNRRR+mwww5LlUmS3nvvPd19990699xzddxxx+lDH/qQEomExo8fryVLlmQ9RklJiS644AJJ0muvvdbnGvW+9WHhwoV93jvUN7/5TZWUlGS8P7f3z+/bt0833XSTZs2apcrKylQde9u2bZsuuugiHXnkkTrssMM0fPhwfexjH9P/+3//T7t3785ahv585CMf6dPR7K2yslKf+cxnJEnPPvtsXsfo3dEEEEEGQCSsXbvWVFVVmcGDBxtJZtiwYaaqqirttWPHDmOMMQcOHDBf/vKXjaTUa/jw4WbQoEGpf3/kIx8xr776ap/jnHfeeUaSOe+881L/X1ZWZkaMGJH62bKyMvPQQw+ZvXv3mk9+8pNGkikvLzfDhg1LbXPYYYeZLVu29Nn/unXrUtvcf//9pry83EgyFRUVqf+XZCZPnmxeeeWVjOfi1VdfNR/96EdT25aUlJhkMplW34svvjjjz/Z8fuedd5qqqiojyQwZMiRVvx6rV6/us//DDjss7RhXXHFFn/1XVVWZiooKI8mUlpb2uUY33nhjatuTTjrJSDLXXntt1ut+7bXXGknmpJNO6vNZz89feeWV5oQTTkhdm5EjR5qSkhKzbt261Lbf+c53TGlpadr16X2+x40bZ5577rmMZZg8eXLWMuSirq4u1Wb90LsNZWsjANxBZxOImFw6KN/4xjeMJDN27Fhz6623mr/97W/GGGO6urrMunXrzIwZM4wkc/zxx5sDBw6k/WxPB7OystIMHTrU/OAHPzDvvfeeMcaYv/zlL2bmzJlGkpkyZYpZtmyZGTVqlPnZz35murq6THd3t9myZYs5/PDDjSSzYMGCPmXr3VFIJpNm4cKFZvv27cYYY/bt22fuueceM3LkSCPJzJ492+zfvz/t59955x0zbdo0I8ksXLjQrF+/3uzdu9cYY0xbW5v53ve+Z4YPH24kmZUrV/Y5fu/O90c+8hHT2NiYOgfNzc2p7e6//37zla98xTz55JPm3XffTb3/xhtvmOuuuy7V6X/ggQf6HKOnozp58uSs18gY/zqbw4cPN8OHDzerV69OXavdu3enrvt///d/p7b79re/bd58801jjDH79+83W7ZsMaeccoqRZCZMmGD27NnT5ziFdjaPP/54I8nMmzcvr58/FJ1NIFrobAIRM1AH5ZVXXjGDBg0yQ4cONVu3bs24TUdHh5kwYYKRZO677760z3o6m5LMj3/84z4/+9JLL6WN7v3ud7/rs01jY2Pq8507d6Z91rujcNRRR6U6R709/vjjqW1+9rOfpX12/fXXpzo+XV1dGev3i1/8wkgyY8aMMfv27Uv7rGe/FRUVfcrmxY033mgkmUWLFvX5LOjOpiTz4IMPZvz5jo4OU1lZaSSZRx99NOM2+/btS/0RcfPNN/f5vJDO5tq1a1NlvOuuuzz/fCZ0NoFo4Z5NIGbWrFmjAwcO6J//+Z/18Y9/POM2I0aM0JIlSyRJjz32WMZtJk2apH/913/t8/7hhx+uI444QpL0iU98QieeeGKfbU466SQlEglJB9dgzOarX/2qhg4d2uf9mpoanXDCCZKktWvXpn121113SZLq6uo0ePDgjPtdsmSJKioqtHv3bjU1NWXc5t/+7d80YcKErGUbyGmnnSZJ2rhxY2qJn7B89KMf1ac+9amMn/3f//2f2traNGPGDC1evDjjNmVlZfrCF74gKXN7ePXVV2WM8Twx54UXXtDFF18sSTrxxBNT9wEDKC7MRgdi5qmnnpIk/frXv1Z1dXXW7XomCL322msZP581a1bahJneqqqq9NJLL2n27NkZPx80aJDGjBmj119/XW+//XbWMpxyyin9fvb0009ry5Ytqfdef/31VHkvvPDCfieO9K7f3Llz+3y+YMGCrD/bo7W1Vbfddpt+/etf64UXXlB7e3ufjuV7772nt99+W2PGjBlwf7b0V5ee9vD888/32x7ef/99Sdnbg1ctLS067bTT1NbWpvHjx+vuu+9WaSnjG0AxorMJxMwbb7whSXr33Xf17rvvDrj9e++9l/H9ESNGZP2ZsrKynLfZt29f1m0+/OEPD/jZrl27Uu/11E1SzrOns9Vv7Nix/f7cxo0bdeqpp6bNih8+fHhq1vqBAwdSZXj33XdD7Wz2V5eec7Z3717t3bt3wH1lO19e7Nq1S4sWLdJLL72kqqoqNTY2FjSKDCDa+DMTiJmekbcrr7xS5uB92f2+orRmYe9Rxeeffz6n+mVL3fY3Krp//3594QtfUFtbm4477jj98pe/VEdHh/bs2aPW1la1tLTomWeeSW1vQn4QW3916Tlnn/vc53I6X4U+8WjXrl065ZRTtH37do0dO1ZPPPGEpk2bVtA+AUQbnU0gZnpSpX6lQ216/fXXB/ys96hd7zSwzfpt3LhRr732mgYNGqSHH35Y//Iv/9JnFLelpaXg4/SM/vY34tje3l7QMYJsD7t27dLJJ5+sP//5z6mO5jHHHGP9uADcRmcTiJie+96yjab13L/3m9/8Jqe0aZjWrVs34GezZs1KvTdlypRUev2hhx6yVq6dO3dKkj70oQ9lTfX39+jFga5Rj5EjR6YdL5NNmzb1u4+B9LSHpqYmvfnmmwXtqz+tra06+eST00Y0P/rRj1o7HoDooLMJRExFRYUkZX3Czr//+7+rrKxMu3fv1rXXXtvvvrq6urI+SSgI//mf/5mxQ7xu3brUxJbPfe5zaZ998YtflHRwVvrvf//7fvf/97//Pa9yJZNJSQc7UK2trX0+/+tf/6pbbrkl688PdI169KwW8Nhjj2W8v/aJJ57Qxo0bcy12RmeeeaYqKyu1b98+1dXV9dsB7u7uHrDMmfROnVdVVWndunV0NAGk0NkEImb69OmSpF/+8pcZ09CHH364rr76aknSd7/7XZ177rnatm1b6vP9+/dr69atuv7663XEEUdo69atgZQ7kzfffFOnnXaampubU2X7+c9/rs9+9rOSpOOPPz71qMMeV1xxhY499ljt3btXJ598sv7rv/5Lf/vb31Kft7W16Ve/+pXOPfdcfeITn8irXCeeeKKGDRsmY4zOOussvfDCC5IO3v/42GOPpR4TmU3PNero6NDPfvazrNudddZZKi0t1d/+9jd94Qtf0F//+ldJB2eG/+hHP9KnP/1pjRo1Kq869KisrNTKlSslHVxG6rTTTtOmTZvU3d0t6WAH8/nnn9dNN92kj370o3r44Yf77GPKlClZH5n51ltvpTqa1dXVWrdunefUec/5nDJlSsbP9+3bp927d6devW8tePvtt9M+629CGoCQWF/JE4CvXnjhBTNkyJC0xyFOnjzZTJ48ObVIeXd3t7n66qtNSUlJavHroUOHmtGjR6c9slKSefLJJ9P23/txldnkshh5z0Lgq1evTnv/0MdV9jyJJ5lMmkQikfps0qRJ5uWXX86479dff93Mmzcv7XGSlZWVqcdE9ryOOOKIPj/b81nvRzlmcvvtt6fta/jw4anzPmbMGPPggw/2u7D4okWLUp+PGDEidY0OXTT9mmuuSTtOMpk0ZWVlRpJZsmRJ6mlQ/S3q3t916F2f3o+nTCQSZvTo0anz3/PKtJB/f4u6X3fddamfzfQI1WyPVM1Uj2yL4PduMwO9BrquAILHyCYQMUceeaTWrVun008/XR/60If0t7/9Ta+99ppee+017d+/X5JUUlKi66+/Xn/84x/1pS99SUcffbQGDRqk9vZ2jRw5UieccIK++tWv6umnn85pvUlbzjjjDD399NNaunSphgwZImOMpk6dqiuuuEJbt27V1KlTM/7c+PHj9eSTT+ruu+/W6aefrnHjxum9995TV1eXpkyZok996lNauXKlfvvb3+ZdtosvvliPPPKIFi5cqOHDh2v//v368Ic/rEsvvVR/+MMfdOyxx/b78z//+c91+eWX66ijjtK+fftS1+jQNPV1112n//3f/9W8efM0bNgwHThwQMcdd5xWrVqlX/ziF/3ONPdan+bmZn3lK1/Rxz/+cSUSCbW1tWn48OGaNWuWLr30Uj3++OOpxd1z1TNCKh1cAqrn1oNsr7AXwAcQvBJjQl6zA0BRWb9+vU4++WRJ4S8ZBACwj5FNAAAAWENnEwAAANbQ2QQAAIA1dDYBAABgDROEAAAAYA0jmwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACssdbZvPXWWzVlyhQNGTJEc+fO1ebNm20dCihqxBpgH3EG5K/EGGP83uk999yjc889V6tWrdLcuXO1cuVK3XvvvWpubtbYsWP7/dnu7m698cYbGjFihEpKSvwuGhAaY4z27Nmj8ePHq7TUn7/ziDWgL79jrZA4k4g1xJOnODMWzJkzx9TW1qb+feDAATN+/HhTX1/fZ9u9e/ea9vb21Gv79u1GEi9esX3t3LmTWOPFK4CXX7HmJc6INV7F9solzsrks66uLjU1NWnFihWp90pLS1VTU6ONGzf22b6+vl7XXXddn/cvl5Twu3CApAZd1e/nV6nBynE7Jd0sacSIEb7sL+hY633esp2jXLYB/JQ5ng9Gmx+x5jXOJH6vFaNi/O7z8jvN987m7t27deDAAVVVVaW9X1VVpb/85S99tl+xYoXq6upS/+7o6NDEiROVEEEZput0ber/r1XfL82w5VK+3tt4Ybvd+ZVGCzrWrs3hCzSXbYpNTzt0MY5sCP6744PW23O8TkkN8ifWvMaZxO+1YuTid19QsZhLnPne2fQqkUgokSD8ANuINSAYxBqQzvfZ6GPGjNGgQYPU2tqa9n5ra6uqq6v9PhxQtIg1wD7iDCic7yOb5eXlmjlzphobG7VkyRJJB2fiNTY2atmyZX4fLtbCTGW7nvLzWj6/6+MlRW/rXBJr0eB6LAXB5neZ7fNLnBXOj+tvsw1l+z6PU+yGXUcrafS6ujqdd955mjVrlubMmaOVK1fq3Xff1QUXXGDjcEDRItYA+4gzoDBWOpuf+9zn9NZbb+maa65RS0uLjjvuOD366KN9brAGUBhiDbCPOAMKY2VR90J0dHQomUzqKvU/a6+YZ3j2KJa6uyi/me4H58i2t7eroqLC7yJ5lmusIbrCSF+6cItJz2x0Ys0NYadw/WCrz+HX7QGZypdLLBZyTC9xxrPRAQAAYE3oSx8NJEp/EQUxihBUvV1fZzNsmc7JQG2156/AqIpDm4hDHfKVb92L7TzBLtpTukKyBb1/tuf/vfaZgvpOZGQTAAAA1tDZBAAAgDXOp9GDHnL3+hjETMPYrvIyXO56XXpz5VYLrzdmR02U2kQ2XuoQh5R7GOX2couJV8U2MTQuonq9Mn0HhLHeZxwwsgkAAABr6GwCAADAGufT6EHLJXUeBj+G66OayhhI2LPsMonrubYlDilrZOfXNS3GtkFsuMuPNWj9WFuzEEG1KUY2AQAAYA2dTQAAAFhTdGn0oGaS5btv0iT+yTY7nHPsHheviV9lGugxci7W3fXyxV0xn39XVhexccwo3s7lV1tkZBMAAADW0NkEAACANSXGGBN2IXrr6OhQMpnUVZISYRcmZMWcSomjnmejt7e3q6KiIuziRDrW/J7ViXDY+o4j1mCL1xngYa5wY/s70UucMbIJAAAAa+hsAgAAwBrnZ6O7nkq2Wb4wnwsfZjmATAZKO/kVi6Tog8N5hWuitFB6lDCyCQAAAGvobAIAAMAa59Porg9Hu14+L+JUl0MFtZh/JnE+r7mK0jlyqSxxlC0WuY3HfZkeUFDMcmm/XvaRjZd9u3ptGNkEAACANc6us6l/rEjmai8d3rg+0SsIxbz2X5jXn7Z3UDGdh2KONRQmSlmYsLHOJgAAAJxAZxMAAADWOD9BCHYEvZZgMaQeBr6JuyfpEC1+TAoohuvvoiAeiVeIXMpH27GHSVl95Vv3MG5TidKtMYxsAgAAwBo6mwAAALCGNHqRilKqwA9B3DYw0P6imUR38zp7aYfZPo9qW/bC9XplW6fQ9XIXE65LbsI+N66vgcrIJgAAAKyhswkAAABrSKPDE1eH6AcS1XIXC6+pOi/XM9u+aRPh8DoDmjRu4aIaA1z7/kXpnDCyCQAAAGvobAIAAMAaZ5+NHvdnyJIe6Cvu54TnNWfn0uLSrs/qxMCIteDE/Xsb2fFsdAAAADiBziYAAACsYTZ6HvxIG8Q53ZBvGjLO5yRqgk6NuXTtXSoLgnkgQ9QFFa+Zvtu5FsgFI5sAAACwhs4mAAAArCGNnoeoLj4cVDrKxbrDG64hXDFQW3T9e7e3hn/MR/fjoQTZVnDId39+be8CG6tb5Pv7M4rnLxcH69UzH31gjGwCAADAGkY2feT6Xy2ul88LP/5adGltR0RHXEcqoiqO1yCXNuZllLOQNhvF8+tSmV0qSz78+r5jZBMAAADW0NkEAACANUXxuErSpdEWxccHZko98Ag9IBiuxprymCCUTS4ThKL0nem6gX4PhXF7Tdi39PC4SgAAADjBU2ezvr5es2fP1ogRIzR27FgtWbJEzc3Nadvs3btXtbW1Gj16tIYPH66lS5eqtbXV10IDcUesAcEg1gD7PM1G37Bhg2prazV79mzt379fX//61/XJT35S27dv17BhwyRJl19+uR555BHde++9SiaTWrZsmT7zmc/oqaeeslKBYhb2EHrQtyeEXd8ghR1rYZ7rYrrOCF+QsXaVGjzfskI8uGGgcx/Gtcl0TFfbi6fO5qOPPpr27zVr1mjs2LFqamrSP/3TP6m9vV133XWXfvrTn+qUU06RJK1evVpHH320nnnmGc2bN6/PPjs7O9XZ2Zn6d0dHRz71AGKFWAOCQawB9hV0z2Z7e7skadSoUZKkpqYm7du3TzU1Naltpk2bpkmTJmnjxo0Z91FfX69kMpl6TZw4sZAiAbFErAHBINYA/+W9qHt3d7eWL1+uBQsWaPr06ZKklpYWlZeXq7KyMm3bqqoqtbS0ZNzPihUrVFdXl/p3R0eHp8DM95FdcRD2EHnYx3eZn+cmjFgL89rGbSZnFFdTyMbVFJ1fwv69lqmt5LKoO8LhYjy4Uo5D5d3ZrK2t1bZt2/Tkk08WVIBEIqFEgoVXgGyINSAYxBpgR15p9GXLlunhhx/WunXrNGHChNT71dXV6urqUltbW9r2ra2tqq6uLqigQDEi1oBgEGuAPZ5GNo0xuvTSS3Xfffdp/fr1mjp1atrnM2fO1ODBg9XY2KilS5dKkpqbm7Vjxw7Nnz/fv1L34uqQMfzj9zWOQlrTxVjLxsVUUi6CKmuUzkkxcinWaCvRwvXKnafOZm1trX7605/qgQce0IgRI1L3qySTSQ0dOlTJZFIXXnih6urqNGrUKFVUVOjSSy/V/PnzM87YA5AZsQYEg1gD7PPU2bz99tslSQsXLkx7f/Xq1Tr//PMlSTfffLNKS0u1dOlSdXZ2avHixbrtttt8KSxQLIg1IBjEGmCf889Gj1KKLoiyxvk571G61vlw9XnNPBvdH3GOzagh1uyK23d1LvXJ9/aruJ2r3ng2OgAAAJxAZxMAAADW5L3OZlDiNuzsxUAL1tuapW1j37ko5mtd7MJuezZliuOw6xjn8w37XGozQbXlfPft0rkKEyObAAAAsMbZkc2GDLdSu/4XQtDlY3TCDr/P6wf767mdOlr8Hpnz8ki+qIpbfbwYKH743ooWL9cr27b5XnPXRy39lsvjt10pq1eMbAIAAMAaOpsAAACwxtk0+lVqiMV6ZLmIW1op6AkRfp8/v8vas79oJtHtnY+4caWN55KKs2mg8sX1+gchjN8VXo6Tbdt8U+oDrXkZZ9nOWVQxsgkAAABr6GwCAADAGmfT6MUqzOFyv9IypMniz8vj3frbJor8mDHq9dGWfqQyw/xuiWtbCJofM7x7C+MRqy7e6uQ3v297cb2+uWBkEwAAANbQ2QQAAIA1sUqjR3U4Ot+0l4t1QXHw2vbilEb1I5Vp81GzuRwn6GsQt0fruiDMdHQxnv9MD6PIpljOiReMbAIAAMAaOpsAAACwJlZpdH+fYx3+UHjYx8/ElfMTh0VuXdGgqyQlnGxvXkR1Zq0fii21N/CtR1F9hEI0RKkthfG94Lowfo8zsgkAAABr6GwCAADAmlil0b2Keio221B4UEPkYabUizkF4rer1KBEAT/vyq0VvblSDuTOj3bU83Mk0dHD9YeV+LXfTP0ZV1ajkBjZBAAAgEV0NgEAAGBNUafRSbXlJpd0fabtOb/FwZVUDe2tf2He7pDLsbl+8eLi7TVx1nOOXb09kJFNAAAAWFNijDFhF6K3jo4OJZPJf6z8B8RHz6SF9vZ2VVRUhF2cSMSaK2vkuVKOQsRhpCnXR/gSa97FoX3ESRSuh5c4Y2QTAAAA1tDZBAAAgDVFPUHIiygMaQNR5epN7T3iEPNxqENcuPj7xEs5XCx/3MTtvDKyCQAAAGvobAIAAMCaSKXReTxivEU1NcO6ogPz81GEceNiu3exTJJbZSlEtnpE5bskqPKF0Q5dbftRx8gmAAAArKGzCQAAAGsilUZnSNu7gR416VJqIt/ZkPnuwy9xbJd+p5K87COO5zMqXF8VIO5cbPtBpJWzHSOq3+e5xJGL19omRjYBAABgDZ1NAAAAWBOpNHqU5PoMX9v8Tlkzk7g4xHW1B2aa9o9zEk+FtHs/br8qtrgrhjp6xcgmAAAArKGzCQAAAGtIo1vm93B6GOmIfFMmNstHmsJ9rtxKEvYxB+JimXorthSoawo5/36vLuD3bVSZykd7C4/Nc8/IJgAAAKyhswkAAABrSKNHTC5D22GnIVxPfUTl+cNBc2Wh/LDbL9JxDcJVyPkPetURF/lVLxcfhOI3m8dhZBMAAADW0NkEAACANSXGGBN2IXrr6OhQMpnUVZISYRcG8FGnpAZJ7e3tqqioCLs4gcaa6yk6L+Vz5XYDZFfMseaFK8/w9nvGPbEYDC9xVtDIZkNDg0pKSrR8+fLUe3v37lVtba1Gjx6t4cOHa+nSpWptbS3kMEDRI9YA+4gzwI68Jwg9++yz+sEPfqCPfexjae9ffvnleuSRR3TvvfcqmUxq2bJl+sxnPqOnnnqq4MLCXa6PXEVZHGLN9UlGPIYVcYizQmR6LOWh/+9ie3elTPmep6hOYPIqr5HNd955R2effbbuvPNOjRw5MvV+e3u77rrrLn3ve9/TKaecopkzZ2r16tV6+umn9cwzz2TcV2dnpzo6OtJeAA4i1gD7/IwziVgDDpVXZ7O2tlannXaaampq0t5vamrSvn370t6fNm2aJk2apI0bN2bcV319vZLJZOo1ceLEfIoExBKxBtjnZ5xJxBpwKM9p9LVr1+q5557Ts88+2+ezlpYWlZeXq7KyMu39qqoqtbS0ZNzfihUrVFdXl/p3R0eHp8B0fYi/WHDu/edarAFx5HecSW7HWrbfmWFOfIvS74+wHwHq9/GD4qmzuXPnTl122WV6/PHHNWTIEF8KkEgklEi4ND8PCB+xBthnI84kYg04lKc0elNTk3bt2qXjjz9eZWVlKisr04YNG3TLLbeorKxMVVVV6urqUltbW9rPtba2qrq62s9yA7FGrAH2EWdAMDyNbC5atEh/+tOf0t674IILNG3aNF155ZWaOHGiBg8erMbGRi1dulSS1NzcrB07dmj+/Pn+lVoDDyWzFh6C5uctHS7FWhTZjPO4fYcU861IQcdZwz9W2gzzPGc7drFd+7gJZ8WPnpU2B+apszlixAhNnz497b1hw4Zp9OjRqfcvvPBC1dXVadSoUaqoqNCll16q+fPna968eV4OBRQ1Yg2wjzgDgpH3OpvZ3HzzzSotLdXSpUvV2dmpxYsX67bbbvP7MEDRI9YA+4gzoHCRf1yl15lZpAqiYaDrGsXryCP04oFbdNxHrB3k+kLfUefHLShRvo0lsMdVAgAAAP2hswkAAABrnE2jy4FZe8XApSH8MFPnNlOjH+z7YNKh2FN7trjUluMkl1uVXDvfpNEB+0ijAwAAwAl0NgEAAGCN70sfIVpcS3+FJZdnBHsR1efXRllQt1kUQ8yEXd+wj1/sOP9uicP1YGQTAAAA1tDZBAAAgDXOz0bvLVOqM6pDyjgoijNd88UMWfQoJC2WKWbiEiN+Idaigd/j0cZsdAAAADjB2QlCV6mBvwDzlG3UxMWbjF0pR28unqc48WM0I8xr5MexCykzbRJBsjmSTlsuHoxsAgAAwBo6mwAAALDG2TT6QLwMv9tMubmecs02AYcbs9OxLmZwMrU5r48LDbPd2vwOCeP4AHAov/sIjGwCAADAGjqbAAAAsMbZdTZ71iOL+qxT5CeO1521/7Irtljz+7aNYjhn2WQ+lwejjVjry+9Y83oLDOKDdTYBAADgBDqbAAAAsMbZ2egNDiQcSAOEJ56zjXuSDgDywaoRhfP7+43fk30V221BuWBkEwAAANbQ2QQAAIA1zqbRg342uiuLnDP87h3nLPqK7br1rm9QqeF8Zw3bnG3sNXZzPSY3rMQDM90PisPvOEY2AQAAYA2dTQAAAFgT2UXd/U57u74/F8VhaN8PuV5rFnUvTl6+C/xIqbNQN7GGeHE1HlnUHQAAAE6gswkAAABrnJ2N3iOoYWJbx4lzqjlu9QG8yiW+g4gT1xfqjvP3oMuK4XauMLmU3nb9WjOyCQAAAGucH9nMxtXe+6GiUk58wNbaf4gfL9fexuhe0G0v3zoQI+HgvGfnRzx6/bmBjum1TFHKGDCyCQAAAGvobAIAAMAa59fZxEGu3/yLgbH2H3pEKf0VRcRadkG1PVfaeC5r18Y1Bm1fA9bZBAAAgBPobAIAAMCayM5GLzYDDYG7krLwS9zqA/QW5jp8uSDm4ivTY58Pfd/v4yAcQV3rXDCyCQAAAGvobAIAAMCaSM1Gz5QGKmRR1UL246ewh7dtiVu9Cm07rs6Q1T+iLVvKpUccrqGLXIqTuKx64Wqs2ZqN7uLvNfQvDrHGbHQAAAA4gc4mAAAArInUbPQ4zZbzO3XmUiquhyvlKISL59VvV6mhT2ovrnX1g99twqVz7VJZ0Fccvo9s1iFOt/8EfZ5sHKc3RjYBAABgDZ1NAAAAWFN0s9GjLg5plCjx83wX2wxZIJMgvsOKLdb4veCd13MWh9njfrM6G/3111/XOeeco9GjR2vo0KE69thjtWXLltTnxhhdc801GjdunIYOHaqamhq9+OKLXg8DFD1iDQgGsQbY5amz+fbbb2vBggUaPHiwfvWrX2n79u266aabNHLkyNQ23/3ud3XLLbdo1apV2rRpk4YNG6bFixdr7969vhceiCtiDQgGsQbY52k2+ne+8x1NnDhRq1evTr03derU1P8bY7Ry5Up94xvf0BlnnCFJ+p//+R9VVVXp/vvv1+c///k+++zs7FRnZ2fq3x0dHVmPz/A15yBMQaaqwo41oFjELda43Qwu8jSy+eCDD2rWrFk688wzNXbsWM2YMUN33nln6vNXXnlFLS0tqqmpSb2XTCY1d+5cbdy4MeM+6+vrlUwmU6+JEyfmWRUgPog1IBjEGmCfpwlCQ4YMkSTV1dXpzDPP1LPPPqvLLrtMq1at0nnnnaenn35aCxYs0BtvvKFx48alfu6ss85SSUmJ7rnnnj77zPQX4MSJE1M3UnPjs7vyvTbFek293EwdZKxlelyli3gkX/SENanC1VgLejKerfNfrN/hSOclzjyl0bu7uzVr1izdcMMNkqQZM2Zo27ZtqaDMRyKRUCLBXFigN2INCAaxBtjnKY0+btw4HXPMMWnvHX300dqxY4ckqbq6WpLU2tqatk1ra2vqMwADI9aAYBBrgH2eRjYXLFig5ubmtPdeeOEFTZ48WdLBm6qrq6vV2Nio4447TtLB9MGmTZt0ySWX5FXA3kP0mYbu810rq7/jIDcuPmYzLumdIGMt0+MqXef6tXVlkkbY8eD6dZLC+b0WFFvnPwrXtViFHfPZeOpsXn755TrhhBN0ww036KyzztLmzZt1xx136I477pAklZSUaPny5frWt76lI488UlOnTtXVV1+t8ePHa8mSJTbKD8QSsQYEg1gD7PPU2Zw9e7buu+8+rVixQtdff72mTp2qlStX6uyzz05t87WvfU3vvvuuLrroIrW1tenEE0/Uo48+mroJG8DAiDUgGMQaYF+kHlcJ+CEKM2SDELVYczU9FEdRP9fEGmCf1cdVAgAAALnylEYPQs9Aa+cA2wH56+z136CP+kEbD1v0Yq0zw//Bjmifa2INsM9LnDmXRv/rX//K0xYQazt37tSECRPCLgaxhtgj1gD7cokz5zqb3d3deuONN2SM0aRJk7Rz504n7rmxoeepEtQx2nKtozFGe/bs0fjx41VaGv4dLMRavFDHD7gYa83NzTrmmGO4PhFHHT/gJc6cS6OXlpZqwoQJ6ujokCRVVFTE9oL2oI7xkEsdk8lkQKUZGLEWT9TxINdi7cMf/rAkrk9cUMeDco2z8P/kAwAAQGzR2QQAAIA1znY2E4mErr32WiUS8V2VjDrGQ9TrGPXy54I6xkOU6xjlsueKOsaDjTo6N0EIAAAA8eHsyCYAAACij84mAAAArKGzCQAAAGvobAIAAMAaOpsAAACwxsnO5q233qopU6ZoyJAhmjt3rjZv3hx2kfJWX1+v2bNna8SIERo7dqyWLFmi5ubmtG327t2r2tpajR49WsOHD9fSpUvV2toaUokL19DQoJKSEi1fvjz1Xhzq+Prrr+ucc87R6NGjNXToUB177LHasmVL6nNjjK655hqNGzdOQ4cOVU1NjV588cUQSzwwYi167bA3Yo1YC0OxxVpc40wKMNaMY9auXWvKy8vND3/4Q/PnP//ZfPGLXzSVlZWmtbU17KLlZfHixWb16tVm27ZtZuvWrebUU081kyZNMu+8805qm4svvthMnDjRNDY2mi1btph58+aZE044IcRS52/z5s1mypQp5mMf+5i57LLLUu9HvY5///vfzeTJk835559vNm3aZF5++WXz2GOPmZdeeim1TUNDg0kmk+b+++83f/jDH8zpp59upk6dat5///0QS54dsRa9dtgbsUashaWYYi2ucWZMsLHmXGdzzpw5pra2NvXvAwcOmPHjx5v6+voQS+WfXbt2GUlmw4YNxhhj2trazODBg829996b2ub55583kszGjRvDKmZe9uzZY4488kjz+OOPm5NOOikVmHGo45VXXmlOPPHErJ93d3eb6upqc+ONN6bea2trM4lEwtx9991BFNEzYi167bAHsUasuSSusRbnODMm2FhzKo3e1dWlpqYm1dTUpN4rLS1VTU2NNm7cGGLJ/NPe3i5JGjVqlCSpqalJ+/btS6vztGnTNGnSpMjVuba2VqeddlpaXaR41PHBBx/UrFmzdOaZZ2rs2LGaMWOG7rzzztTnr7zyilpaWtLqmEwmNXfuXCfrSKwdFLV22INYI9ZcEtdYi3OcScHGmlOdzd27d+vAgQOqqqpKe7+qqkotLS0hlco/3d3dWr58uRYsWKDp06dLklpaWlReXq7Kysq0baNW57Vr1+q5555TfX19n8/iUMeXX35Zt99+u4488kg99thjuuSSS/TlL39ZP/rRjyQpVY+otF1i7QNRqzOxRqy5JK6xFvc4k4KNtTJ/ioxc1NbWatu2bXryySfDLoqvdu7cqcsuu0yPP/64hgwZEnZxrOju7tasWbN0ww03SJJmzJihbdu2adWqVTrvvPNCLh0ORaxFF7EWLXGMtWKIMynYWHNqZHPMmDEaNGhQnxldra2tqq6uDqlU/li2bJkefvhhrVu3ThMmTEi9X11dra6uLrW1taVtH6U6NzU1adeuXTr++ONVVlamsrIybdiwQbfccovKyspUVVUV+TqOGzdOxxxzTNp7Rx99tHbs2CFJqXpEpe0Sax+IUp2JNWLNJXGNtWKIMynYWHOqs1leXq6ZM2eqsbEx9V53d7caGxs1f/78EEuWP2OMli1bpvvuu09PPPGEpk6dmvb5zJkzNXjw4LQ6Nzc3a8eOHZGp86JFi/SnP/1JW7duTb1mzZqls88+O/X/Ua/jggUL+izt8cILL2jy5MmSpKlTp6q6ujqtjh0dHdq0aZOTdSTWDopaOyTWiDUXxD3WiiHOpIBjLb85TPasXbvWJBIJs2bNGrN9+3Zz0UUXmcrKStPS0hJ20fJyySWXmGQyadavX2/efPPN1Ou9995LbXPxxRebSZMmmSeeeMJs2bLFzJ8/38yfPz/EUheu98w9Y6Jfx82bN5uysjLz7W9/27z44ovmJz/5iTnssMPMj3/849Q2DQ0NprKy0jzwwAPmj3/8oznjjDOcX46FWItWO8yEWCPWglaMsRa3ODMm2FhzrrNpjDHf//73zaRJk0x5ebmZM2eOeeaZZ8IuUt4kZXytXr06tc37779vvvSlL5mRI0eaww47zHz60582b775ZniF9sGhgRmHOj700ENm+vTpJpFImGnTppk77rgj7fPu7m5z9dVXm6qqKpNIJMyiRYtMc3NzSKXNDbEWvXZ4KGKNWAtaMcZaHOPMmOBircQYYzyOvAIAAAA5ceqeTQAAAMQLnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGANnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGCNtc7mrbfeqilTpmjIkCGaO3euNm/ebOtQQFEj1gD7iDMgfyXGGOP3Tu+55x6de+65WrVqlebOnauVK1fq3nvvVXNzs8aOHdvvz3Z3d+uNN97QiBEjVFJS4nfRgNAYY7Rnzx6NHz9epaX+/J1HrAF9+R1rhcSZRKwhnjzFmbFgzpw5pra2NvXvAwcOmPHjx5v6+vo+2+7du9e0t7enXtu3bzeSePGK7Wvnzp3EGi9eAbz8ijUvcUas8Sq2Vy5xViafdXV1qampSStWrEi9V1paqpqaGm3cuLHP9vX19bruuuv6vH+5pEQB5WjQVRnfv0oNOf/cQNsWu6DPVbZrmgsXrmWnpJsljRgxwpf9uRJr2eQbg3HgJTb4zvGfn7HmNc6k7LHWE21c53RxjgEX65atTF7L6iXOfO9s7t69WwcOHFBVVVXa+1VVVfrLX/7SZ/sVK1aorq4u9e+Ojg5NnDhRCRX2C/DaPC9qvj9XjLycq+t0ba+fy/QlnNvP5stLW8p2vN7lzrRNrvXyK43mSqxlv7aJLO/7sW9/FXI9M/H2PZLI8H/wgx+x5jXOpOyxdpVu5hpnEOffu/nWzeZ3X7Yy5VvWXOLM986mV4lEQokE4QfYRqwBwSDWgHS+z0YfM2aMBg0apNbW1rT3W1tbVV1d7ffhgKJFrAH2EWdA4Xwf2SwvL9fMmTPV2NioJUuWSDo4E6+xsVHLli3z+3C+CyptZ1MuaWA/9u1lf4WlJK/rc+wwDHT8oNuOK7Fms65+79tLGyqkvQUVG5nYjP9i5EqcxVFPW6Vtxp+VNHpdXZ3OO+88zZo1S3PmzNHKlSv17rvv6oILLrBxOKBoEWuAfcQZUBgrnc3Pfe5zeuutt3TNNdeopaVFxx13nB599NE+N1gDKAyxBthHnAGFsbKoeyE6OjqUTCZ1lcKZmenXrOkw0wJ+p5vDTnH4UR8/ZkMXeoxOSQ2S2tvbVVFRkVd5/BR2rIXBZltyJf5BrIUlSjEQxkoXrp8Tr7zEGc9GBwAAgDWhL33kGj8mskSVX+X346bvgdY9DGqyUBjHhHtyacthTsArFkwoycyV9WijdF2CWvs3SufEJkY2AQAAYA2dTQAAAFgTqzR6Ma8vl2+K169Ut/+P0+p/f2Gn1HuLe3rd70c5umKg6xlGHeNwXm3i/GQW1Hnxcpy43hISp7oEiZFNAAAAWENnEwAAANY4u86m/rEi2UBD1l5TmAyBp4tDqiMqt0+4vvafn2uKBqmYZygHUfcofke4HmuIh6j87rGFdTYBAADgBDqbAAAAsMbZ2ehXqSGndIPrw9Vhp6AGOn4hj+QsZD9xFPa1LtRAM/xdrZPf5YpSWj6IMrJYPYBCMbIJAAAAa+hsAgAAwBpnZ6Mzaw9hySXll0+auZhnyJJGjR+b17TQ23WKOdZ6i9ItIYgeZqMDAADACXQ2AQAAYA1p9IghHRldpPYQV659L8Up1lw7twhGLg/ZCLs9kEYHAACAE+hsAgAAwBpnF3WPIi/pjnxTI2EPm+fClRmQrixA/0E5epIOQLyEHetxFudz68rvChflck6idIsFI5sAAACwJlYjm0H18rMdJ4gRSldG6/rjUlkysfUoxoHaRTGPa7ryF7gr5ShE0HWIwkSFKItDm4R3fvweilJ7YWQTAAAA1tDZBAAAgDWxSqMHNaQc5tB172Pnkt4qBrmkoaKUboA9cWgHQdchDucMbuKWmvAFdR4Y2QQAAIA1dDYBAABgTazS6MXG65B3saUNwkw3Ftu5HgjnIDuvbYW2FS9cw/CFscqLK9c9qHIwsgkAAABr6GwCAADAGtLo/XB9AXWv6TRXyu23uNYLxaGQ9hv04/7CSOHbeggD4oH2EZxC4p+RTQAAAFhDZxMAAADWkEbvh+tD8a6XDwd9kHoo5qejh4fZ2/7Jdv5snmOumTcutncvDyAJakUGV85Nb67fuldIORjZBAAAgDV0NgEAAGANafR/GGhGm+vD22HLN62R7ef8nmEYdGop0zFIohfGyzW0eb3DTlO6+J3jYpmKlSvPG/fCa5mLub2F/f2TL0Y2AQAAYA2dTQAAAFhDGr1AUR3S9pvfMwJzuYXBj+MgOnKZCR1mOcIQ9KLuwKFyiT8/bq2Kg4HqZnO1h7DPKyObAAAAsKboRja9jIL4PWIS9l8WYSrmumNghbSPnu2DHuEEwuTKdypZqNyFuSZo2OeVkU0AAABYQ2cTAAAA1sQ2jW5zvS8/9u1KCiQMXutebOenGMUhTRSGqE4WcK0cUeH6rSJ+p9QRH4xsAgAAwBpPnc36+nrNnj1bI0aM0NixY7VkyRI1NzenbbN3717V1tZq9OjRGj58uJYuXarW1lZfCw3EHbEGBINYA+zzlEbfsGGDamtrNXv2bO3fv19f//rX9clPflLbt2/XsGHDJEmXX365HnnkEd17771KJpNatmyZPvOZz+ipp56yUoFsvK7JF+YssaCEmbKK0nnyysZah1GKtWIW1TSwK+seunDOiDX/RDUeikHY18ZTZ/PRRx9N+/eaNWs0duxYNTU16Z/+6Z/U3t6uu+66Sz/96U91yimnSJJWr16to48+Ws8884zmzZvXZ5+dnZ3q7OxM/bujoyOfegCxQqwBwSDWAPsKumezvb1dkjRq1ChJUlNTk/bt26eamprUNtOmTdOkSZO0cePGjPuor69XMplMvSZOnFhIkYBYItaAYBBrgP/yno3e3d2t5cuXa8GCBZo+fbokqaWlReXl5aqsrEzbtqqqSi0tLRn3s2LFCtXV1aX+3dHRYTUwi3nWa1TLnUnYKYHebB8/qrHWm9/Xy6XrH0Vezl8xnd8wYi3TrV1RXaXDlTL5fbtcHIRd97w7m7W1tdq2bZuefPLJggqQSCSUSCQK2gcQZ8QaEAxiDbAjrzT6smXL9PDDD2vdunWaMGFC6v3q6mp1dXWpra0tbfvW1lZVV1cXVFCgGBFrQDCINcAeTyObxhhdeumluu+++7R+/XpNnTo17fOZM2dq8ODBamxs1NKlSyVJzc3N2rFjh+bPn+9fqSMq7NQfqczoiFusuT6LOd+2HNV270r857sPP797ohRrUW1vQeM89RX2rQWeOpu1tbX66U9/qgceeEAjRoxI3a+STCY1dOhQJZNJXXjhhaqrq9OoUaNUUVGhSy+9VPPnz884Yw9AZsQaEAxiDbDPU2fz9ttvlyQtXLgw7f3Vq1fr/PPPlyTdfPPNKi0t1dKlS9XZ2anFixfrtttu86WwQLEg1oBgEGuAfSXGGBN2IXrr6OhQMpnUVZK4vTr+iikV3ympQQeXVqmoqAi7OMQaJLkZg4WWiVgD0tlIo3uJM56NDgAAAGvobAIAAMCavNfZRDS4mCID/GTj2fTFJOiZ5LngWroj30Xn4ZawV6BgZBMAAADWMLIZQ9luBHZRlP5CDnudsmKUy1/Sttbc7L1frv1BXr9bghh1JntjV7Gd07i2Jz/qVcj5YGQTAAAA1tDZBAAAgDWRSqMzvJ2bXNJ/8E/u57hnVbLi5iW1GkacZzpmnL5v/OLK9wzXBocq5HdqXNtT2PViZBMAAADW0NkEAACANZFKoxcDm7cKsF5aYVxJG0adi+s6Ijf5xgDXDkEKu42F0d5dX2+YkU0AAABYQ2cTAAAA1kQqje7q8LCfgnrsW8+QO+mtvljAO3hhLN4OAJLdFWGCYuuYfp0bRjYBAABgDZ1NAAAAWBOpNHq+XE+LhlkOV86BS2wtNs6S7rnh1g4AcINf38GMbAIAAMAaOpsAAACwpijS6NlEKV3n94KtrtfXJtcXvy1Gcb4WUW9vPMAAUZFvrEU1NqOEkU0AAABYQ2cTAAAA1kQqjR7Ec8ODfo5prsdkmN+/68+5RJB62luUbtvxKm71gb+CavuZ9h3VuMu33K7Wl5FNAAAAWBOpkc18e/de5PJXgat/OcQd5xpRFtX2m8v3YJjfiXH6Po76ZLJsXFlLOk5tJRtX68XIJgAAAKyhswkAAABrIpVGD0JQQ9CuDnXDH8WQrnFFFFOPcWgf2dKTYZYj6uJUFxdF6fx6LWumGHSpvoxsAgAAwBo6mwAAALAmtmn0XGZQ5vN5f/uOojik81wU93NJu3GD3+nrfK9lvil12k5m2c4h5wvZuN42GNkEAACANXQ2AQAAYE1s0+i9hTlT0nWuD73DTS61G5fKkqswypxLqtuPmf2ZjhPUzPUP9t0pqcHacWyLYpuOmmK7ZS4XNme0M7IJAAAAa+hsAgAAwJpIpdHznQGb7zPVi20IvTdmQyLuXIn1oMrhJX3tV5ky/azNOvbsO9pJdAQhqJh35XsmbIxsAgAAwBo6mwAAALAmUmn0gWQbrvaSEi7mYe5swk43eJkhywzDYMThNosolbW3IFbX8OvcBP3c+rjMRi9EMadtg25vuXCpLAOxuWoEI5sAAACwhs4mAAAArCkxxpiwC9FbR0eHksmkrpKUCLswERWHFKcfXDsPPYm99vZ2VVRUhFKG3gqJNW5X8M6v9ljMadJcxSnW4B+vsUOs9c9LnDGyCQAAAGvobAIAAMCaWM1Gjyq/070M9x8U1POYkRkpqHR+nYN898P1QDHy67vfxZnuXoR9W1lBI5sNDQ0qKSnR8uXLU+/t3btXtbW1Gj16tIYPH66lS5eqtbW10HICRY1YA+wjzgA78p4g9Oyzz+qss85SRUWFTj75ZK1cuVKSdMkll+iRRx7RmjVrlEwmtWzZMpWWluqpp57Kab/cSI24ynfSguux5veIWdh/gYcp7EdXxuXRvvnEmq04k9z9vRbXWPM6mpmtvgPtJ6rnyct17y/OrU8Qeuedd3T22Wfrzjvv1MiRI1Pvt7e366677tL3vvc9nXLKKZo5c6ZWr16tp59+Ws8880zGfXV2dqqjoyPtBeAgYg2wz884k4g14FB5dTZra2t12mmnqaamJu39pqYm7du3L+39adOmadKkSdq4cWPGfdXX1yuZTKZeEydOzKdIQCwRa4B9fsaZRKwBh/I8QWjt2rV67rnn9Oyzz/b5rKWlReXl5aqsrEx7v6qqSi0tLRn3t2LFCtXV1aX+3dHREVhgupwGkjIPdQeVWnPpfET9xux8RSXW/L4uxXadewuq7n4cJy7Xye84k7zFWpjfu2Ffw3x/x+Wb3s72c8W2brCXuvhVb0+dzZ07d+qyyy7T448/riFDhvhSgEQioUTCpbtYgPARa4B9NuJMItaAQ3lKozc1NWnXrl06/vjjVVZWprKyMm3YsEG33HKLysrKVFVVpa6uLrW1taX9XGtrq6qrq/0sNxBrxBpgH3EGBMPTyOaiRYv0pz/9Ke29Cy64QNOmTdOVV16piRMnavDgwWpsbNTSpUslSc3NzdqxY4fmz5/vX6mLUBBD+HFKE4TBz5mdLsaaq7dZIF2268T168uFOAviWrjaJvxeS9pLet3mTPywz6uLPHU2R4wYoenTp6e9N2zYMI0ePTr1/oUXXqi6ujqNGjVKFRUVuvTSSzV//nzNmzfPv1IDMUesAfYRZ0AwfH+C0M0336zS0lItXbpUnZ2dWrx4sW677Ta/DwMUPWINsI84AwqX96LutgS5+K3rQ92uly9O/DjXA+0j30XdbfEaa7RHhCGfdhf1WCtEXBciR26CfTDEwUiztqg7AAAAkAs6mwAAALDG93s2XZRtWNmVdEJUn08bp7Rq1MsfBM5RX349Yxjp4nquGv6RSLdZp4HaHhAGRjYBAABgDZ1NAAAAWFPUs9FdEeZzWaOUriqkrEE/Zz6TYp4hi3Q24y5KMW0LsQZbXL/tLcj49xJnjGwCAADAGjqbAAAAsKYoZqO7Lt/nvNo8totyKSspRPf1XKMwro/f7SPf/QU9G7kQxFR0hRlruXC9fJm4XlZXy8fIJgAAAKxhZNOyQm4mdvUvlKhw/UbuYhX0+WeNwcIQL9HFtYMrGNkEAACANXQ2AQAAYA1pdMu4WT9YnBP0x+/2EVR745YQxJHr7TfoCYVx/v3OyCYAAACsobMJAAAAayKVRg9ziNmVNFbchtb9Fuc0hKtcP+dhl8mPtQR7/6yX2fVBXRs/juN6OwpSGOeC899X0LfdxPm2O0Y2AQAAYA2dTQAAAFgTqTR6plRS2EPDA3El/Q7YUsxt2Uuayq+UliuPxfRbtlsFolQHvxRjnf1ks/24/js9W/nCvtWFkU0AAABYQ2cTAAAA1kQqjd6bK0PWA3G1nDZvQwjzFgdXzzfiyY90lB/7C5vfC15jYH6niqPU9gaqexh18Xo9gvg9me8qFrnszytGNgEAAGANnU0AAABYU2KMMWEXoreOjg4lk0ldJSlh+VjFPuOxUAMNyxfbOR0oNdopqUFSe3u7KioqgitYFkHGWhRFYWHtqKzK4VWh555Yc1fQcWXz+ea5iPNDDrzEGSObAAAAsIbOJgAAAKwp6jT6QHIZxo7CUHdY8k0J5rp91BRbai9uM66Rv6BjuxhizZXvyzj8nsz3u8rmd5zr50wijQ4AAABHMLLZjyj8ZYHsXBtZK4bRllzEdVJLvvie8V9UYy3Td1Yc2oRr38VxEfZ3ByObAAAAcAKdTQAAAFgT2cdVBsHVtfX8PGbc0hg88s59UVxbzyavk+e8/mzQ4poKDkKczhPfxbkp5Lsq6PZSSFkZ2QQAAIA1dDYBAABgjbNp9IZ/zNuLU1ohmzDqGNfzGtd6BSFKqeeBRL38/fFStyil3+EPm3Hs5far3tt4SalnK3+cvp9681oXP85Dvt8LhZx3RjYBAABgDZ1NAAAAWONsGv0qNYS+qDtQTOKUmoqbXB4D6CLa1MAGuoYuzVAO83rGtS15TYv7cR78SL8zGx0AAADOoLMJAAAAa5xNowMA+teTyspldmlQKfe4pjttsbm6QL4L7Ps98zuqbSKIGfCunxu/zgEjmwAAALCGziYAAACsKTHGmLAL0VtHR4eSyeQ/lnRPF9dFXXtzsY4ulimbXFKFYdWhU1KDpPb2dlVUVIRSht56Yk0+PkAhqouIR6mNDyROdcmXq7GW6fdavvK9LaJY20Sxy/cWjP7ai5c48zyy+frrr+ucc87R6NGjNXToUB177LHasmVL6nNjjK655hqNGzdOQ4cOVU1NjV588UWvhwGKHrEGBINYA+zy1Nl8++23tWDBAg0ePFi/+tWvtH37dt10000aOXJkapvvfve7uuWWW7Rq1Spt2rRJw4YN0+LFi7V3717fCw/EFbEGBINYA+zzlEa/6qqr9NRTT+l3v/tdxs+NMRo/fryuuOIKfeUrX5F0cHi1qqpKa9as0ec///k+P9PZ2anOzs7Uvzs6OjRx4kRf0w1x4OWZtH4eL8hj+i3fOtiqu5eUg4uxFoc2EQcDXQeuk/ux5vftJrk8T7zQYwCHspZGf/DBBzVr1iydeeaZGjt2rGbMmKE777wz9fkrr7yilpYW1dTUpN5LJpOaO3euNm7cmHGf9fX1SiaTqdfEiRO9FAmIJWINCAaxBtjnaWRzyJAhkqS6ujqdeeaZevbZZ3XZZZdp1apVOu+88/T0009rwYIFeuONNzRu3LjUz5111lkqKSnRPffc02efLo9sMkLglkLWCXTh+nn5K7DYYg3ordDvXmKteBTb7+l8R8VtTN70EmeeFnXv7u7WrFmzdMMNN0iSZsyYoW3btqWCMh+JREKJBOEH9EasAcEg1gD7PKXRx40bp2OOOSbtvaOPPlo7duyQJFVXV0uSWltb07ZpbW1NfQZgYMQaEAxiDbDP08jmggUL1NzcnPbeCy+8oMmTJ0uSpk6dqurqajU2Nuq4446TdDB9sGnTJl1yySX+lLgfPGILceF6rGVTbCktVxTbefezvlGNNRwUpfbuR7v14+eCenRtb546m5dffrlOOOEE3XDDDTrrrLO0efNm3XHHHbrjjjskSSUlJVq+fLm+9a1v6cgjj9TUqVN19dVXa/z48VqyZImN8gOxRKwBwSDWAPs8dTZnz56t++67TytWrND111+vqVOnauXKlTr77LNT23zta1/Tu+++q4suukhtbW068cQT9eijj6ZuwgYwMGINCAaxBtgXqcdVehHVx+Yhu2KajR4E24/Qy5a2ceFa+CWu9Yo6V2NNGaKNduM9joi7wvj1PW31cZUAAABArjyl0YPQM9DaOcB2A8u8h8L3i/Dkf/VcuO49ZXAlmeBfrPXWmeH/+ns/6uJar2hzNdYytRLajeQ9joi7wvjzPe0lzpxLo//1r3/laQuItZ07d2rChAlhF4NYQ+wRa4B9ucSZc53N7u5uvfHGGzLGaNKkSdq5c6cT99zY0PNUCeoYbbnW0RijPXv2aPz48SotDf8OFmItXqjjB1yMtebmZh1zzDFcn4ijjh/wEmfOpdFLS0s1YcIEdXR0SJIqKipie0F7UMd4yKWOBycJuIFYiyfqeJBrsfbhD39YEtcnLqjjQbnGWfh/8gEAACC26GwCAADAGmc7m4lEQtdee60SCb9WAHQPdYyHqNcx6uXPBXWMhyjXMcplzxV1jAcbdXRughAAAADiw9mRTQAAAEQfnU0AAABYQ2cTAAAA1tDZBAAAgDV0NgEAAGCNk53NW2+9VVOmTNGQIUM0d+5cbd68Oewi5a2+vl6zZ8/WiBEjNHbsWC1ZskTNzc1p2+zdu1e1tbUaPXq0hg8frqVLl6q1tTWkEheuoaFBJSUlWr58eeq9ONTx9ddf1znnnKPRo0dr6NChOvbYY7Vly5bU58YYXXPNNRo3bpyGDh2qmpoavfjiiyGWeGDEWvTaYW/EGrEWhmKLtbjGmRRgrBnHrF271pSXl5sf/vCH5s9//rP54he/aCorK01ra2vYRcvL4sWLzerVq822bdvM1q1bzamnnmomTZpk3nnnndQ2F198sZk4caJpbGw0W7ZsMfPmzTMnnHBCiKXO3+bNm82UKVPMxz72MXPZZZel3o96Hf/+97+byZMnm/PPP99s2rTJvPzyy+axxx4zL730UmqbhoYGk0wmzf3332/+8Ic/mNNPP91MnTrVvP/++yGWPDtiLXrtsDdijVgLSzHFWlzjzJhgY825zuacOXNMbW1t6t8HDhww48ePN/X19SGWyj+7du0yksyGDRuMMca0tbWZwYMHm3vvvTe1zfPPP28kmY0bN4ZVzLzs2bPHHHnkkebxxx83J510Uiow41DHK6+80px44olZP+/u7jbV1dXmxhtvTL3X1tZmEomEufvuu4MoomfEWvTaYQ9ijVhzSVxjLc5xZkywseZUGr2rq0tNTU2qqalJvVdaWqqamhpt3LgxxJL5p729XZI0atQoSVJTU5P27duXVudp06Zp0qRJkatzbW2tTjvttLS6SPGo44MPPqhZs2bpzDPP1NixYzVjxgzdeeedqc9feeUVtbS0pNUxmUxq7ty5TtaRWDsoau2wB7FGrLkkrrEW5ziTgo01pzqbu3fv1oEDB1RVVZX2flVVlVpaWkIqlX+6u7u1fPlyLViwQNOnT5cktbS0qLy8XJWVlWnbRq3Oa9eu1XPPPaf6+vo+n8Whji+//LJuv/12HXnkkXrsscd0ySWX6Mtf/rJ+9KMfSVKqHlFpu8TaB6JWZ2KNWHNJXGMt7nEmBRtrZf4UGbmora3Vtm3b9OSTT4ZdFF/t3LlTl112mR5//HENGTIk7OJY0d3drVmzZumGG26QJM2YMUPbtm3TqlWrdN5554VcOhyKWIsuYi1a4hhrxRBnUrCx5tTI5pgxYzRo0KA+M7paW1tVXV0dUqn8sWzZMj388MNat26dJkyYkHq/urpaXV1damtrS9s+SnVuamrSrl27dPzxx6usrExlZWXasGGDbrnlFpWVlamqqirydRw3bpyOOeaYtPeOPvpo7dixQ5JS9YhK2yXWPhClOhNrxJpL4hprxRBnUrCx5lRns7y8XDNnzlRjY2Pqve7ubjU2Nmr+/Pkhlix/xhgtW7ZM9913n5544glNnTo17fOZM2dq8ODBaXVubm7Wjh07IlPnRYsW6U9/+pO2bt2aes2aNUtnn3126v+jXscFCxb0WdrjhRde0OTJkyVJU6dOVXV1dVodOzo6tGnTJifrSKwdFLV2SKwRay6Ie6wVQ5xJAcdafnOY7Fm7dq1JJBJmzZo1Zvv27eaiiy4ylZWVpqWlJeyi5eWSSy4xyWTSrF+/3rz55pup13vvvZfa5uKLLzaTJk0yTzzxhNmyZYuZP3++mT9/foilLlzvmXvGRL+OmzdvNmVlZebb3/62efHFF81PfvITc9hhh5kf//jHqW0aGhpMZWWleeCBB8wf//hHc8YZZzi/HAuxFq12mAmxRqwFrRhjLW5xZkywseZcZ9MYY77//e+bSZMmmfLycjNnzhzzzDPPhF2kvEnK+Fq9enVqm/fff9986UtfMiNHjjSHHXaY+fSnP23efPPN8Artg0MDMw51fOihh8z06dNNIpEw06ZNM3fccUfa593d3ebqq682VVVVJpFImEWLFpnm5uaQSpsbYi167fBQxBqxFrRijLU4xpkxwcVaiTHGeBx5BQAAAHLi1D2bAAAAiBc6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACsobMJAAAAa+hsAgAAwBo6mwAAALCGziYAAACs+f+ra92tTsRJHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可視化\n",
    "row = 2  # 行数\n",
    "col = 3  # 列数\n",
    "\n",
    "for num in range(0, 30, 6):\n",
    "    fig, ax = plt.subplots(nrows=row, ncols=col, figsize=(8, 6))\n",
    "    fig.suptitle(f\"temperature:{prm_list[num][0]}\", fontsize=18, color='black')\n",
    "    for iconf in range(6):\n",
    "        _r = iconf//col\n",
    "        _c = iconf % col\n",
    "        file = f\"{prm_list[num][1]}{iconf}.npy\"\n",
    "        sc = np.load(file)\n",
    "        ax[_r,_c].imshow(sc, interpolation='nearest', vmin=0, vmax=1, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.shape =  24750\n",
      "test_dataset.shape =  13365\n"
     ]
    }
   ],
   "source": [
    "# hold out\n",
    "dataset, _ = create_train_data_CV(\n",
    "    prm_list, \n",
    "    ndata, \n",
    "    T_cr, \n",
    "    total_label=2, \n",
    "    L=L, \n",
    "    model_name=\"2d_Ising\",\n",
    "    exclude_T=exclude_T, \n",
    "    # correlation_configuration=True\n",
    ")\n",
    "_, _, test_dataset = create_train_data_hold_out(\n",
    "    prm_list, \n",
    "    ndata, \n",
    "    T_cr, \n",
    "    exclude_T=exclude_T, \n",
    "    total_label=2, \n",
    "    L=L, \n",
    "    model_name=\"2d_Ising\",\n",
    "    correlation_configuration=True\n",
    ")\n",
    "BATCH_SIZE=1024\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"dataset.shape = \", len(dataset))\n",
    "print(\"test_dataset.shape = \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, target_size):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(7*7*512, 512)\n",
    "        self.fc2 = nn.Linear(512, 96)\n",
    "        self.fc3 = nn.Linear(96, target_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = nn.MaxPool2d(2)(x)\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = nn.MaxPool2d(2)(x)\n",
    "        # x = self.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.dropout2(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps is available.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011150893839922819, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9720    0.9882    0.9800      1267\n",
      "           1     0.9874    0.9702    0.9787      1208\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9797    0.9792    0.9794      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011350504075637972, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9921    0.9760      1269\n",
      "           1     0.9914    0.9569    0.9738      1206\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9745    0.9749      2475\n",
      "weighted avg     0.9755    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011785676985075979, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9599    0.9916    0.9755      1305\n",
      "           1     0.9902    0.9538    0.9717      1170\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9751    0.9727    0.9736      2475\n",
      "weighted avg     0.9743    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000141563057297408, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.9961    0.9775      1286\n",
      "           1     0.9956    0.9546    0.9747      1189\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9776    0.9753    0.9761      2475\n",
      "weighted avg     0.9769    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010658046512892752, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9721    0.9892    0.9806      1301\n",
      "           1     0.9878    0.9685    0.9781      1174\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9799    0.9789    0.9793      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011026918888092041, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9946    0.9780      1298\n",
      "           1     0.9938    0.9567    0.9749      1177\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9779    0.9756    0.9765      2475\n",
      "weighted avg     0.9771    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.683189900234492e-05, Accuracy: 98.54545454545455%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9821    0.9898    0.9859      1272\n",
      "           1     0.9891    0.9809    0.9850      1203\n",
      "\n",
      "    accuracy                         0.9855      2475\n",
      "   macro avg     0.9856    0.9853    0.9854      2475\n",
      "weighted avg     0.9855    0.9855    0.9855      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001477850808037652, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9548    0.9906    0.9724      1280\n",
      "           1     0.9895    0.9498    0.9693      1195\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9722    0.9702    0.9708      2475\n",
      "weighted avg     0.9716    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010603050691912873, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9645    0.9871    0.9757      1321\n",
      "           1     0.9849    0.9584    0.9715      1154\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9747    0.9728    0.9736      2475\n",
      "weighted avg     0.9740    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013091763763716728, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9503    0.9937    0.9715      1271\n",
      "           1     0.9930    0.9452    0.9685      1204\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9717    0.9694    0.9700      2475\n",
      "weighted avg     0.9711    0.9701    0.9701      2475\n",
      "\n",
      "created model_classifier_config_0.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010675895394700946, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9558    0.9890    0.9721      1268\n",
      "           1     0.9880    0.9519    0.9696      1207\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9719    0.9705    0.9709      2475\n",
      "weighted avg     0.9715    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013372618140596333, Accuracy: 98.38383838383838%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9773    0.9923    0.9848      1303\n",
      "           1     0.9913    0.9744    0.9828      1172\n",
      "\n",
      "    accuracy                         0.9838      2475\n",
      "   macro avg     0.9843    0.9834    0.9838      2475\n",
      "weighted avg     0.9840    0.9838    0.9838      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.691428656529898e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9706    0.9877    0.9791      1303\n",
      "           1     0.9861    0.9667    0.9763      1172\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9783    0.9772    0.9777      2475\n",
      "weighted avg     0.9779    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000116806316255319, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9642    0.9891    0.9765      1281\n",
      "           1     0.9879    0.9606    0.9741      1194\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9761    0.9749    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012896943573999887, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9639    0.9895    0.9765      1240\n",
      "           1     0.9892    0.9628    0.9758      1235\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9765    0.9761    0.9762      2475\n",
      "weighted avg     0.9765    0.9762    0.9762      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013171779386924974, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.9923    0.9772      1295\n",
      "           1     0.9912    0.9576    0.9741      1180\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9769    0.9750    0.9757      2475\n",
      "weighted avg     0.9762    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001248582505216502, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.9939    0.9731      1309\n",
      "           1     0.9928    0.9451    0.9684      1166\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9730    0.9695    0.9707      2475\n",
      "weighted avg     0.9718    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012244009008311263, Accuracy: 96.48484848484848%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9431    0.9922    0.9671      1287\n",
      "           1     0.9911    0.9352    0.9623      1188\n",
      "\n",
      "    accuracy                         0.9648      2475\n",
      "   macro avg     0.9671    0.9637    0.9647      2475\n",
      "weighted avg     0.9661    0.9648    0.9648      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012778834863142534, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9546    0.9953    0.9745      1268\n",
      "           1     0.9948    0.9503    0.9720      1207\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9747    0.9728    0.9733      2475\n",
      "weighted avg     0.9742    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010708666510052152, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9731    0.9901    0.9815      1316\n",
      "           1     0.9886    0.9689    0.9786      1159\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9808    0.9795    0.9801      2475\n",
      "weighted avg     0.9803    0.9802    0.9802      2475\n",
      "\n",
      "created model_classifier_config_1.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001252098667501199, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9618    0.9898    0.9756      1271\n",
      "           1     0.9889    0.9585    0.9734      1204\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9753    0.9741    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010526615260827421, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9954    0.9786      1311\n",
      "           1     0.9946    0.9562    0.9750      1164\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9785    0.9758    0.9768      2475\n",
      "weighted avg     0.9776    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010488990581396854, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9617    0.9899    0.9756      1293\n",
      "           1     0.9886    0.9569    0.9725      1182\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9752    0.9734    0.9740      2475\n",
      "weighted avg     0.9746    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011172466205828118, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.9946    0.9753      1289\n",
      "           1     0.9938    0.9511    0.9720      1186\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9753    0.9728    0.9736      2475\n",
      "weighted avg     0.9745    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.942871683775777e-05, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9929    0.9761      1273\n",
      "           1     0.9922    0.9559    0.9737      1202\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9760    0.9744    0.9749      2475\n",
      "weighted avg     0.9755    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001126101492631315, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9534    0.9938    0.9732      1298\n",
      "           1     0.9929    0.9465    0.9691      1177\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9732    0.9702    0.9712      2475\n",
      "weighted avg     0.9722    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011483669883072978, Accuracy: 98.22222222222223%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9759    0.9898    0.9828      1269\n",
      "           1     0.9891    0.9743    0.9816      1206\n",
      "\n",
      "    accuracy                         0.9822      2475\n",
      "   macro avg     0.9825    0.9820    0.9822      2475\n",
      "weighted avg     0.9823    0.9822    0.9822      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011749402140126083, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9679    0.9891    0.9784      1280\n",
      "           1     0.9880    0.9649    0.9763      1195\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9779    0.9770    0.9773      2475\n",
      "weighted avg     0.9776    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012069779815095844, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.9900    0.9779      1296\n",
      "           1     0.9887    0.9618    0.9751      1179\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9774    0.9759    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.115876573504824e-05, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9645    0.9899    0.9770      1290\n",
      "           1     0.9887    0.9603    0.9743      1185\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9766    0.9751    0.9757      2475\n",
      "weighted avg     0.9761    0.9758    0.9757      2475\n",
      "\n",
      "created model_classifier_config_2.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011232042854482477, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9664    0.9888    0.9774      1249\n",
      "           1     0.9883    0.9649    0.9765      1226\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9773    0.9769    0.9770      2475\n",
      "weighted avg     0.9772    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012202522971413352, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9891    0.9755      1289\n",
      "           1     0.9878    0.9578    0.9726      1186\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9750    0.9735    0.9741      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012625048858950838, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9522    0.9952    0.9732      1260\n",
      "           1     0.9948    0.9481    0.9709      1215\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9735    0.9717    0.9721      2475\n",
      "weighted avg     0.9731    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011956656822050461, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9536    0.9922    0.9725      1283\n",
      "           1     0.9912    0.9480    0.9691      1192\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9724    0.9701    0.9708      2475\n",
      "weighted avg     0.9717    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013590006515233204, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9605    0.9931    0.9765      1297\n",
      "           1     0.9921    0.9550    0.9732      1178\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9763    0.9740    0.9748      2475\n",
      "weighted avg     0.9755    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010464564718381323, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9707    0.9915    0.9810      1301\n",
      "           1     0.9904    0.9668    0.9784      1174\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9805    0.9792    0.9797      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001024655621461194, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9928    0.9799      1253\n",
      "           1     0.9924    0.9656    0.9788      1222\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9799    0.9792    0.9794      2475\n",
      "weighted avg     0.9797    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001582027625555944, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9643    0.9931    0.9785      1305\n",
      "           1     0.9920    0.9590    0.9752      1170\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9782    0.9760    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011483649713824494, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9678    0.9873    0.9774      1339\n",
      "           1     0.9847    0.9613    0.9728      1136\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9762    0.9743    0.9751      2475\n",
      "weighted avg     0.9755    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011551400025685628, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9915    0.9779      1294\n",
      "           1     0.9904    0.9602    0.9751      1181\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9775    0.9759    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "created model_classifier_config_3.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010503246928706314, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9731    0.9883    0.9807      1282\n",
      "           1     0.9872    0.9707    0.9789      1193\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9802    0.9795    0.9798      2475\n",
      "weighted avg     0.9799    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011196580800143155, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9740    0.9907    0.9822      1284\n",
      "           1     0.9897    0.9715    0.9805      1191\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9819    0.9811    0.9814      2475\n",
      "weighted avg     0.9816    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000112197453325445, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.9905    0.9794      1269\n",
      "           1     0.9898    0.9660    0.9778      1206\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9791    0.9783    0.9786      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012921836641099717, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9572    0.9913    0.9740      1264\n",
      "           1     0.9906    0.9538    0.9718      1211\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9739    0.9725    0.9729      2475\n",
      "weighted avg     0.9735    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.295458444441207e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9938    0.9791      1296\n",
      "           1     0.9930    0.9601    0.9763      1179\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9789    0.9770    0.9777      2475\n",
      "weighted avg     0.9782    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010329092993880764, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.9869    0.9764      1300\n",
      "           1     0.9852    0.9617    0.9733      1175\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9756    0.9743    0.9749      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014144278836972785, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9915    0.9756      1292\n",
      "           1     0.9904    0.9552    0.9725      1183\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9753    0.9733    0.9740      2475\n",
      "weighted avg     0.9747    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011739818134693185, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9933    0.9771      1353\n",
      "           1     0.9916    0.9519    0.9714      1122\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9765    0.9726    0.9742      2475\n",
      "weighted avg     0.9751    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013213720285531246, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9871    0.9780      1237\n",
      "           1     0.9868    0.9685    0.9776      1238\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9779    0.9778    0.9778      2475\n",
      "weighted avg     0.9779    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014148052593674322, Accuracy: 96.48484848484848%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9414    0.9946    0.9673      1293\n",
      "           1     0.9937    0.9323    0.9620      1182\n",
      "\n",
      "    accuracy                         0.9648      2475\n",
      "   macro avg     0.9676    0.9635    0.9647      2475\n",
      "weighted avg     0.9664    0.9648    0.9648      2475\n",
      "\n",
      "created model_classifier_config_4.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010242092187958535, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9923    0.9801      1291\n",
      "           1     0.9913    0.9645    0.9777      1184\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9798    0.9784    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011122731548367125, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9650    0.9908    0.9778      1309\n",
      "           1     0.9894    0.9597    0.9743      1166\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9772    0.9753    0.9760      2475\n",
      "weighted avg     0.9765    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010464655630516284, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9681    0.9914    0.9796      1286\n",
      "           1     0.9905    0.9647    0.9774      1189\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9793    0.9781    0.9785      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013570148234415535, Accuracy: 96.56565656565657%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9464    0.9890    0.9672      1267\n",
      "           1     0.9878    0.9412    0.9640      1208\n",
      "\n",
      "    accuracy                         0.9657      2475\n",
      "   macro avg     0.9671    0.9651    0.9656      2475\n",
      "weighted avg     0.9666    0.9657    0.9656      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001064236748098123, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9938    0.9773      1299\n",
      "           1     0.9929    0.9558    0.9740      1176\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9771    0.9748    0.9756      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010230611671100964, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9719    0.9900    0.9809      1295\n",
      "           1     0.9888    0.9686    0.9786      1180\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9804    0.9793    0.9797      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010538972086376614, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9930    0.9778      1286\n",
      "           1     0.9922    0.9588    0.9752      1189\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9776    0.9759    0.9765      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013310838528353758, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9709    0.9896    0.9802      1249\n",
      "           1     0.9892    0.9698    0.9794      1226\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9801    0.9797    0.9798      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012354283922850484, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.9865    0.9774      1335\n",
      "           1     0.9839    0.9623    0.9729      1140\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9761    0.9744    0.9752      2475\n",
      "weighted avg     0.9755    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013529486728437018, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9476    0.9952    0.9708      1253\n",
      "           1     0.9948    0.9435    0.9685      1222\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9712    0.9694    0.9697      2475\n",
      "weighted avg     0.9709    0.9697    0.9697      2475\n",
      "\n",
      "created model_classifier_config_5.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011274903109579375, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9901    0.9785      1308\n",
      "           1     0.9886    0.9623    0.9752      1167\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9778    0.9762    0.9769      2475\n",
      "weighted avg     0.9772    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011096583773391416, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9931    0.9787      1298\n",
      "           1     0.9921    0.9601    0.9758      1177\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9785    0.9766    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011595188066212818, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.9884    0.9738      1298\n",
      "           1     0.9868    0.9541    0.9702      1177\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9732    0.9713    0.9720      2475\n",
      "weighted avg     0.9725    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010576559738679365, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9691    0.9900    0.9795      1301\n",
      "           1     0.9887    0.9651    0.9767      1174\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9789    0.9775    0.9781      2475\n",
      "weighted avg     0.9784    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011396559199901543, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9509    0.9937    0.9718      1267\n",
      "           1     0.9930    0.9462    0.9691      1208\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9720    0.9699    0.9704      2475\n",
      "weighted avg     0.9715    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012939140652165268, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.9952    0.9771      1241\n",
      "           1     0.9949    0.9579    0.9761      1234\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9773    0.9765    0.9766      2475\n",
      "weighted avg     0.9772    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011169572671254476, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9546    0.9932    0.9735      1314\n",
      "           1     0.9919    0.9466    0.9687      1161\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9733    0.9699    0.9711      2475\n",
      "weighted avg     0.9721    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012357138624094954, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9651    0.9899    0.9773      1284\n",
      "           1     0.9888    0.9614    0.9749      1191\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9769    0.9756    0.9761      2475\n",
      "weighted avg     0.9765    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010073159379188461, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9946    0.9810      1297\n",
      "           1     0.9939    0.9635    0.9784      1178\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9808    0.9791    0.9797      2475\n",
      "weighted avg     0.9802    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013711740272213715, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9549    0.9905    0.9724      1262\n",
      "           1     0.9897    0.9514    0.9702      1213\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9723    0.9709    0.9713      2475\n",
      "weighted avg     0.9720    0.9713    0.9713      2475\n",
      "\n",
      "created model_classifier_config_6.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012033206344854953, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9712    0.9923    0.9816      1291\n",
      "           1     0.9913    0.9679    0.9795      1184\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9813    0.9801    0.9805      2475\n",
      "weighted avg     0.9808    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013097707370314935, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9589    0.9887    0.9736      1322\n",
      "           1     0.9865    0.9514    0.9687      1153\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9727    0.9700    0.9711      2475\n",
      "weighted avg     0.9718    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010129661873133495, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9664    0.9906    0.9784      1279\n",
      "           1     0.9897    0.9632    0.9763      1196\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9781    0.9769    0.9773      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010439754134476786, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9885    0.9739      1301\n",
      "           1     0.9868    0.9540    0.9701      1174\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9732    0.9712    0.9720      2475\n",
      "weighted avg     0.9725    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011081548953297163, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9937    0.9766      1279\n",
      "           1     0.9930    0.9557    0.9740      1196\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9765    0.9747    0.9753      2475\n",
      "weighted avg     0.9760    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010782241219221944, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9733    0.9907    0.9819      1286\n",
      "           1     0.9897    0.9706    0.9800      1189\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9815    0.9806    0.9810      2475\n",
      "weighted avg     0.9812    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010867093548630223, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9655    0.9921    0.9786      1270\n",
      "           1     0.9915    0.9627    0.9768      1205\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9774    0.9777      2475\n",
      "weighted avg     0.9781    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011303792397181193, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9897    0.9792      1262\n",
      "           1     0.9890    0.9670    0.9779      1213\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9790    0.9784    0.9786      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.656332658998894e-05, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9714    0.9923    0.9817      1300\n",
      "           1     0.9913    0.9677    0.9793      1175\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9813    0.9800    0.9805      2475\n",
      "weighted avg     0.9808    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.98744097622958e-05, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9593    0.9953    0.9770      1280\n",
      "           1     0.9948    0.9548    0.9744      1195\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9771    0.9751    0.9757      2475\n",
      "weighted avg     0.9764    0.9758    0.9757      2475\n",
      "\n",
      "created model_classifier_config_7.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012565190442884812, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9558    0.9914    0.9733      1286\n",
      "           1     0.9904    0.9504    0.9700      1189\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9731    0.9709    0.9716      2475\n",
      "weighted avg     0.9724    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.53916467801489e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9944    0.9785      1257\n",
      "           1     0.9941    0.9606    0.9770      1218\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9775    0.9778      2475\n",
      "weighted avg     0.9783    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.623121964811074e-05, Accuracy: 98.54545454545455%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9789    0.9939    0.9863      1306\n",
      "           1     0.9930    0.9760    0.9845      1169\n",
      "\n",
      "    accuracy                         0.9855      2475\n",
      "   macro avg     0.9860    0.9850    0.9854      2475\n",
      "weighted avg     0.9856    0.9855    0.9854      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012389394671025902, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9906    0.9750      1277\n",
      "           1     0.9896    0.9558    0.9724      1198\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9747    0.9732    0.9737      2475\n",
      "weighted avg     0.9742    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011318247125606344, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9645    0.9915    0.9778      1289\n",
      "           1     0.9904    0.9604    0.9752      1186\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9775    0.9759    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010928558881836708, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9877    0.9779      1300\n",
      "           1     0.9861    0.9643    0.9750      1175\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9772    0.9760    0.9765      2475\n",
      "weighted avg     0.9768    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.709279425216443e-05, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9853    0.9762      1291\n",
      "           1     0.9836    0.9637    0.9735      1184\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9755    0.9745    0.9749      2475\n",
      "weighted avg     0.9751    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001282375870328961, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9618    0.9921    0.9767      1269\n",
      "           1     0.9914    0.9585    0.9747      1206\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9766    0.9753    0.9757      2475\n",
      "weighted avg     0.9762    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013705432716042105, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9549    0.9931    0.9736      1300\n",
      "           1     0.9920    0.9481    0.9695      1175\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9734    0.9706    0.9716      2475\n",
      "weighted avg     0.9725    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001252276457921423, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9946    0.9810      1295\n",
      "           1     0.9939    0.9636    0.9785      1180\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9808    0.9791    0.9797      2475\n",
      "weighted avg     0.9802    0.9798    0.9798      2475\n",
      "\n",
      "created model_classifier_config_8.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.847843285762903e-05, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9905    0.9755      1266\n",
      "           1     0.9897    0.9578    0.9735      1209\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9753    0.9742    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011734235467332782, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.9885    0.9772      1299\n",
      "           1     0.9869    0.9617    0.9742      1176\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9765    0.9751    0.9757      2475\n",
      "weighted avg     0.9760    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011208920466779458, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9665    0.9937    0.9800      1279\n",
      "           1     0.9931    0.9632    0.9779      1196\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9798    0.9785    0.9789      2475\n",
      "weighted avg     0.9794    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.931102846608017e-05, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9944    0.9798      1242\n",
      "           1     0.9941    0.9643    0.9790      1233\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9799    0.9793    0.9794      2475\n",
      "weighted avg     0.9798    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011643232420237377, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9602    0.9930    0.9763      1287\n",
      "           1     0.9921    0.9554    0.9734      1188\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9762    0.9742    0.9749      2475\n",
      "weighted avg     0.9755    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011228558391031593, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9938    0.9733      1300\n",
      "           1     0.9929    0.9464    0.9691      1175\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9732    0.9701    0.9712      2475\n",
      "weighted avg     0.9722    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012009477976596716, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9909    0.9763      1312\n",
      "           1     0.9893    0.9561    0.9725      1163\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9758    0.9735    0.9744      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001238263827381712, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.9894    0.9779      1319\n",
      "           1     0.9876    0.9611    0.9741      1156\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9771    0.9752    0.9760      2475\n",
      "weighted avg     0.9764    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014396482946896794, Accuracy: 96.4040404040404%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9393    0.9928    0.9653      1247\n",
      "           1     0.9922    0.9349    0.9627      1228\n",
      "\n",
      "    accuracy                         0.9640      2475\n",
      "   macro avg     0.9658    0.9638    0.9640      2475\n",
      "weighted avg     0.9656    0.9640    0.9640      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011765176900709519, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9917    0.9772      1319\n",
      "           1     0.9902    0.9567    0.9732      1156\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9767    0.9742    0.9752      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "created model_classifier_config_9.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011645892653802428, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.9897    0.9731      1263\n",
      "           1     0.9889    0.9538    0.9710      1212\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9730    0.9718    0.9721      2475\n",
      "weighted avg     0.9727    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.609930975268585e-05, Accuracy: 98.34343434343434%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9807    0.9875    0.9841      1285\n",
      "           1     0.9865    0.9790    0.9827      1190\n",
      "\n",
      "    accuracy                         0.9834      2475\n",
      "   macro avg     0.9836    0.9833    0.9834      2475\n",
      "weighted avg     0.9835    0.9834    0.9834      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.494276359827832e-05, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9711    0.9864    0.9787      1327\n",
      "           1     0.9840    0.9660    0.9749      1148\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9775    0.9762    0.9768      2475\n",
      "weighted avg     0.9771    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001011949446466234, Accuracy: 98.42424242424242%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9762    0.9937    0.9849      1278\n",
      "           1     0.9932    0.9741    0.9836      1197\n",
      "\n",
      "    accuracy                         0.9842      2475\n",
      "   macro avg     0.9847    0.9839    0.9842      2475\n",
      "weighted avg     0.9844    0.9842    0.9842      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011426572847847987, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9930    0.9752      1288\n",
      "           1     0.9921    0.9528    0.9721      1187\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9751    0.9729    0.9736      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001019695672121915, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9905    0.9750      1259\n",
      "           1     0.9898    0.9572    0.9732      1216\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9749    0.9739    0.9741      2475\n",
      "weighted avg     0.9746    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000106155023430333, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9697    0.9922    0.9808      1289\n",
      "           1     0.9913    0.9663    0.9787      1186\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9805    0.9793    0.9797      2475\n",
      "weighted avg     0.9801    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001299442125089241, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9557    0.9923    0.9737      1305\n",
      "           1     0.9911    0.9487    0.9694      1170\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9734    0.9705    0.9716      2475\n",
      "weighted avg     0.9724    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001280331491219877, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9947    0.9806      1318\n",
      "           1     0.9937    0.9611    0.9772      1157\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9803    0.9779    0.9789      2475\n",
      "weighted avg     0.9794    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.579995966920949e-05, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9881    0.9745      1258\n",
      "           1     0.9873    0.9589    0.9729      1217\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9743    0.9735    0.9737      2475\n",
      "weighted avg     0.9741    0.9737    0.9737      2475\n",
      "\n",
      "created model_classifier_config_10.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.835739930470785e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9931    0.9811      1308\n",
      "           1     0.9921    0.9649    0.9783      1167\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9807    0.9790    0.9797      2475\n",
      "weighted avg     0.9801    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011769828170236915, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9946    0.9769      1295\n",
      "           1     0.9938    0.9542    0.9736      1180\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9768    0.9744    0.9752      2475\n",
      "weighted avg     0.9760    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013603451577099887, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9691    0.9877    0.9783      1300\n",
      "           1     0.9861    0.9651    0.9755      1175\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9776    0.9764    0.9769      2475\n",
      "weighted avg     0.9771    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010633857864322085, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9930    0.9774      1286\n",
      "           1     0.9922    0.9579    0.9748      1189\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9772    0.9755    0.9761      2475\n",
      "weighted avg     0.9767    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010075452652844516, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9902    0.9773      1325\n",
      "           1     0.9883    0.9583    0.9731      1150\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9765    0.9742    0.9752      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011708261087687328, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9540    0.9912    0.9723      1255\n",
      "           1     0.9906    0.9508    0.9703      1220\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9723    0.9710    0.9713      2475\n",
      "weighted avg     0.9720    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014444305740221583, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9883    0.9758      1284\n",
      "           1     0.9870    0.9597    0.9732      1191\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9753    0.9740    0.9745      2475\n",
      "weighted avg     0.9749    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.091002471519239e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9708    0.9906    0.9806      1277\n",
      "           1     0.9898    0.9683    0.9789      1198\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9803    0.9794    0.9798      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011470136016306251, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9643    0.9930    0.9784      1278\n",
      "           1     0.9922    0.9607    0.9762      1197\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9783    0.9768    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010460752730417733, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9579    0.9913    0.9743      1262\n",
      "           1     0.9906    0.9547    0.9723      1213\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9742    0.9730    0.9733      2475\n",
      "weighted avg     0.9739    0.9733    0.9733      2475\n",
      "\n",
      "created model_classifier_config_11.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012827870821711994, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9589    0.9884    0.9734      1298\n",
      "           1     0.9868    0.9533    0.9697      1177\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9729    0.9709    0.9716      2475\n",
      "weighted avg     0.9722    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011247507550499657, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9743    0.9866    0.9804      1266\n",
      "           1     0.9858    0.9727    0.9792      1209\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9800    0.9796    0.9798      2475\n",
      "weighted avg     0.9799    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001117710844434873, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.9906    0.9762      1283\n",
      "           1     0.9896    0.9581    0.9736      1192\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9744    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010932274840094826, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9550    0.9931    0.9737      1303\n",
      "           1     0.9920    0.9480    0.9695      1172\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9735    0.9705    0.9716      2475\n",
      "weighted avg     0.9725    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014457278179399896, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.9932    0.9754      1315\n",
      "           1     0.9919    0.9509    0.9710      1160\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9750    0.9720    0.9732      2475\n",
      "weighted avg     0.9740    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.477495545088643e-05, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.9932    0.9776      1317\n",
      "           1     0.9919    0.9560    0.9736      1158\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9772    0.9746    0.9756      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011315527588430077, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9607    0.9938    0.9770      1280\n",
      "           1     0.9930    0.9565    0.9744      1195\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9769    0.9751    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011275980207655166, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.9929    0.9769      1259\n",
      "           1     0.9923    0.9589    0.9753      1216\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9769    0.9759    0.9761      2475\n",
      "weighted avg     0.9767    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001136403131966639, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9657    0.9906    0.9780      1280\n",
      "           1     0.9897    0.9623    0.9758      1195\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9777    0.9765    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.361559694463556e-05, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9589    0.9937    0.9760      1269\n",
      "           1     0.9931    0.9552    0.9738      1206\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9760    0.9745    0.9749      2475\n",
      "weighted avg     0.9756    0.9749    0.9749      2475\n",
      "\n",
      "created model_classifier_config_12.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001306136328764636, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9511    0.9961    0.9731      1290\n",
      "           1     0.9956    0.9443    0.9693      1185\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9733    0.9702    0.9712      2475\n",
      "weighted avg     0.9724    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.891829707405784e-05, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9904    0.9788      1256\n",
      "           1     0.9899    0.9655    0.9776      1219\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9786    0.9780    0.9782      2475\n",
      "weighted avg     0.9785    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012000344317368786, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9703    0.9899    0.9800      1287\n",
      "           1     0.9888    0.9672    0.9779      1188\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9796    0.9785    0.9789      2475\n",
      "weighted avg     0.9792    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011197699741883711, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9716    0.9894    0.9804      1315\n",
      "           1     0.9877    0.9672    0.9774      1160\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9796    0.9783    0.9789      2475\n",
      "weighted avg     0.9791    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.41583484110206e-05, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9720    0.9923    0.9820      1293\n",
      "           1     0.9913    0.9687    0.9799      1182\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9817    0.9805    0.9810      2475\n",
      "weighted avg     0.9812    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013165399281665533, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9542    0.9923    0.9729      1302\n",
      "           1     0.9911    0.9471    0.9686      1173\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9726    0.9697    0.9708      2475\n",
      "weighted avg     0.9717    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013133386469850637, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9561    0.9925    0.9740      1206\n",
      "           1     0.9926    0.9567    0.9743      1269\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9744    0.9746    0.9741      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010270052184962263, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9907    0.9775      1296\n",
      "           1     0.9895    0.9601    0.9746      1179\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9771    0.9754    0.9761      2475\n",
      "weighted avg     0.9765    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012348437851125545, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9858    0.9773      1267\n",
      "           1     0.9848    0.9669    0.9758      1208\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9769    0.9763    0.9765      2475\n",
      "weighted avg     0.9767    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011154712149591157, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9663    0.9919    0.9789      1358\n",
      "           1     0.9898    0.9579    0.9736      1117\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9781    0.9749    0.9763      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "created model_classifier_config_13.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010452187121516526, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9605    0.9922    0.9761      1276\n",
      "           1     0.9914    0.9566    0.9737      1199\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9760    0.9744    0.9749      2475\n",
      "weighted avg     0.9755    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010460629607691909, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9969    0.9771      1284\n",
      "           1     0.9965    0.9530    0.9742      1191\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9773    0.9749    0.9757      2475\n",
      "weighted avg     0.9766    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011829418064367892, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9767    0.9871    0.9818      1315\n",
      "           1     0.9852    0.9733    0.9792      1160\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9809    0.9802    0.9805      2475\n",
      "weighted avg     0.9807    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012699906874184656, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9937    0.9755      1264\n",
      "           1     0.9931    0.9546    0.9735      1211\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9756    0.9741    0.9745      2475\n",
      "weighted avg     0.9752    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.785884257518884e-05, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9706    0.9931    0.9817      1296\n",
      "           1     0.9922    0.9669    0.9794      1179\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9814    0.9800    0.9805      2475\n",
      "weighted avg     0.9809    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012057013884939328, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.9913    0.9798      1269\n",
      "           1     0.9906    0.9660    0.9782      1206\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9795    0.9787    0.9790      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011780903495923437, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9875    0.9732      1285\n",
      "           1     0.9861    0.9546    0.9701      1190\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9726    0.9711    0.9716      2475\n",
      "weighted avg     0.9721    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012184255351923933, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9549    0.9917    0.9730      1325\n",
      "           1     0.9900    0.9461    0.9675      1150\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9725    0.9689    0.9703      2475\n",
      "weighted avg     0.9712    0.9705    0.9704      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012378675769073795, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9492    0.9969    0.9725      1275\n",
      "           1     0.9965    0.9433    0.9692      1200\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9728    0.9701    0.9708      2475\n",
      "weighted avg     0.9721    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011011899721742881, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9731    0.9891    0.9810      1281\n",
      "           1     0.9881    0.9707    0.9793      1194\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9806    0.9799    0.9802      2475\n",
      "weighted avg     0.9803    0.9802    0.9802      2475\n",
      "\n",
      "created model_classifier_config_14.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001275372655704768, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9499    0.9931    0.9710      1298\n",
      "           1     0.9919    0.9422    0.9664      1177\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9709    0.9676    0.9687      2475\n",
      "weighted avg     0.9699    0.9689    0.9688      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010584233686177417, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9612    0.9938    0.9772      1296\n",
      "           1     0.9930    0.9559    0.9741      1179\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9771    0.9749    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010952081042106706, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9939    0.9808      1308\n",
      "           1     0.9929    0.9632    0.9778      1167\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9805    0.9785    0.9793      2475\n",
      "weighted avg     0.9797    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.849132612498119e-05, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9945    0.9809      1264\n",
      "           1     0.9940    0.9653    0.9795      1211\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9809    0.9799    0.9802      2475\n",
      "weighted avg     0.9806    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.58231686582469e-05, Accuracy: 98.34343434343434%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9814    0.9880    0.9847      1333\n",
      "           1     0.9859    0.9781    0.9820      1142\n",
      "\n",
      "    accuracy                         0.9834      2475\n",
      "   macro avg     0.9836    0.9831    0.9833      2475\n",
      "weighted avg     0.9835    0.9834    0.9834      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010871519645055135, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9544    0.9910    0.9724      1226\n",
      "           1     0.9908    0.9536    0.9718      1249\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9726    0.9723    0.9721      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012029859453740746, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9626    0.9894    0.9758      1325\n",
      "           1     0.9874    0.9557    0.9713      1150\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9750    0.9725    0.9735      2475\n",
      "weighted avg     0.9741    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011144441787642662, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9906    0.9771      1271\n",
      "           1     0.9897    0.9610    0.9751      1204\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9769    0.9758    0.9761      2475\n",
      "weighted avg     0.9765    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013454989351407447, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9584    0.9930    0.9754      1277\n",
      "           1     0.9922    0.9541    0.9728      1198\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9753    0.9735    0.9741      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012801380771579164, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9553    0.9921    0.9734      1272\n",
      "           1     0.9913    0.9510    0.9707      1203\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9733    0.9715    0.9721      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "created model_classifier_config_15.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.808587907540678e-05, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9761    0.9883    0.9821      1279\n",
      "           1     0.9873    0.9741    0.9806      1196\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9817    0.9812    0.9814      2475\n",
      "weighted avg     0.9815    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011357897459858596, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9599    0.9936    0.9765      1252\n",
      "           1     0.9932    0.9575    0.9750      1223\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9765    0.9755    0.9757      2475\n",
      "weighted avg     0.9764    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011586872014132413, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9561    0.9865    0.9711      1259\n",
      "           1     0.9855    0.9531    0.9691      1216\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9708    0.9698    0.9701      2475\n",
      "weighted avg     0.9706    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011939893768291281, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9931    0.9773      1301\n",
      "           1     0.9920    0.9566    0.9740      1174\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9770    0.9748    0.9756      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012714983838977236, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9486    0.9938    0.9706      1281\n",
      "           1     0.9929    0.9422    0.9669      1194\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9708    0.9680    0.9688      2475\n",
      "weighted avg     0.9700    0.9689    0.9688      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.532242712348398e-05, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9748    0.9884    0.9816      1293\n",
      "           1     0.9871    0.9721    0.9795      1182\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9810    0.9802    0.9806      2475\n",
      "weighted avg     0.9807    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011181521897364144, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9884    0.9756      1292\n",
      "           1     0.9869    0.9586    0.9726      1183\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9750    0.9735    0.9741      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001278207910181296, Accuracy: 98.22222222222223%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9768    0.9901    0.9834      1316\n",
      "           1     0.9886    0.9733    0.9809      1159\n",
      "\n",
      "    accuracy                         0.9822      2475\n",
      "   macro avg     0.9827    0.9817    0.9821      2475\n",
      "weighted avg     0.9823    0.9822    0.9822      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012129790554142962, Accuracy: 98.22222222222223%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9732    0.9939    0.9835      1316\n",
      "           1     0.9929    0.9689    0.9808      1159\n",
      "\n",
      "    accuracy                         0.9822      2475\n",
      "   macro avg     0.9831    0.9814    0.9821      2475\n",
      "weighted avg     0.9824    0.9822    0.9822      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012615005476306182, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9521    0.9938    0.9725      1281\n",
      "           1     0.9930    0.9464    0.9691      1194\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9726    0.9701    0.9708      2475\n",
      "weighted avg     0.9718    0.9709    0.9709      2475\n",
      "\n",
      "created model_classifier_config_16.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012554833684304747, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9715    0.9885    0.9799      1310\n",
      "           1     0.9869    0.9674    0.9770      1165\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9792    0.9780    0.9785      2475\n",
      "weighted avg     0.9787    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010445314224320228, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.9930    0.9770      1282\n",
      "           1     0.9922    0.9573    0.9744      1193\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9768    0.9751    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.72914153879339e-05, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9617    0.9959    0.9785      1234\n",
      "           1     0.9958    0.9605    0.9779      1241\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9787    0.9782    0.9782      2475\n",
      "weighted avg     0.9788    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001262883014149136, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9899    0.9766      1285\n",
      "           1     0.9887    0.9597    0.9740      1190\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9762    0.9748    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010844072910270306, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9908    0.9793      1311\n",
      "           1     0.9894    0.9631    0.9761      1164\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9787    0.9770    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010225268626453901, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9575    0.9929    0.9749      1271\n",
      "           1     0.9922    0.9535    0.9725      1204\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9749    0.9732    0.9737      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011542458124835081, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9692    0.9946    0.9817      1297\n",
      "           1     0.9939    0.9652    0.9793      1178\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9815    0.9799    0.9805      2475\n",
      "weighted avg     0.9809    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012797294542042897, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9578    0.9895    0.9734      1330\n",
      "           1     0.9873    0.9493    0.9679      1145\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9725    0.9694    0.9707      2475\n",
      "weighted avg     0.9714    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010727329988672276, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9509    0.9953    0.9726      1283\n",
      "           1     0.9947    0.9446    0.9690      1192\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9728    0.9700    0.9708      2475\n",
      "weighted avg     0.9720    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013479497396584714, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9486    0.9905    0.9691      1267\n",
      "           1     0.9896    0.9437    0.9661      1208\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9691    0.9671    0.9676      2475\n",
      "weighted avg     0.9686    0.9677    0.9676      2475\n",
      "\n",
      "created model_classifier_config_17.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011090044120345453, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.9907    0.9786      1290\n",
      "           1     0.9896    0.9629    0.9760      1185\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9782    0.9768    0.9773      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011518064171376854, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9742    0.9907    0.9824      1296\n",
      "           1     0.9896    0.9712    0.9803      1179\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9819    0.9810    0.9814      2475\n",
      "weighted avg     0.9816    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011881129007146816, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9635    0.9954    0.9792      1300\n",
      "           1     0.9947    0.9583    0.9762      1175\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9791    0.9768    0.9777      2475\n",
      "weighted avg     0.9783    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013099133968353272, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.9914    0.9769      1277\n",
      "           1     0.9905    0.9591    0.9746      1198\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9766    0.9752    0.9757      2475\n",
      "weighted avg     0.9762    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010793484220601092, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.9870    0.9744      1310\n",
      "           1     0.9850    0.9562    0.9704      1165\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9735    0.9716    0.9724      2475\n",
      "weighted avg     0.9728    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012181488853512388, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9542    0.9911    0.9723      1239\n",
      "           1     0.9907    0.9523    0.9711      1236\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9724    0.9717    0.9717      2475\n",
      "weighted avg     0.9724    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011230496445087471, Accuracy: 98.18181818181819%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9729    0.9921    0.9824      1266\n",
      "           1     0.9916    0.9711    0.9812      1209\n",
      "\n",
      "    accuracy                         0.9818      2475\n",
      "   macro avg     0.9822    0.9816    0.9818      2475\n",
      "weighted avg     0.9820    0.9818    0.9818      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010540435410509206, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9709    0.9867    0.9787      1283\n",
      "           1     0.9855    0.9681    0.9767      1192\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9782    0.9774    0.9777      2475\n",
      "weighted avg     0.9779    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010302724561305961, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9617    0.9915    0.9764      1292\n",
      "           1     0.9904    0.9569    0.9733      1183\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9760    0.9742    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001256756619973616, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9962    0.9766      1317\n",
      "           1     0.9955    0.9499    0.9722      1158\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9766    0.9731    0.9744      2475\n",
      "weighted avg     0.9754    0.9745    0.9745      2475\n",
      "\n",
      "created model_classifier_config_18.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001161908952876775, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9713    0.9915    0.9813      1297\n",
      "           1     0.9904    0.9677    0.9790      1178\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9809    0.9796    0.9801      2475\n",
      "weighted avg     0.9804    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011855545971128676, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.9922    0.9772      1274\n",
      "           1     0.9914    0.9592    0.9750      1201\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9770    0.9757    0.9761      2475\n",
      "weighted avg     0.9766    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010572434073746806, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9944    0.9757      1253\n",
      "           1     0.9940    0.9550    0.9741      1222\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9747    0.9749      2475\n",
      "weighted avg     0.9757    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012121781556293217, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.9930    0.9755      1283\n",
      "           1     0.9921    0.9539    0.9726      1192\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9754    0.9734    0.9741      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001062988301720282, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9899    0.9793      1288\n",
      "           1     0.9888    0.9655    0.9770      1187\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9788    0.9777    0.9781      2475\n",
      "weighted avg     0.9784    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013084864977634314, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9907    0.9751      1284\n",
      "           1     0.9896    0.9555    0.9722      1191\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9748    0.9731    0.9737      2475\n",
      "weighted avg     0.9742    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.843475288814969e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9743    0.9866    0.9805      1347\n",
      "           1     0.9838    0.9690    0.9763      1128\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9791    0.9778    0.9784      2475\n",
      "weighted avg     0.9787    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011152917086476027, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9540    0.9915    0.9724      1296\n",
      "           1     0.9902    0.9474    0.9684      1179\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9721    0.9695    0.9704      2475\n",
      "weighted avg     0.9713    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.89234477582604e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9921    0.9782      1268\n",
      "           1     0.9915    0.9619    0.9765      1207\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9781    0.9770    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011554187295412776, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9542    0.9938    0.9736      1280\n",
      "           1     0.9930    0.9490    0.9705      1195\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9736    0.9714    0.9720      2475\n",
      "weighted avg     0.9730    0.9721    0.9721      2475\n",
      "\n",
      "created model_classifier_config_19.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011756280756960011, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9637    0.9876    0.9755      1291\n",
      "           1     0.9861    0.9595    0.9726      1184\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9749    0.9735    0.9741      2475\n",
      "weighted avg     0.9744    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011461616766573202, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9599    0.9938    0.9766      1300\n",
      "           1     0.9929    0.9540    0.9731      1175\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9764    0.9739    0.9748      2475\n",
      "weighted avg     0.9756    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011121619229364876, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9635    0.9938    0.9784      1300\n",
      "           1     0.9929    0.9583    0.9753      1175\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9782    0.9761    0.9769      2475\n",
      "weighted avg     0.9775    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011197549526137535, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9892    0.9733      1291\n",
      "           1     0.9877    0.9527    0.9699      1184\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9729    0.9709    0.9716      2475\n",
      "weighted avg     0.9722    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012280434069007333, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9914    0.9753      1273\n",
      "           1     0.9905    0.9559    0.9729      1202\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9751    0.9736    0.9741      2475\n",
      "weighted avg     0.9747    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014138245221340296, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9930    0.9744      1285\n",
      "           1     0.9921    0.9513    0.9713      1190\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9743    0.9721    0.9728      2475\n",
      "weighted avg     0.9736    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011138205275391087, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9589    0.9915    0.9749      1293\n",
      "           1     0.9903    0.9535    0.9716      1182\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9746    0.9725    0.9732      2475\n",
      "weighted avg     0.9739    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011639177498191294, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9714    0.9890    0.9801      1270\n",
      "           1     0.9882    0.9693    0.9786      1205\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9798    0.9791    0.9794      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.433030179052642e-05, Accuracy: 98.46464646464646%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9754    0.9953    0.9852      1274\n",
      "           1     0.9949    0.9734    0.9840      1201\n",
      "\n",
      "    accuracy                         0.9846      2475\n",
      "   macro avg     0.9851    0.9843    0.9846      2475\n",
      "weighted avg     0.9849    0.9846    0.9846      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001326776303426184, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9961    0.9802      1293\n",
      "           1     0.9956    0.9602    0.9776      1182\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9802    0.9782    0.9789      2475\n",
      "weighted avg     0.9795    0.9790    0.9790      2475\n",
      "\n",
      "created model_classifier_config_20.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.728026811522667e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9912    0.9791      1255\n",
      "           1     0.9907    0.9656    0.9780      1220\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9790    0.9784    0.9786      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012463709320684877, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.9856    0.9719      1315\n",
      "           1     0.9831    0.9517    0.9671      1160\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9708    0.9686    0.9695      2475\n",
      "weighted avg     0.9701    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010834536167106244, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9920    0.9806      1246\n",
      "           1     0.9917    0.9683    0.9798      1229\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9805    0.9801    0.9802      2475\n",
      "weighted avg     0.9805    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001427177618248294, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9602    0.9913    0.9755      1267\n",
      "           1     0.9906    0.9570    0.9735      1208\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9754    0.9741    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001379121072364576, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9635    0.9916    0.9774      1306\n",
      "           1     0.9903    0.9581    0.9739      1169\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9769    0.9748    0.9756      2475\n",
      "weighted avg     0.9762    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.865404379488241e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9691    0.9908    0.9798      1298\n",
      "           1     0.9895    0.9652    0.9772      1177\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9793    0.9780    0.9785      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012043734993597474, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9715    0.9890    0.9801      1273\n",
      "           1     0.9881    0.9692    0.9786      1202\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9798    0.9791    0.9794      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010204826039497298, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9914    0.9792      1282\n",
      "           1     0.9905    0.9640    0.9771      1193\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9789    0.9777    0.9781      2475\n",
      "weighted avg     0.9785    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010917633771896362, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9589    0.9962    0.9772      1313\n",
      "           1     0.9955    0.9518    0.9732      1162\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9772    0.9740    0.9752      2475\n",
      "weighted avg     0.9761    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011731127897898357, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9878    0.9785      1315\n",
      "           1     0.9859    0.9647    0.9752      1160\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9777    0.9762    0.9768      2475\n",
      "weighted avg     0.9771    0.9770    0.9770      2475\n",
      "\n",
      "created model_classifier_config_21.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010716995506575614, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9610    0.9947    0.9776      1314\n",
      "           1     0.9937    0.9543    0.9736      1161\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9774    0.9745    0.9756      2475\n",
      "weighted avg     0.9764    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001229757070541382, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.9892    0.9727      1295\n",
      "           1     0.9877    0.9508    0.9689      1180\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9722    0.9700    0.9708      2475\n",
      "weighted avg     0.9715    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011286703023043545, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9775    0.9864    0.9819      1320\n",
      "           1     0.9843    0.9740    0.9791      1155\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9809    0.9802    0.9805      2475\n",
      "weighted avg     0.9806    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013178908764713943, Accuracy: 96.52525252525253%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9445    0.9915    0.9674      1288\n",
      "           1     0.9902    0.9368    0.9628      1187\n",
      "\n",
      "    accuracy                         0.9653      2475\n",
      "   macro avg     0.9674    0.9641    0.9651      2475\n",
      "weighted avg     0.9664    0.9653    0.9652      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011241112995629359, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9551    0.9939    0.9741      1305\n",
      "           1     0.9928    0.9479    0.9698      1170\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9740    0.9709    0.9720      2475\n",
      "weighted avg     0.9729    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011047704352272882, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9527    0.9944    0.9731      1257\n",
      "           1     0.9940    0.9491    0.9710      1218\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9734    0.9718    0.9721      2475\n",
      "weighted avg     0.9730    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010005559584107062, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9645    0.9913    0.9777      1261\n",
      "           1     0.9907    0.9621    0.9762      1214\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9776    0.9767    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001133476242874608, Accuracy: 98.18181818181819%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9721    0.9938    0.9828      1297\n",
      "           1     0.9930    0.9686    0.9807      1178\n",
      "\n",
      "    accuracy                         0.9818      2475\n",
      "   macro avg     0.9826    0.9812    0.9818      2475\n",
      "weighted avg     0.9821    0.9818    0.9818      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012340894853225863, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.9899    0.9758      1284\n",
      "           1     0.9887    0.9580    0.9731      1191\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9754    0.9739    0.9745      2475\n",
      "weighted avg     0.9749    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010340867620525939, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.9896    0.9744      1249\n",
      "           1     0.9890    0.9576    0.9731      1226\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9743    0.9736    0.9737      2475\n",
      "weighted avg     0.9742    0.9737    0.9737      2475\n",
      "\n",
      "created model_classifier_config_22.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010638745445193666, Accuracy: 98.22222222222223%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9737    0.9931    0.9833      1306\n",
      "           1     0.9921    0.9701    0.9810      1169\n",
      "\n",
      "    accuracy                         0.9822      2475\n",
      "   macro avg     0.9829    0.9816    0.9821      2475\n",
      "weighted avg     0.9824    0.9822    0.9822      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001407535539733039, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9961    0.9759      1279\n",
      "           1     0.9956    0.9515    0.9731      1196\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9760    0.9738    0.9745      2475\n",
      "weighted avg     0.9754    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011105626520484385, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9709    0.9899    0.9803      1283\n",
      "           1     0.9889    0.9681    0.9784      1192\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9799    0.9790    0.9793      2475\n",
      "weighted avg     0.9796    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012689009158298222, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9939    0.9773      1302\n",
      "           1     0.9929    0.9557    0.9739      1173\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9771    0.9748    0.9756      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012112898959053888, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9876    0.9782      1292\n",
      "           1     0.9862    0.9653    0.9757      1183\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9775    0.9765    0.9769      2475\n",
      "weighted avg     0.9771    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.670250343553948e-05, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9706    0.9897    0.9801      1268\n",
      "           1     0.9890    0.9685    0.9787      1207\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9798    0.9791    0.9794      2475\n",
      "weighted avg     0.9796    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001150182190567556, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9558    0.9921    0.9736      1265\n",
      "           1     0.9914    0.9521    0.9713      1210\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9736    0.9721    0.9725      2475\n",
      "weighted avg     0.9732    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011338999175062083, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9666    0.9924    0.9793      1313\n",
      "           1     0.9911    0.9613    0.9760      1162\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9789    0.9768    0.9777      2475\n",
      "weighted avg     0.9781    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001532887810408467, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.9887    0.9754      1325\n",
      "           1     0.9865    0.9557    0.9708      1150\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9745    0.9722    0.9731      2475\n",
      "weighted avg     0.9737    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012030217081609399, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9477    0.9951    0.9708      1237\n",
      "           1     0.9949    0.9451    0.9693      1238\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9713    0.9701    0.9701      2475\n",
      "weighted avg     0.9713    0.9701    0.9701      2475\n",
      "\n",
      "created model_classifier_config_23.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012337069619785656, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9497    0.9922    0.9705      1275\n",
      "           1     0.9913    0.9442    0.9671      1200\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9705    0.9682    0.9688      2475\n",
      "weighted avg     0.9698    0.9689    0.9689      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014384152612300835, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9500    0.9944    0.9717      1261\n",
      "           1     0.9939    0.9456    0.9692      1214\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9720    0.9700    0.9705      2475\n",
      "weighted avg     0.9716    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000130858990279111, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9888    0.9741      1255\n",
      "           1     0.9882    0.9574    0.9725      1220\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9740    0.9731    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011525595428967717, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9631    0.9930    0.9778      1288\n",
      "           1     0.9922    0.9587    0.9751      1187\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9776    0.9759    0.9765      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012752753315549908, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9934    0.9793      1358\n",
      "           1     0.9917    0.9570    0.9740      1117\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9786    0.9752    0.9767      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001283577475884948, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9915    0.9801      1289\n",
      "           1     0.9905    0.9654    0.9778      1186\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9797    0.9784    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010984707360315804, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.9936    0.9743      1257\n",
      "           1     0.9932    0.9524    0.9723      1218\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9744    0.9730    0.9733      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001299553597816313, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9947    0.9798      1318\n",
      "           1     0.9937    0.9594    0.9763      1157\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9796    0.9770    0.9780      2475\n",
      "weighted avg     0.9786    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.683418384706132e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9923    0.9809      1296\n",
      "           1     0.9913    0.9661    0.9785      1179\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9806    0.9792    0.9797      2475\n",
      "weighted avg     0.9801    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012344932917392616, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9482    0.9914    0.9693      1273\n",
      "           1     0.9904    0.9426    0.9659      1202\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9693    0.9670    0.9676      2475\n",
      "weighted avg     0.9687    0.9677    0.9676      2475\n",
      "\n",
      "created model_classifier_config_24.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001253327185457403, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9605    0.9900    0.9750      1301\n",
      "           1     0.9885    0.9549    0.9714      1174\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9745    0.9724    0.9732      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011258865245664962, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9900    0.9764      1295\n",
      "           1     0.9886    0.9585    0.9733      1180\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9742    0.9749      2475\n",
      "weighted avg     0.9753    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010451027540245441, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9717    0.9916    0.9815      1314\n",
      "           1     0.9903    0.9673    0.9786      1161\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9810    0.9794    0.9801      2475\n",
      "weighted avg     0.9804    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.600527057744036e-05, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9617    0.9921    0.9766      1264\n",
      "           1     0.9915    0.9587    0.9748      1211\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9766    0.9754    0.9757      2475\n",
      "weighted avg     0.9762    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013511033371241407, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9635    0.9908    0.9770      1305\n",
      "           1     0.9894    0.9581    0.9735      1170\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9764    0.9745    0.9752      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.819243291411737e-05, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9891    0.9750      1282\n",
      "           1     0.9879    0.9573    0.9723      1193\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9746    0.9732    0.9737      2475\n",
      "weighted avg     0.9741    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001280297835667928, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9968    0.9782      1263\n",
      "           1     0.9966    0.9571    0.9764      1212\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9784    0.9770    0.9773      2475\n",
      "weighted avg     0.9781    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001077436317097057, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9928    0.9772      1250\n",
      "           1     0.9924    0.9600    0.9759      1225\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9772    0.9764    0.9765      2475\n",
      "weighted avg     0.9771    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012250067308695628, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9900    0.9768      1299\n",
      "           1     0.9886    0.9592    0.9737      1176\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9763    0.9746    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.400064897055578e-05, Accuracy: 98.66666666666667%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9802    0.9946    0.9874      1297\n",
      "           1     0.9940    0.9779    0.9859      1178\n",
      "\n",
      "    accuracy                         0.9867      2475\n",
      "   macro avg     0.9871    0.9863    0.9866      2475\n",
      "weighted avg     0.9868    0.9867    0.9867      2475\n",
      "\n",
      "created model_classifier_config_25.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012670650927707402, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.9847    0.9699      1310\n",
      "           1     0.9822    0.9485    0.9651      1165\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9689    0.9666    0.9675      2475\n",
      "weighted avg     0.9681    0.9677    0.9676      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010055221391446662, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9658    0.9948    0.9801      1335\n",
      "           1     0.9936    0.9588    0.9759      1140\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9797    0.9768    0.9780      2475\n",
      "weighted avg     0.9786    0.9782    0.9781      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.550666417738403e-05, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9718    0.9891    0.9804      1290\n",
      "           1     0.9880    0.9688    0.9783      1185\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9799    0.9790    0.9793      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010603421565258141, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9612    0.9929    0.9768      1274\n",
      "           1     0.9922    0.9575    0.9746      1201\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9767    0.9752    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010524508025911119, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9665    0.9906    0.9784      1281\n",
      "           1     0.9897    0.9631    0.9762      1194\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9781    0.9769    0.9773      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011534957271633726, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9666    0.9939    0.9801      1311\n",
      "           1     0.9929    0.9613    0.9769      1164\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9798    0.9776    0.9785      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010069282066942466, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9944    0.9781      1258\n",
      "           1     0.9940    0.9597    0.9766      1217\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9782    0.9771    0.9773      2475\n",
      "weighted avg     0.9779    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010827963099335179, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9663    0.9829    0.9745      1284\n",
      "           1     0.9812    0.9631    0.9720      1191\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9737    0.9730    0.9733      2475\n",
      "weighted avg     0.9735    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001195371783140934, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9882    0.9763      1274\n",
      "           1     0.9872    0.9617    0.9743      1201\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9760    0.9750    0.9753      2475\n",
      "weighted avg     0.9756    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013988210095299615, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9542    0.9984    0.9758      1253\n",
      "           1     0.9983    0.9509    0.9740      1222\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9763    0.9747    0.9749      2475\n",
      "weighted avg     0.9760    0.9749    0.9749      2475\n",
      "\n",
      "created model_classifier_config_26.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012244941008211386, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9523    0.9940    0.9727      1327\n",
      "           1     0.9927    0.9425    0.9669      1148\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9725    0.9682    0.9698      2475\n",
      "weighted avg     0.9710    0.9701    0.9700      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011563426015352962, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9891    0.9784      1285\n",
      "           1     0.9880    0.9647    0.9762      1190\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9780    0.9769    0.9773      2475\n",
      "weighted avg     0.9776    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011285136745433614, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.9929    0.9741      1268\n",
      "           1     0.9922    0.9519    0.9717      1207\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9741    0.9724    0.9729      2475\n",
      "weighted avg     0.9736    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011470086345768938, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9635    0.9922    0.9776      1277\n",
      "           1     0.9914    0.9599    0.9754      1198\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9774    0.9761    0.9765      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013014398138932507, Accuracy: 96.52525252525253%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9434    0.9913    0.9667      1261\n",
      "           1     0.9904    0.9382    0.9636      1214\n",
      "\n",
      "    accuracy                         0.9653      2475\n",
      "   macro avg     0.9669    0.9647    0.9652      2475\n",
      "weighted avg     0.9665    0.9653    0.9652      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011090834634472626, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9682    0.9961    0.9820      1285\n",
      "           1     0.9957    0.9647    0.9799      1190\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9819    0.9804    0.9810      2475\n",
      "weighted avg     0.9814    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001395112516904118, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9926    0.9795      1351\n",
      "           1     0.9908    0.9591    0.9747      1124\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9788    0.9758    0.9771      2475\n",
      "weighted avg     0.9777    0.9774    0.9773      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010881252361066413, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9696    0.9889    0.9792      1259\n",
      "           1     0.9882    0.9679    0.9780      1216\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9789    0.9784    0.9786      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001249319856817072, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9940    0.9773      1324\n",
      "           1     0.9928    0.9540    0.9730      1151\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9770    0.9740    0.9752      2475\n",
      "weighted avg     0.9759    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014225973324342208, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9675    0.9895    0.9783      1233\n",
      "           1     0.9893    0.9670    0.9780      1242\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9784    0.9782    0.9782      2475\n",
      "weighted avg     0.9784    0.9782    0.9782      2475\n",
      "\n",
      "created model_classifier_config_27.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.933217607363305e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9962    0.9793      1327\n",
      "           1     0.9955    0.9556    0.9751      1148\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9792    0.9759    0.9772      2475\n",
      "weighted avg     0.9780    0.9774    0.9773      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014371281019364944, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9913    0.9744      1266\n",
      "           1     0.9906    0.9545    0.9722      1209\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9743    0.9729    0.9733      2475\n",
      "weighted avg     0.9739    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011051301402275009, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9686    0.9872    0.9778      1250\n",
      "           1     0.9867    0.9673    0.9769      1225\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9776    0.9773    0.9774      2475\n",
      "weighted avg     0.9775    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012808938821156818, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9705    0.9892    0.9798      1299\n",
      "           1     0.9878    0.9668    0.9772      1176\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9792    0.9780    0.9785      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014244925494145865, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9955    0.9789      1330\n",
      "           1     0.9945    0.9555    0.9746      1145\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9787    0.9755    0.9768      2475\n",
      "weighted avg     0.9775    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010477983590328333, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9572    0.9938    0.9751      1283\n",
      "           1     0.9930    0.9522    0.9722      1192\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9751    0.9730    0.9737      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012226609870640917, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9880    0.9774      1248\n",
      "           1     0.9875    0.9658    0.9765      1227\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9773    0.9769    0.9770      2475\n",
      "weighted avg     0.9772    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011632378655250626, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9617    0.9887    0.9750      1322\n",
      "           1     0.9866    0.9549    0.9705      1153\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9741    0.9718    0.9727      2475\n",
      "weighted avg     0.9733    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001092724155898046, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9952    0.9785      1259\n",
      "           1     0.9949    0.9597    0.9770      1216\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9786    0.9775    0.9778      2475\n",
      "weighted avg     0.9783    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011484981787325156, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9574    0.9961    0.9764      1286\n",
      "           1     0.9956    0.9521    0.9733      1189\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9765    0.9741    0.9749      2475\n",
      "weighted avg     0.9758    0.9749    0.9749      2475\n",
      "\n",
      "created model_classifier_config_28.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011985142423649027, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9687    0.9916    0.9800      1309\n",
      "           1     0.9903    0.9640    0.9770      1166\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9795    0.9778    0.9785      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014061210131404374, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9521    0.9922    0.9718      1283\n",
      "           1     0.9912    0.9463    0.9682      1192\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9717    0.9693    0.9700      2475\n",
      "weighted avg     0.9710    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011115160554346412, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9907    0.9802      1297\n",
      "           1     0.9896    0.9660    0.9777      1178\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9797    0.9784    0.9789      2475\n",
      "weighted avg     0.9792    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001333117966700082, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9555    0.9870    0.9710      1304\n",
      "           1     0.9849    0.9488    0.9665      1171\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9702    0.9679    0.9687      2475\n",
      "weighted avg     0.9694    0.9689    0.9689      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014308672962766705, Accuracy: 96.8080808080808%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9443    0.9943    0.9686      1227\n",
      "           1     0.9941    0.9423    0.9675      1248\n",
      "\n",
      "    accuracy                         0.9681      2475\n",
      "   macro avg     0.9692    0.9683    0.9681      2475\n",
      "weighted avg     0.9694    0.9681    0.9681      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.49060826590567e-05, Accuracy: 98.26262626262626%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9743    0.9931    0.9836      1296\n",
      "           1     0.9922    0.9712    0.9816      1179\n",
      "\n",
      "    accuracy                         0.9826      2475\n",
      "   macro avg     0.9832    0.9821    0.9826      2475\n",
      "weighted avg     0.9828    0.9826    0.9826      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.706388218234284e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9878    0.9800      1312\n",
      "           1     0.9860    0.9682    0.9770      1163\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9791    0.9780    0.9785      2475\n",
      "weighted avg     0.9787    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011814087027251118, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9664    0.9898    0.9779      1277\n",
      "           1     0.9889    0.9633    0.9759      1198\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9776    0.9765    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010780969051399616, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9718    0.9914    0.9815      1286\n",
      "           1     0.9905    0.9689    0.9796      1189\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9812    0.9802    0.9806      2475\n",
      "weighted avg     0.9808    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010341930570024433, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.9945    0.9777      1279\n",
      "           1     0.9939    0.9574    0.9753      1196\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9777    0.9759    0.9765      2475\n",
      "weighted avg     0.9771    0.9766    0.9765      2475\n",
      "\n",
      "created model_classifier_config_29.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011732030697543212, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9610    0.9907    0.9756      1292\n",
      "           1     0.9895    0.9560    0.9725      1183\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9752    0.9734    0.9740      2475\n",
      "weighted avg     0.9746    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014567713845859873, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9517    0.9961    0.9734      1286\n",
      "           1     0.9956    0.9453    0.9698      1189\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9736    0.9707    0.9716      2475\n",
      "weighted avg     0.9728    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013143870264592796, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9730    0.9867    0.9798      1280\n",
      "           1     0.9856    0.9707    0.9781      1195\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9793    0.9787    0.9790      2475\n",
      "weighted avg     0.9791    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010517571911667332, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9712    0.9899    0.9805      1293\n",
      "           1     0.9888    0.9679    0.9782      1182\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9800    0.9789    0.9793      2475\n",
      "weighted avg     0.9796    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013361464847217906, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9468    0.9952    0.9704      1251\n",
      "           1     0.9948    0.9428    0.9681      1224\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9708    0.9690    0.9693      2475\n",
      "weighted avg     0.9705    0.9693    0.9693      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012232799421657214, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9633    0.9907    0.9768      1297\n",
      "           1     0.9895    0.9584    0.9737      1178\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9764    0.9746    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011353510798829974, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9703    0.9915    0.9808      1287\n",
      "           1     0.9905    0.9672    0.9787      1188\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9804    0.9793    0.9797      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011283005126798996, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9876    0.9754      1286\n",
      "           1     0.9862    0.9596    0.9727      1189\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9749    0.9736    0.9741      2475\n",
      "weighted avg     0.9744    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013444329452032996, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.9952    0.9753      1252\n",
      "           1     0.9949    0.9534    0.9737      1223\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9756    0.9743    0.9745      2475\n",
      "weighted avg     0.9753    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013529699258130006, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9544    0.9941    0.9738      1346\n",
      "           1     0.9925    0.9433    0.9673      1129\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9734    0.9687    0.9706      2475\n",
      "weighted avg     0.9718    0.9709    0.9708      2475\n",
      "\n",
      "created model_classifier_config_30.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010828113616114914, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9898    0.9776      1278\n",
      "           1     0.9888    0.9624    0.9754      1197\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9772    0.9761    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010036662371471675, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.9897    0.9754      1263\n",
      "           1     0.9889    0.9587    0.9736      1212\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9752    0.9742    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001254176672058876, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9893    0.9744      1309\n",
      "           1     0.9876    0.9537    0.9703      1166\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9738    0.9715    0.9724      2475\n",
      "weighted avg     0.9730    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012469425044878563, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.9938    0.9801      1286\n",
      "           1     0.9931    0.9630    0.9778      1189\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9799    0.9784    0.9789      2475\n",
      "weighted avg     0.9794    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012188090218438043, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.9914    0.9765      1281\n",
      "           1     0.9905    0.9581    0.9740      1194\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9763    0.9748    0.9753      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.48698352081607e-05, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9555    0.9923    0.9736      1299\n",
      "           1     0.9911    0.9490    0.9696      1176\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9733    0.9706    0.9716      2475\n",
      "weighted avg     0.9724    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014431673167931912, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.9946    0.9753      1288\n",
      "           1     0.9938    0.9511    0.9720      1187\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9753    0.9729    0.9736      2475\n",
      "weighted avg     0.9745    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011395989042339903, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9650    0.9901    0.9774      1310\n",
      "           1     0.9885    0.9597    0.9739      1165\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9768    0.9749    0.9756      2475\n",
      "weighted avg     0.9761    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013494812779956395, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9937    0.9784      1277\n",
      "           1     0.9931    0.9599    0.9762      1198\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9783    0.9768    0.9773      2475\n",
      "weighted avg     0.9779    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012120300772214177, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9550    0.9945    0.9743      1279\n",
      "           1     0.9939    0.9498    0.9714      1196\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9744    0.9722    0.9728      2475\n",
      "weighted avg     0.9738    0.9729    0.9729      2475\n",
      "\n",
      "created model_classifier_config_31.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013131161229779022, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9897    0.9759      1266\n",
      "           1     0.9889    0.9595    0.9740      1209\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9756    0.9746    0.9749      2475\n",
      "weighted avg     0.9753    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.627796784795896e-05, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9602    0.9856    0.9728      1250\n",
      "           1     0.9849    0.9584    0.9715      1225\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9726    0.9720    0.9721      2475\n",
      "weighted avg     0.9724    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011031707729956117, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9554    0.9921    0.9734      1273\n",
      "           1     0.9913    0.9509    0.9707      1202\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9733    0.9715    0.9721      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011701723842909841, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9733    0.9907    0.9819      1290\n",
      "           1     0.9897    0.9705    0.9800      1185\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9815    0.9806    0.9810      2475\n",
      "weighted avg     0.9812    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010748035979993416, Accuracy: 98.3030303030303%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9738    0.9937    0.9837      1274\n",
      "           1     0.9932    0.9717    0.9823      1201\n",
      "\n",
      "    accuracy                         0.9830      2475\n",
      "   macro avg     0.9835    0.9827    0.9830      2475\n",
      "weighted avg     0.9832    0.9830    0.9830      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010713836159368958, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9529    0.9897    0.9710      1267\n",
      "           1     0.9888    0.9487    0.9683      1208\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9708    0.9692    0.9696      2475\n",
      "weighted avg     0.9704    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012077522398245455, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9931    0.9799      1302\n",
      "           1     0.9921    0.9625    0.9771      1173\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9796    0.9778    0.9785      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001341981448308386, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9704    0.9839    0.9771      1301\n",
      "           1     0.9818    0.9668    0.9742      1174\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9761    0.9753    0.9757      2475\n",
      "weighted avg     0.9758    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010816163486904568, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9962    0.9820      1318\n",
      "           1     0.9955    0.9628    0.9789      1157\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9819    0.9795    0.9805      2475\n",
      "weighted avg     0.9810    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011017556744392472, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9755    0.9895    0.9824      1329\n",
      "           1     0.9876    0.9712    0.9793      1146\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9815    0.9803    0.9809      2475\n",
      "weighted avg     0.9811    0.9810    0.9810      2475\n",
      "\n",
      "created model_classifier_config_32.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010811249716113311, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9887    0.9766      1327\n",
      "           1     0.9865    0.9582    0.9722      1148\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9756    0.9734    0.9744      2475\n",
      "weighted avg     0.9748    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010319105302444612, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9713    0.9870    0.9791      1305\n",
      "           1     0.9852    0.9675    0.9763      1170\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9783    0.9772    0.9777      2475\n",
      "weighted avg     0.9779    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010278220128531408, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9675    0.9884    0.9778      1295\n",
      "           1     0.9870    0.9636    0.9751      1180\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9772    0.9760    0.9765      2475\n",
      "weighted avg     0.9768    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013008431653783778, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9584    0.9906    0.9743      1280\n",
      "           1     0.9896    0.9540    0.9715      1195\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9740    0.9723    0.9729      2475\n",
      "weighted avg     0.9735    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010376767678694292, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9720    0.9905    0.9812      1263\n",
      "           1     0.9899    0.9703    0.9800      1212\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9810    0.9804    0.9806      2475\n",
      "weighted avg     0.9808    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001252971153066616, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9521    0.9914    0.9714      1284\n",
      "           1     0.9903    0.9463    0.9678      1191\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9712    0.9688    0.9696      2475\n",
      "weighted avg     0.9705    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010485783971921363, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9670    0.9945    0.9806      1269\n",
      "           1     0.9940    0.9643    0.9790      1206\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9805    0.9794    0.9798      2475\n",
      "weighted avg     0.9802    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013539760100721109, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9512    0.9947    0.9725      1332\n",
      "           1     0.9935    0.9405    0.9663      1143\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9724    0.9676    0.9694      2475\n",
      "weighted avg     0.9707    0.9697    0.9696      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001013239977335689, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9687    0.9928    0.9806      1246\n",
      "           1     0.9925    0.9675    0.9798      1229\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9806    0.9801    0.9802      2475\n",
      "weighted avg     0.9805    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001308131278163255, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9568    0.9953    0.9757      1269\n",
      "           1     0.9948    0.9527    0.9733      1206\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9758    0.9740    0.9745      2475\n",
      "weighted avg     0.9753    0.9745    0.9745      2475\n",
      "\n",
      "created model_classifier_config_33.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010283469551741475, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9710    0.9916    0.9812      1316\n",
      "           1     0.9903    0.9664    0.9782      1159\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9806    0.9790    0.9797      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011418482570937185, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9631    0.9899    0.9764      1293\n",
      "           1     0.9887    0.9585    0.9734      1182\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9742    0.9749      2475\n",
      "weighted avg     0.9753    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012089472828489361, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9686    0.9939    0.9811      1303\n",
      "           1     0.9930    0.9642    0.9784      1172\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9808    0.9790    0.9797      2475\n",
      "weighted avg     0.9801    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010504503141749989, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9602    0.9937    0.9766      1262\n",
      "           1     0.9932    0.9571    0.9748      1213\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9767    0.9754    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014651597148240215, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9512    0.9961    0.9731      1291\n",
      "           1     0.9955    0.9443    0.9692      1184\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9734    0.9702    0.9712      2475\n",
      "weighted avg     0.9724    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010868372038157299, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9653    0.9894    0.9772      1320\n",
      "           1     0.9875    0.9593    0.9732      1155\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9764    0.9744    0.9752      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011653790570268727, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.9927    0.9740      1226\n",
      "           1     0.9925    0.9552    0.9735      1249\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9743    0.9739    0.9737      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010477457985733494, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.9869    0.9724      1302\n",
      "           1     0.9850    0.9523    0.9684      1173\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9716    0.9696    0.9704      2475\n",
      "weighted avg     0.9709    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010001422780932802, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9653    0.9915    0.9782      1292\n",
      "           1     0.9904    0.9611    0.9755      1183\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9779    0.9763    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011664947476049867, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9521    0.9905    0.9709      1265\n",
      "           1     0.9896    0.9479    0.9683      1210\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9709    0.9692    0.9696      2475\n",
      "weighted avg     0.9705    0.9697    0.9697      2475\n",
      "\n",
      "created model_classifier_config_34.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010512270409651476, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9725    0.9922    0.9822      1282\n",
      "           1     0.9914    0.9698    0.9805      1193\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9820    0.9810    0.9814      2475\n",
      "weighted avg     0.9816    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013347648008905276, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9595    0.9953    0.9771      1284\n",
      "           1     0.9948    0.9547    0.9743      1191\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9771    0.9750    0.9757      2475\n",
      "weighted avg     0.9764    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010140950029546564, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9899    0.9763      1288\n",
      "           1     0.9887    0.9587    0.9735      1187\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9758    0.9743    0.9749      2475\n",
      "weighted avg     0.9753    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001173166132936574, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9865    0.9719      1262\n",
      "           1     0.9855    0.9547    0.9698      1213\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9716    0.9706    0.9709      2475\n",
      "weighted avg     0.9713    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011465163845004458, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9588    0.9886    0.9735      1225\n",
      "           1     0.9884    0.9584    0.9732      1250\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9736    0.9735    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011909894870989251, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9947    0.9772      1314\n",
      "           1     0.9937    0.9535    0.9732      1161\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9770    0.9741    0.9752      2475\n",
      "weighted avg     0.9760    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011213009104584202, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9924    0.9780      1321\n",
      "           1     0.9910    0.9575    0.9740      1154\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9775    0.9750    0.9760      2475\n",
      "weighted avg     0.9766    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013204141397668857, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9527    0.9961    0.9740      1295\n",
      "           1     0.9955    0.9458    0.9700      1180\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9741    0.9710    0.9720      2475\n",
      "weighted avg     0.9731    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012273687304872454, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9703    0.9894    0.9798      1321\n",
      "           1     0.9876    0.9653    0.9763      1154\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9789    0.9774    0.9780      2475\n",
      "weighted avg     0.9784    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013488842682404952, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.9937    0.9743      1278\n",
      "           1     0.9930    0.9507    0.9714      1197\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9743    0.9722    0.9729      2475\n",
      "weighted avg     0.9737    0.9729    0.9729      2475\n",
      "\n",
      "created model_classifier_config_35.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014166806382362289, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9916    0.9756      1308\n",
      "           1     0.9902    0.9537    0.9716      1167\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9751    0.9727    0.9736      2475\n",
      "weighted avg     0.9743    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001146896258749143, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9642    0.9939    0.9788      1301\n",
      "           1     0.9929    0.9591    0.9757      1174\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9786    0.9765    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9773      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012212494106003734, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9522    0.9930    0.9722      1284\n",
      "           1     0.9921    0.9463    0.9686      1191\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9721    0.9696    0.9704      2475\n",
      "weighted avg     0.9714    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011777924768852465, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9891    0.9789      1288\n",
      "           1     0.9879    0.9655    0.9766      1187\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9784    0.9773    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012352980146504411, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9748    0.9892    0.9819      1291\n",
      "           1     0.9880    0.9721    0.9800      1184\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9814    0.9806    0.9810      2475\n",
      "weighted avg     0.9811    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012321026638300732, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9961    0.9765      1295\n",
      "           1     0.9956    0.9517    0.9731      1180\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9766    0.9739    0.9748      2475\n",
      "weighted avg     0.9757    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010131741412962326, Accuracy: 98.46464646464646%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9823    0.9884    0.9853      1290\n",
      "           1     0.9873    0.9806    0.9839      1185\n",
      "\n",
      "    accuracy                         0.9846      2475\n",
      "   macro avg     0.9848    0.9845    0.9846      2475\n",
      "weighted avg     0.9847    0.9846    0.9846      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011841410037243005, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.9889    0.9735      1263\n",
      "           1     0.9881    0.9554    0.9715      1212\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9733    0.9722    0.9725      2475\n",
      "weighted avg     0.9730    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011478092935350206, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9507    0.9891    0.9695      1286\n",
      "           1     0.9877    0.9445    0.9656      1189\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9692    0.9668    0.9676      2475\n",
      "weighted avg     0.9685    0.9677    0.9676      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010335673888524374, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9558    0.9929    0.9740      1264\n",
      "           1     0.9923    0.9521    0.9718      1211\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9740    0.9725    0.9729      2475\n",
      "weighted avg     0.9737    0.9729    0.9729      2475\n",
      "\n",
      "created model_classifier_config_36.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011397662487897005, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.9881    0.9719      1261\n",
      "           1     0.9872    0.9530    0.9698      1214\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9717    0.9706    0.9709      2475\n",
      "weighted avg     0.9714    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010023582764346191, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9655    0.9960    0.9805      1265\n",
      "           1     0.9957    0.9628    0.9790      1210\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9806    0.9794    0.9798      2475\n",
      "weighted avg     0.9803    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012160494171007716, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9948    0.9819      1339\n",
      "           1     0.9936    0.9630    0.9781      1136\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9815    0.9789    0.9800      2475\n",
      "weighted avg     0.9805    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011579222751386238, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9922    0.9796      1283\n",
      "           1     0.9914    0.9639    0.9775      1192\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9793    0.9781    0.9785      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010221854905889492, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9555    0.9891    0.9720      1280\n",
      "           1     0.9878    0.9506    0.9689      1195\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9716    0.9698    0.9704      2475\n",
      "weighted avg     0.9711    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011778057524652193, Accuracy: 96.84848484848484%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9477    0.9937    0.9702      1276\n",
      "           1     0.9930    0.9416    0.9666      1199\n",
      "\n",
      "    accuracy                         0.9685      2475\n",
      "   macro avg     0.9703    0.9677    0.9684      2475\n",
      "weighted avg     0.9696    0.9685    0.9684      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011130553604376437, Accuracy: 98.18181818181819%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9724    0.9930    0.9826      1278\n",
      "           1     0.9923    0.9699    0.9810      1197\n",
      "\n",
      "    accuracy                         0.9818      2475\n",
      "   macro avg     0.9824    0.9814    0.9818      2475\n",
      "weighted avg     0.9820    0.9818    0.9818      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001078641926399385, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9884    0.9785      1292\n",
      "           1     0.9870    0.9653    0.9761      1183\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9780    0.9769    0.9773      2475\n",
      "weighted avg     0.9776    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001393677881269744, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9921    0.9786      1267\n",
      "           1     0.9915    0.9627    0.9769      1208\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9774    0.9777      2475\n",
      "weighted avg     0.9781    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012449213952729196, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.9902    0.9763      1329\n",
      "           1     0.9883    0.9555    0.9716      1146\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9755    0.9729    0.9739      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "created model_classifier_config_37.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00015895096942631886, Accuracy: 96.44444444444444%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9396    0.9945    0.9662      1266\n",
      "           1     0.9938    0.9330    0.9625      1209\n",
      "\n",
      "    accuracy                         0.9644      2475\n",
      "   macro avg     0.9667    0.9637    0.9643      2475\n",
      "weighted avg     0.9661    0.9644    0.9644      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010352121158079668, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9611    0.9946    0.9775      1291\n",
      "           1     0.9939    0.9561    0.9746      1184\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9775    0.9753    0.9761      2475\n",
      "weighted avg     0.9768    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001250416883314499, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9872    0.9736      1324\n",
      "           1     0.9847    0.9531    0.9687      1151\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9725    0.9701    0.9711      2475\n",
      "weighted avg     0.9717    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010856330996811992, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.9894    0.9779      1321\n",
      "           1     0.9875    0.9610    0.9741      1154\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9771    0.9752    0.9760      2475\n",
      "weighted avg     0.9764    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001259174882763564, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9937    0.9746      1273\n",
      "           1     0.9931    0.9517    0.9720      1202\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9746    0.9727    0.9733      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011197884576489228, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9682    0.9889    0.9784      1261\n",
      "           1     0.9882    0.9662    0.9771      1214\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9782    0.9776    0.9778      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010176941902950556, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9931    0.9813      1295\n",
      "           1     0.9922    0.9661    0.9790      1180\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9810    0.9796    0.9801      2475\n",
      "weighted avg     0.9805    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001454399631480978, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9954    0.9772      1293\n",
      "           1     0.9947    0.9543    0.9741      1182\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9772    0.9748    0.9757      2475\n",
      "weighted avg     0.9764    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011414343058460891, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9660    0.9889    0.9773      1265\n",
      "           1     0.9881    0.9636    0.9757      1210\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9771    0.9763    0.9765      2475\n",
      "weighted avg     0.9768    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001047750073249894, Accuracy: 98.18181818181819%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9725    0.9930    0.9826      1281\n",
      "           1     0.9923    0.9698    0.9809      1194\n",
      "\n",
      "    accuracy                         0.9818      2475\n",
      "   macro avg     0.9824    0.9814    0.9818      2475\n",
      "weighted avg     0.9820    0.9818    0.9818      2475\n",
      "\n",
      "created model_classifier_config_38.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012885485634659275, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9908    0.9748      1306\n",
      "           1     0.9893    0.9530    0.9708      1169\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9743    0.9719    0.9728      2475\n",
      "weighted avg     0.9735    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001181077595913049, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9637    0.9899    0.9766      1287\n",
      "           1     0.9887    0.9596    0.9739      1188\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9762    0.9747    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001077586773670081, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9908    0.9788      1305\n",
      "           1     0.9895    0.9624    0.9757      1170\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9783    0.9766    0.9773      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011081026660071479, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9605    0.9953    0.9776      1272\n",
      "           1     0.9948    0.9568    0.9754      1203\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9777    0.9760    0.9765      2475\n",
      "weighted avg     0.9772    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001192450463169753, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9715    0.9879    0.9796      1241\n",
      "           1     0.9876    0.9708    0.9792      1234\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9796    0.9794    0.9794      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001323419056757532, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9587    0.9907    0.9744      1288\n",
      "           1     0.9895    0.9537    0.9713      1187\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9741    0.9722    0.9728      2475\n",
      "weighted avg     0.9735    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001242076146482217, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9564    0.9961    0.9758      1277\n",
      "           1     0.9956    0.9516    0.9731      1198\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9760    0.9738    0.9745      2475\n",
      "weighted avg     0.9754    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012367892746973519, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9569    0.9898    0.9731      1278\n",
      "           1     0.9887    0.9524    0.9702      1197\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9728    0.9711    0.9716      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011425535787235607, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9857    0.9773      1332\n",
      "           1     0.9830    0.9633    0.9730      1143\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9760    0.9745    0.9752      2475\n",
      "weighted avg     0.9755    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010377303819463711, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9682    0.9953    0.9816      1284\n",
      "           1     0.9948    0.9647    0.9795      1191\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9815    0.9800    0.9806      2475\n",
      "weighted avg     0.9810    0.9806    0.9806      2475\n",
      "\n",
      "created model_classifier_config_39.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012525435951020981, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9736    0.9881    0.9808      1342\n",
      "           1     0.9856    0.9682    0.9768      1133\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9796    0.9782    0.9788      2475\n",
      "weighted avg     0.9791    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001096102384605793, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9898    0.9748      1272\n",
      "           1     0.9888    0.9568    0.9725      1203\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9746    0.9733    0.9737      2475\n",
      "weighted avg     0.9742    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011074743487618186, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9665    0.9883    0.9773      1283\n",
      "           1     0.9871    0.9631    0.9749      1192\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9768    0.9757    0.9761      2475\n",
      "weighted avg     0.9764    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010392822099454475, Accuracy: 98.26262626262626%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9770    0.9910    0.9839      1328\n",
      "           1     0.9894    0.9730    0.9811      1147\n",
      "\n",
      "    accuracy                         0.9826      2475\n",
      "   macro avg     0.9832    0.9820    0.9825      2475\n",
      "weighted avg     0.9827    0.9826    0.9826      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011135991173561173, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9543    0.9890    0.9713      1268\n",
      "           1     0.9879    0.9503    0.9688      1207\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9711    0.9696    0.9700      2475\n",
      "weighted avg     0.9707    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011160121120587744, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9634    0.9954    0.9791      1296\n",
      "           1     0.9947    0.9584    0.9762      1179\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9791    0.9769    0.9777      2475\n",
      "weighted avg     0.9783    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011677219711168848, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9611    0.9960    0.9783      1265\n",
      "           1     0.9957    0.9579    0.9764      1210\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9784    0.9769    0.9773      2475\n",
      "weighted avg     0.9780    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001355624409637066, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9920    0.9738      1255\n",
      "           1     0.9915    0.9533    0.9720      1220\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9738    0.9727    0.9729      2475\n",
      "weighted avg     0.9736    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011832211956833348, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.9866    0.9744      1273\n",
      "           1     0.9855    0.9592    0.9722      1202\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9740    0.9729    0.9733      2475\n",
      "weighted avg     0.9736    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011197264748390275, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9652    0.9899    0.9774      1288\n",
      "           1     0.9887    0.9612    0.9748      1187\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9770    0.9756    0.9761      2475\n",
      "weighted avg     0.9765    0.9762    0.9761      2475\n",
      "\n",
      "created model_classifier_config_40.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011829045685854825, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9639    0.9932    0.9783      1318\n",
      "           1     0.9919    0.9576    0.9745      1157\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9779    0.9754    0.9764      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001072395991797399, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9916    0.9784      1304\n",
      "           1     0.9903    0.9607    0.9753      1171\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9780    0.9761    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011389444873790548, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9721    0.9847    0.9784      1308\n",
      "           1     0.9826    0.9683    0.9754      1167\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9773    0.9765    0.9769      2475\n",
      "weighted avg     0.9770    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.891454248717337e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9709    0.9916    0.9812      1313\n",
      "           1     0.9903    0.9664    0.9782      1162\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9806    0.9790    0.9797      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011666822313058256, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9725    0.9899    0.9811      1284\n",
      "           1     0.9889    0.9698    0.9792      1191\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9807    0.9798    0.9802      2475\n",
      "weighted avg     0.9804    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001095576478977396, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9651    0.9938    0.9792      1280\n",
      "           1     0.9931    0.9615    0.9770      1195\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9791    0.9776    0.9781      2475\n",
      "weighted avg     0.9786    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011794128502258147, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9501    0.9939    0.9715      1302\n",
      "           1     0.9928    0.9420    0.9668      1173\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9714    0.9679    0.9691      2475\n",
      "weighted avg     0.9703    0.9693    0.9692      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.8192532255192e-05, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9557    0.9868    0.9710      1290\n",
      "           1     0.9851    0.9502    0.9674      1185\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9704    0.9685    0.9692      2475\n",
      "weighted avg     0.9698    0.9693    0.9693      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013196353057418208, Accuracy: 96.84848484848484%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9438    0.9959    0.9692      1232\n",
      "           1     0.9957    0.9413    0.9677      1243\n",
      "\n",
      "    accuracy                         0.9685      2475\n",
      "   macro avg     0.9698    0.9686    0.9685      2475\n",
      "weighted avg     0.9699    0.9685    0.9685      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001085927781432566, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9610    0.9944    0.9774      1239\n",
      "           1     0.9941    0.9595    0.9765      1236\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9776    0.9769    0.9770      2475\n",
      "weighted avg     0.9775    0.9770    0.9770      2475\n",
      "\n",
      "created model_classifier_config_41.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014106296830707126, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9969    0.9792      1296\n",
      "           1     0.9965    0.9567    0.9762      1179\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9792    0.9768    0.9777      2475\n",
      "weighted avg     0.9784    0.9778    0.9777      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.980292262453022e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9706    0.9905    0.9805      1268\n",
      "           1     0.9898    0.9685    0.9791      1207\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9802    0.9795    0.9798      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012970507746995098, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9611    0.9915    0.9761      1296\n",
      "           1     0.9903    0.9559    0.9728      1179\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9757    0.9737    0.9744      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.606488726355812e-05, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9575    0.9954    0.9761      1291\n",
      "           1     0.9947    0.9519    0.9728      1184\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9761    0.9736    0.9744      2475\n",
      "weighted avg     0.9753    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010677696779520825, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9916    0.9770      1308\n",
      "           1     0.9902    0.9572    0.9734      1167\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9766    0.9744    0.9752      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013569137062689271, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9616    0.9939    0.9775      1311\n",
      "           1     0.9929    0.9553    0.9737      1164\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9772    0.9746    0.9756      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.946517571054324e-05, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9631    0.9929    0.9778      1262\n",
      "           1     0.9923    0.9604    0.9761      1213\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9777    0.9766    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013439987343971175, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9558    0.9905    0.9728      1266\n",
      "           1     0.9897    0.9520    0.9705      1209\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9727    0.9713    0.9717      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011032339599397448, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.9876    0.9744      1290\n",
      "           1     0.9861    0.9570    0.9713      1185\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9738    0.9723    0.9728      2475\n",
      "weighted avg     0.9733    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010174287087989576, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9753    0.9852    0.9802      1282\n",
      "           1     0.9839    0.9732    0.9785      1193\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9796    0.9792    0.9794      2475\n",
      "weighted avg     0.9794    0.9794    0.9794      2475\n",
      "\n",
      "created model_classifier_config_42.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011464781833417488, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9930    0.9752      1287\n",
      "           1     0.9921    0.9529    0.9721      1188\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9751    0.9729    0.9736      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011345649006390812, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9887    0.9770      1333\n",
      "           1     0.9865    0.9588    0.9725      1142\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9760    0.9738    0.9747      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011418237228586216, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9914    0.9766      1286\n",
      "           1     0.9904    0.9579    0.9739      1189\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9763    0.9747    0.9753      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001158281046934802, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9646    0.9913    0.9778      1266\n",
      "           1     0.9906    0.9620    0.9761      1209\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9776    0.9766    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012933321372427122, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9642    0.9857    0.9748      1258\n",
      "           1     0.9849    0.9622    0.9734      1217\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9745    0.9739    0.9741      2475\n",
      "weighted avg     0.9744    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014104529763713026, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9915    0.9745      1290\n",
      "           1     0.9904    0.9527    0.9712      1185\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9742    0.9721    0.9728      2475\n",
      "weighted avg     0.9735    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001296801097465284, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9641    0.9867    0.9753      1280\n",
      "           1     0.9854    0.9607    0.9729      1195\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9748    0.9737    0.9741      2475\n",
      "weighted avg     0.9744    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.394909396316066e-05, Accuracy: 98.46464646464646%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9792    0.9914    0.9853      1282\n",
      "           1     0.9907    0.9774    0.9840      1193\n",
      "\n",
      "    accuracy                         0.9846      2475\n",
      "   macro avg     0.9849    0.9844    0.9846      2475\n",
      "weighted avg     0.9847    0.9846    0.9846      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010395733696041685, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9686    0.9946    0.9814      1301\n",
      "           1     0.9939    0.9642    0.9788      1174\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9812    0.9794    0.9801      2475\n",
      "weighted avg     0.9806    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001333779277223529, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9616    0.9930    0.9771      1287\n",
      "           1     0.9921    0.9571    0.9743      1188\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9769    0.9750    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "created model_classifier_config_43.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012986496241405756, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9635    0.9920    0.9775      1249\n",
      "           1     0.9916    0.9617    0.9764      1226\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9775    0.9768    0.9770      2475\n",
      "weighted avg     0.9774    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010073973674966831, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9914    0.9769      1282\n",
      "           1     0.9905    0.9589    0.9744      1193\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9767    0.9752    0.9757      2475\n",
      "weighted avg     0.9762    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001258922977880998, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9676    0.9910    0.9792      1328\n",
      "           1     0.9892    0.9616    0.9752      1147\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9784    0.9763    0.9772      2475\n",
      "weighted avg     0.9777    0.9774    0.9773      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011538215658881448, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9960    0.9765      1250\n",
      "           1     0.9957    0.9551    0.9750      1225\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9767    0.9756    0.9757      2475\n",
      "weighted avg     0.9765    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011787356150270712, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.9909    0.9750      1319\n",
      "           1     0.9892    0.9524    0.9705      1156\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9744    0.9717    0.9727      2475\n",
      "weighted avg     0.9734    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.286436468663842e-05, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9797    0.9820    0.9809      1280\n",
      "           1     0.9807    0.9782    0.9795      1195\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9802    0.9801    0.9802      2475\n",
      "weighted avg     0.9802    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001468638007086937, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9534    0.9915    0.9721      1300\n",
      "           1     0.9902    0.9464    0.9678      1175\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9718    0.9690    0.9699      2475\n",
      "weighted avg     0.9709    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011920884402111323, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9488    0.9944    0.9711      1249\n",
      "           1     0.9940    0.9454    0.9691      1226\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9714    0.9699    0.9701      2475\n",
      "weighted avg     0.9712    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011385562745007601, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9587    0.9922    0.9752      1286\n",
      "           1     0.9913    0.9537    0.9721      1189\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9750    0.9730    0.9737      2475\n",
      "weighted avg     0.9743    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000139097481062918, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.9925    0.9774      1327\n",
      "           1     0.9910    0.9556    0.9729      1148\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9768    0.9740    0.9752      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "created model_classifier_config_44.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010796862118171923, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9585    0.9945    0.9762      1276\n",
      "           1     0.9939    0.9541    0.9736      1199\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9762    0.9743    0.9749      2475\n",
      "weighted avg     0.9756    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010618737550696941, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9737    0.9841    0.9789      1318\n",
      "           1     0.9816    0.9697    0.9757      1157\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9777    0.9769    0.9773      2475\n",
      "weighted avg     0.9774    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013035562905398283, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9543    0.9977    0.9756      1320\n",
      "           1     0.9973    0.9455    0.9707      1155\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9758    0.9716    0.9731      2475\n",
      "weighted avg     0.9744    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011788716520925965, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9559    0.9921    0.9737      1268\n",
      "           1     0.9914    0.9519    0.9713      1207\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9736    0.9720    0.9725      2475\n",
      "weighted avg     0.9732    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014011333687136872, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9893    0.9751      1305\n",
      "           1     0.9876    0.9556    0.9713      1170\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9745    0.9724    0.9732      2475\n",
      "weighted avg     0.9737    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001067214933308688, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9901    0.9748      1308\n",
      "           1     0.9885    0.9537    0.9708      1167\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9742    0.9719    0.9728      2475\n",
      "weighted avg     0.9734    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010655012395646837, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9874    0.9750      1266\n",
      "           1     0.9864    0.9603    0.9732      1209\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9747    0.9738    0.9741      2475\n",
      "weighted avg     0.9744    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011696997013959017, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9708    0.9921    0.9814      1273\n",
      "           1     0.9915    0.9684    0.9798      1202\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9811    0.9803    0.9806      2475\n",
      "weighted avg     0.9808    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.498079316784637e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9735    0.9874    0.9804      1265\n",
      "           1     0.9866    0.9719    0.9792      1210\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9800    0.9796    0.9798      2475\n",
      "weighted avg     0.9799    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012105868320272426, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9953    0.9783      1271\n",
      "           1     0.9948    0.9585    0.9763      1204\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9784    0.9769    0.9773      2475\n",
      "weighted avg     0.9780    0.9774    0.9774      2475\n",
      "\n",
      "created model_classifier_config_45.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011096777337970156, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9913    0.9736      1265\n",
      "           1     0.9905    0.9529    0.9714      1210\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9735    0.9721    0.9725      2475\n",
      "weighted avg     0.9732    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011372530099117395, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9611    0.9896    0.9752      1250\n",
      "           1     0.9891    0.9592    0.9739      1225\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9751    0.9744    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001042676694465406, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9721    0.9895    0.9807      1336\n",
      "           1     0.9874    0.9666    0.9769      1139\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9798    0.9781    0.9788      2475\n",
      "weighted avg     0.9791    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001104676572963445, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9692    0.9893    0.9791      1304\n",
      "           1     0.9878    0.9650    0.9762      1171\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9771    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013759562162437823, Accuracy: 96.84848484848484%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9468    0.9970    0.9712      1320\n",
      "           1     0.9963    0.9359    0.9652      1155\n",
      "\n",
      "    accuracy                         0.9685      2475\n",
      "   macro avg     0.9715    0.9665    0.9682      2475\n",
      "weighted avg     0.9699    0.9685    0.9684      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013881097538302644, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.9937    0.9747      1277\n",
      "           1     0.9930    0.9516    0.9719      1198\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9747    0.9727    0.9733      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000129202279177579, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.9959    0.9740      1223\n",
      "           1     0.9958    0.9521    0.9735      1252\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9744    0.9740    0.9737      2475\n",
      "weighted avg     0.9747    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012213580235086307, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9638    0.9894    0.9764      1319\n",
      "           1     0.9875    0.9576    0.9723      1156\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9757    0.9735    0.9744      2475\n",
      "weighted avg     0.9749    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001170566166290129, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.9938    0.9779      1292\n",
      "           1     0.9930    0.9577    0.9750      1183\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9778    0.9758    0.9765      2475\n",
      "weighted avg     0.9771    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011707101807449804, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.9891    0.9754      1284\n",
      "           1     0.9879    0.9580    0.9727      1191\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9750    0.9736    0.9741      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "created model_classifier_config_46.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012794116530755553, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9520    0.9914    0.9713      1281\n",
      "           1     0.9904    0.9464    0.9679      1194\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9712    0.9689    0.9696      2475\n",
      "weighted avg     0.9705    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012464867095754605, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9618    0.9921    0.9767      1268\n",
      "           1     0.9914    0.9586    0.9747      1207\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9766    0.9753    0.9757      2475\n",
      "weighted avg     0.9762    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001194248596827189, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9929    0.9752      1268\n",
      "           1     0.9922    0.9544    0.9730      1207\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9752    0.9737    0.9741      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010940866638915708, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9557    0.9936    0.9743      1259\n",
      "           1     0.9931    0.9523    0.9723      1216\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9744    0.9730    0.9733      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001091323025298841, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.9930    0.9742      1292\n",
      "           1     0.9921    0.9501    0.9706      1183\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9740    0.9716    0.9724      2475\n",
      "weighted avg     0.9733    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.38593317763974e-05, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9954    0.9820      1318\n",
      "           1     0.9946    0.9637    0.9789      1157\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9818    0.9796    0.9805      2475\n",
      "weighted avg     0.9810    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001101938070672931, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9908    0.9800      1309\n",
      "           1     0.9894    0.9648    0.9770      1166\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9794    0.9778    0.9785      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013024036330406112, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9471    0.9952    0.9706      1259\n",
      "           1     0.9948    0.9424    0.9679      1216\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9709    0.9688    0.9692      2475\n",
      "weighted avg     0.9705    0.9693    0.9693      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011995277019462201, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9880    0.9802      1330\n",
      "           1     0.9858    0.9677    0.9766      1145\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9792    0.9778    0.9784      2475\n",
      "weighted avg     0.9787    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.93236658549068e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9876    0.9784      1286\n",
      "           1     0.9863    0.9664    0.9762      1189\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9779    0.9770    0.9773      2475\n",
      "weighted avg     0.9775    0.9774    0.9774      2475\n",
      "\n",
      "created model_classifier_config_47.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012205001982775601, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9569    0.9945    0.9753      1273\n",
      "           1     0.9939    0.9526    0.9728      1202\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9754    0.9735    0.9741      2475\n",
      "weighted avg     0.9749    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010046994445299861, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9731    0.9916    0.9823      1312\n",
      "           1     0.9903    0.9690    0.9796      1163\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9817    0.9803    0.9809      2475\n",
      "weighted avg     0.9812    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010596747952278214, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.9923    0.9802      1297\n",
      "           1     0.9913    0.9643    0.9776      1178\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9798    0.9783    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010240187548627757, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9929    0.9769      1276\n",
      "           1     0.9922    0.9575    0.9745      1199\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9768    0.9752    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010558232213511611, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9631    0.9925    0.9776      1341\n",
      "           1     0.9909    0.9550    0.9726      1134\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9770    0.9738    0.9751      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011120655921974567, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9924    0.9805      1320\n",
      "           1     0.9911    0.9636    0.9772      1155\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9800    0.9780    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012288323255500407, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.9944    0.9762      1258\n",
      "           1     0.9940    0.9556    0.9744      1217\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9763    0.9750    0.9753      2475\n",
      "weighted avg     0.9760    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011622359957357849, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9530    0.9921    0.9722      1268\n",
      "           1     0.9913    0.9486    0.9695      1207\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9722    0.9704    0.9708      2475\n",
      "weighted avg     0.9717    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012062778075536093, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9503    0.9929    0.9711      1270\n",
      "           1     0.9922    0.9452    0.9681      1205\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9712    0.9691    0.9696      2475\n",
      "weighted avg     0.9707    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011650253425944935, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9693    0.9825    0.9759      1255\n",
      "           1     0.9817    0.9680    0.9748      1220\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9755    0.9753    0.9753      2475\n",
      "weighted avg     0.9754    0.9754    0.9753      2475\n",
      "\n",
      "created model_classifier_config_48.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001131041453342245, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9637    0.9930    0.9782      1285\n",
      "           1     0.9922    0.9597    0.9757      1190\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9780    0.9763    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011484568167214442, Accuracy: 98.3030303030303%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9780    0.9911    0.9845      1346\n",
      "           1     0.9892    0.9734    0.9812      1129\n",
      "\n",
      "    accuracy                         0.9830      2475\n",
      "   macro avg     0.9836    0.9823    0.9829      2475\n",
      "weighted avg     0.9831    0.9830    0.9830      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010966564669753567, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9594    0.9930    0.9759      1286\n",
      "           1     0.9921    0.9546    0.9730      1189\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9758    0.9738    0.9745      2475\n",
      "weighted avg     0.9751    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011767978319013962, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9687    0.9888    0.9787      1253\n",
      "           1     0.9883    0.9673    0.9777      1222\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9785    0.9780    0.9782      2475\n",
      "weighted avg     0.9784    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011613446052628334, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9898    0.9727      1278\n",
      "           1     0.9887    0.9515    0.9698      1197\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9724    0.9707    0.9712      2475\n",
      "weighted avg     0.9719    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001137470356141678, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9674    0.9901    0.9786      1318\n",
      "           1     0.9885    0.9620    0.9750      1157\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9779    0.9761    0.9768      2475\n",
      "weighted avg     0.9772    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00015761643949181142, Accuracy: 96.4040404040404%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9415    0.9922    0.9662      1282\n",
      "           1     0.9911    0.9338    0.9616      1193\n",
      "\n",
      "    accuracy                         0.9640      2475\n",
      "   macro avg     0.9663    0.9630    0.9639      2475\n",
      "weighted avg     0.9654    0.9640    0.9640      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.801926937970248e-05, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9885    0.9766      1308\n",
      "           1     0.9868    0.9597    0.9731      1167\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9741    0.9748      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.866200543413258e-05, Accuracy: 98.3030303030303%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9709    0.9969    0.9837      1271\n",
      "           1     0.9966    0.9684    0.9823      1204\n",
      "\n",
      "    accuracy                         0.9830      2475\n",
      "   macro avg     0.9837    0.9826    0.9830      2475\n",
      "weighted avg     0.9834    0.9830    0.9830      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001326462295320299, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9470    0.9912    0.9686      1243\n",
      "           1     0.9906    0.9440    0.9667      1232\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9688    0.9676    0.9677      2475\n",
      "weighted avg     0.9687    0.9677    0.9677      2475\n",
      "\n",
      "created model_classifier_config_49.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012093865811222731, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9663    0.9875    0.9768      1278\n",
      "           1     0.9863    0.9632    0.9746      1197\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9763    0.9754    0.9757      2475\n",
      "weighted avg     0.9760    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011741254967872542, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.9928    0.9746      1258\n",
      "           1     0.9923    0.9540    0.9728      1217\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9747    0.9734    0.9737      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014815627926527853, Accuracy: 96.16161616161617%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9376    0.9914    0.9638      1274\n",
      "           1     0.9902    0.9301    0.9592      1201\n",
      "\n",
      "    accuracy                         0.9616      2475\n",
      "   macro avg     0.9639    0.9607    0.9615      2475\n",
      "weighted avg     0.9632    0.9616    0.9615      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.53845845328437e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9928    0.9802      1248\n",
      "           1     0.9925    0.9666    0.9794      1227\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9802    0.9797    0.9798      2475\n",
      "weighted avg     0.9801    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014520539779855747, Accuracy: 98.34343434343434%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9719    0.9969    0.9842      1283\n",
      "           1     0.9965    0.9690    0.9826      1192\n",
      "\n",
      "    accuracy                         0.9834      2475\n",
      "   macro avg     0.9842    0.9829    0.9834      2475\n",
      "weighted avg     0.9838    0.9834    0.9834      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010240806473626031, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9749    0.9892    0.9820      1298\n",
      "           1     0.9879    0.9720    0.9799      1177\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9814    0.9806    0.9809      2475\n",
      "weighted avg     0.9811    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001191883496563844, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9713    0.9947    0.9828      1325\n",
      "           1     0.9937    0.9661    0.9797      1150\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9825    0.9804    0.9813      2475\n",
      "weighted avg     0.9817    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001240335570441352, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9713    0.9873    0.9792      1336\n",
      "           1     0.9848    0.9658    0.9752      1139\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9780    0.9765    0.9772      2475\n",
      "weighted avg     0.9775    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001263943946722782, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9536    0.9922    0.9725      1285\n",
      "           1     0.9912    0.9479    0.9691      1190\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9724    0.9701    0.9708      2475\n",
      "weighted avg     0.9717    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010740320790897716, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9883    0.9736      1285\n",
      "           1     0.9870    0.9546    0.9705      1190\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9731    0.9715    0.9720      2475\n",
      "weighted avg     0.9726    0.9721    0.9721      2475\n",
      "\n",
      "created model_classifier_config_50.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013776034718812114, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9716    0.9929    0.9821      1274\n",
      "           1     0.9923    0.9692    0.9806      1201\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9820    0.9811    0.9814      2475\n",
      "weighted avg     0.9816    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010842442512512207, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9736    0.9897    0.9816      1265\n",
      "           1     0.9891    0.9719    0.9804      1210\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9813    0.9808    0.9810      2475\n",
      "weighted avg     0.9811    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001284179783830739, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.9908    0.9736      1305\n",
      "           1     0.9893    0.9504    0.9695      1170\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9732    0.9706    0.9716      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011085294713877668, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9909    0.9776      1323\n",
      "           1     0.9892    0.9583    0.9735      1152\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9770    0.9746    0.9756      2475\n",
      "weighted avg     0.9761    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011746971896200469, Accuracy: 98.26262626262626%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9785    0.9883    0.9834      1287\n",
      "           1     0.9872    0.9764    0.9818      1188\n",
      "\n",
      "    accuracy                         0.9826      2475\n",
      "   macro avg     0.9828    0.9824    0.9826      2475\n",
      "weighted avg     0.9827    0.9826    0.9826      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011092963543805209, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9628    0.9922    0.9772      1277\n",
      "           1     0.9914    0.9591    0.9750      1198\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9771    0.9756    0.9761      2475\n",
      "weighted avg     0.9766    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012787262598673503, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9658    0.9904    0.9780      1255\n",
      "           1     0.9899    0.9639    0.9767      1220\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9779    0.9772    0.9774      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012993597924107253, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9512    0.9914    0.9709      1277\n",
      "           1     0.9904    0.9457    0.9675      1198\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9708    0.9686    0.9692      2475\n",
      "weighted avg     0.9701    0.9693    0.9693      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011263838922134553, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9643    0.9903    0.9771      1338\n",
      "           1     0.9882    0.9569    0.9723      1137\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9763    0.9736    0.9747      2475\n",
      "weighted avg     0.9753    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010679157394351381, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9890    0.9755      1269\n",
      "           1     0.9880    0.9594    0.9735      1206\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9752    0.9742    0.9745      2475\n",
      "weighted avg     0.9749    0.9745    0.9745      2475\n",
      "\n",
      "created model_classifier_config_51.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011111015623266046, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9929    0.9778      1266\n",
      "           1     0.9923    0.9603    0.9760      1209\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9778    0.9766    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011487648342594956, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9658    0.9937    0.9795      1277\n",
      "           1     0.9931    0.9624    0.9775      1198\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9794    0.9781    0.9785      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000132001508968045, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9635    0.9961    0.9795      1273\n",
      "           1     0.9957    0.9601    0.9776      1202\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9796    0.9781    0.9785      2475\n",
      "weighted avg     0.9791    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011176119850139425, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9681    0.9922    0.9800      1284\n",
      "           1     0.9914    0.9647    0.9779      1191\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9797    0.9785    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013794125330568563, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9606    0.9904    0.9753      1255\n",
      "           1     0.9898    0.9582    0.9738      1220\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9752    0.9743    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011203083426061302, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9723    0.9933    0.9827      1341\n",
      "           1     0.9919    0.9665    0.9790      1134\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9821    0.9799    0.9808      2475\n",
      "weighted avg     0.9812    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012607052470698502, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9595    0.9915    0.9752      1291\n",
      "           1     0.9904    0.9544    0.9720      1184\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9749    0.9729    0.9736      2475\n",
      "weighted avg     0.9743    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012685525597948017, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9939    0.9802      1319\n",
      "           1     0.9929    0.9611    0.9767      1156\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9798    0.9775    0.9784      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013013705460712164, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9591    0.9875    0.9731      1281\n",
      "           1     0.9862    0.9548    0.9702      1194\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9726    0.9711    0.9716      2475\n",
      "weighted avg     0.9721    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011929279626017869, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9534    0.9883    0.9705      1283\n",
      "           1     0.9869    0.9480    0.9671      1192\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9701    0.9681    0.9688      2475\n",
      "weighted avg     0.9695    0.9689    0.9689      2475\n",
      "\n",
      "created model_classifier_config_52.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011166227586341627, Accuracy: 98.26262626262626%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9720    0.9944    0.9831      1255\n",
      "           1     0.9941    0.9705    0.9822      1220\n",
      "\n",
      "    accuracy                         0.9826      2475\n",
      "   macro avg     0.9830    0.9825    0.9826      2475\n",
      "weighted avg     0.9829    0.9826    0.9826      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011043299629230692, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9702    0.9829    0.9765      1290\n",
      "           1     0.9812    0.9671    0.9741      1185\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9757    0.9750    0.9753      2475\n",
      "weighted avg     0.9754    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.454938799443871e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.9929    0.9793      1262\n",
      "           1     0.9924    0.9637    0.9778      1213\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9792    0.9783    0.9786      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012908640232953158, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9552    0.9978    0.9760      1346\n",
      "           1     0.9972    0.9442    0.9700      1129\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9762    0.9710    0.9730      2475\n",
      "weighted avg     0.9744    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011346468118706134, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9706    0.9855    0.9780      1306\n",
      "           1     0.9835    0.9666    0.9750      1169\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9770    0.9760    0.9765      2475\n",
      "weighted avg     0.9767    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010123957889248626, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9651    0.9914    0.9781      1284\n",
      "           1     0.9905    0.9614    0.9757      1191\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9778    0.9764    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014227240073560465, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9430    0.9968    0.9692      1262\n",
      "           1     0.9965    0.9373    0.9660      1213\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9698    0.9671    0.9676      2475\n",
      "weighted avg     0.9692    0.9677    0.9676      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012341465010787503, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9638    0.9876    0.9756      1294\n",
      "           1     0.9861    0.9594    0.9725      1181\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9749    0.9735    0.9741      2475\n",
      "weighted avg     0.9744    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011394881539874607, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9892    0.9733      1291\n",
      "           1     0.9877    0.9527    0.9699      1184\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9729    0.9709    0.9716      2475\n",
      "weighted avg     0.9722    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014331782104993107, Accuracy: 96.60606060606061%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9423    0.9953    0.9681      1280\n",
      "           1     0.9947    0.9347    0.9638      1195\n",
      "\n",
      "    accuracy                         0.9661      2475\n",
      "   macro avg     0.9685    0.9650    0.9659      2475\n",
      "weighted avg     0.9676    0.9661    0.9660      2475\n",
      "\n",
      "created model_classifier_config_53.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010151674952169862, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9655    0.9924    0.9788      1324\n",
      "           1     0.9910    0.9592    0.9748      1151\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9782    0.9758    0.9768      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001237189799848229, Accuracy: 96.8080808080808%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9495    0.9906    0.9696      1273\n",
      "           1     0.9895    0.9443    0.9664      1202\n",
      "\n",
      "    accuracy                         0.9681      2475\n",
      "   macro avg     0.9695    0.9674    0.9680      2475\n",
      "weighted avg     0.9690    0.9681    0.9680      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011321837853903722, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9604    0.9878    0.9739      1227\n",
      "           1     0.9876    0.9599    0.9736      1248\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9740    0.9739    0.9737      2475\n",
      "weighted avg     0.9741    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012089685960249467, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9626    0.9882    0.9753      1276\n",
      "           1     0.9871    0.9591    0.9729      1199\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9749    0.9737    0.9741      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001048470868004693, Accuracy: 98.18181818181819%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9731    0.9931    0.9830      1309\n",
      "           1     0.9921    0.9691    0.9805      1166\n",
      "\n",
      "    accuracy                         0.9818      2475\n",
      "   macro avg     0.9826    0.9811    0.9817      2475\n",
      "weighted avg     0.9820    0.9818    0.9818      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010104539719494907, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9645    0.9892    0.9767      1292\n",
      "           1     0.9878    0.9603    0.9739      1183\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9762    0.9747    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010047764188111431, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9675    0.9938    0.9805      1290\n",
      "           1     0.9930    0.9637    0.9782      1185\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9803    0.9788    0.9793      2475\n",
      "weighted avg     0.9798    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010621694603351631, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9532    0.9906    0.9715      1275\n",
      "           1     0.9896    0.9483    0.9685      1200\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9714    0.9695    0.9700      2475\n",
      "weighted avg     0.9708    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001120273783953503, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9626    0.9938    0.9779      1294\n",
      "           1     0.9930    0.9577    0.9750      1181\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9778    0.9757    0.9765      2475\n",
      "weighted avg     0.9771    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012437278574163263, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9610    0.9962    0.9783      1310\n",
      "           1     0.9955    0.9545    0.9746      1165\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9782    0.9753    0.9764      2475\n",
      "weighted avg     0.9772    0.9766    0.9765      2475\n",
      "\n",
      "created model_classifier_config_54.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010588343697364884, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9674    0.9902    0.9787      1320\n",
      "           1     0.9884    0.9619    0.9750      1155\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9779    0.9760    0.9768      2475\n",
      "weighted avg     0.9772    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011300200765783136, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9947    0.9795      1322\n",
      "           1     0.9937    0.9584    0.9757      1153\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9792    0.9765    0.9776      2475\n",
      "weighted avg     0.9783    0.9778    0.9777      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011662439565465907, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9610    0.9913    0.9759      1268\n",
      "           1     0.9906    0.9577    0.9739      1207\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9758    0.9745    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001445982221401099, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9938    0.9756      1285\n",
      "           1     0.9930    0.9529    0.9726      1190\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9755    0.9734    0.9741      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013420834685816909, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9946    0.9777      1299\n",
      "           1     0.9938    0.9558    0.9744      1176\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9776    0.9752    0.9761      2475\n",
      "weighted avg     0.9768    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011174585181053238, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9682    0.9866    0.9773      1267\n",
      "           1     0.9856    0.9661    0.9758      1208\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9769    0.9763    0.9765      2475\n",
      "weighted avg     0.9767    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012695938047736582, Accuracy: 96.12121212121212%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9364    0.9913    0.9630      1262\n",
      "           1     0.9903    0.9299    0.9592      1213\n",
      "\n",
      "    accuracy                         0.9612      2475\n",
      "   macro avg     0.9634    0.9606    0.9611      2475\n",
      "weighted avg     0.9628    0.9612    0.9612      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.877441206363716e-05, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9930    0.9774      1284\n",
      "           1     0.9922    0.9580    0.9748      1191\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9772    0.9755    0.9761      2475\n",
      "weighted avg     0.9767    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010329941607484914, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9679    0.9953    0.9814      1274\n",
      "           1     0.9948    0.9650    0.9797      1201\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9814    0.9802    0.9806      2475\n",
      "weighted avg     0.9810    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010966035753789574, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9868    0.9770      1289\n",
      "           1     0.9853    0.9637    0.9744      1186\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9763    0.9753    0.9757      2475\n",
      "weighted avg     0.9759    0.9758    0.9757      2475\n",
      "\n",
      "created model_classifier_config_55.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011771625039553401, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9519    0.9915    0.9713      1297\n",
      "           1     0.9902    0.9448    0.9670      1178\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9711    0.9682    0.9691      2475\n",
      "weighted avg     0.9701    0.9693    0.9692      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011480217329179398, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9579    0.9952    0.9762      1256\n",
      "           1     0.9949    0.9549    0.9745      1219\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9764    0.9751    0.9753      2475\n",
      "weighted avg     0.9761    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010728776755959096, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9875    0.9756      1275\n",
      "           1     0.9863    0.9608    0.9734      1200\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9752    0.9741    0.9745      2475\n",
      "weighted avg     0.9748    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012146566853378758, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9644    0.9907    0.9774      1287\n",
      "           1     0.9896    0.9604    0.9748      1188\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9770    0.9756    0.9761      2475\n",
      "weighted avg     0.9765    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012317914553362913, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9509    0.9915    0.9708      1290\n",
      "           1     0.9903    0.9443    0.9667      1185\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9706    0.9679    0.9688      2475\n",
      "weighted avg     0.9698    0.9689    0.9688      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001207113205784499, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9922    0.9804      1286\n",
      "           1     0.9914    0.9655    0.9783      1189\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9801    0.9789    0.9793      2475\n",
      "weighted avg     0.9797    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012477499065977155, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9658    0.9908    0.9782      1311\n",
      "           1     0.9894    0.9605    0.9747      1164\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9776    0.9757    0.9764      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00015360872552852437, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9584    0.9938    0.9758      1299\n",
      "           1     0.9929    0.9524    0.9722      1176\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9757    0.9731    0.9740      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001149913849252643, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9543    0.9929    0.9732      1261\n",
      "           1     0.9923    0.9506    0.9710      1214\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9733    0.9717    0.9721      2475\n",
      "weighted avg     0.9729    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001181266193438058, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9657    0.9916    0.9785      1308\n",
      "           1     0.9903    0.9606    0.9752      1167\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9780    0.9761    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9769      2475\n",
      "\n",
      "created model_classifier_config_56.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011313785507221415, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9907    0.9775      1295\n",
      "           1     0.9895    0.9602    0.9746      1180\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9771    0.9755    0.9761      2475\n",
      "weighted avg     0.9765    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010592483209841179, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9703    0.9861    0.9781      1292\n",
      "           1     0.9845    0.9670    0.9757      1183\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9774    0.9766    0.9769      2475\n",
      "weighted avg     0.9771    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010508754036643288, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9931    0.9770      1303\n",
      "           1     0.9920    0.9556    0.9735      1172\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9767    0.9744    0.9752      2475\n",
      "weighted avg     0.9759    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001136082922569429, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9681    0.9954    0.9816      1311\n",
      "           1     0.9947    0.9631    0.9786      1164\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9814    0.9792    0.9801      2475\n",
      "weighted avg     0.9806    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012099577621980146, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9879    0.9758      1327\n",
      "           1     0.9857    0.9573    0.9713      1148\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9748    0.9726    0.9735      2475\n",
      "weighted avg     0.9740    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012099180859748763, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9606    0.9952    0.9776      1249\n",
      "           1     0.9949    0.9584    0.9763      1226\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9778    0.9768    0.9770      2475\n",
      "weighted avg     0.9776    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.747008482615153e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9702    0.9868    0.9784      1285\n",
      "           1     0.9854    0.9672    0.9763      1190\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9778    0.9770    0.9773      2475\n",
      "weighted avg     0.9775    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010305240900829585, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.9905    0.9736      1268\n",
      "           1     0.9897    0.9536    0.9713      1207\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9735    0.9721    0.9725      2475\n",
      "weighted avg     0.9731    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011811855164441195, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9961    0.9776      1292\n",
      "           1     0.9956    0.9544    0.9745      1183\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9777    0.9752    0.9761      2475\n",
      "weighted avg     0.9769    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013514447693872933, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9552    0.9912    0.9729      1248\n",
      "           1     0.9907    0.9527    0.9713      1227\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9729    0.9720    0.9721      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "created model_classifier_config_57.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012376395740894356, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9536    0.9930    0.9729      1283\n",
      "           1     0.9921    0.9480    0.9695      1192\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9728    0.9705    0.9712      2475\n",
      "weighted avg     0.9721    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001290726029511654, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9595    0.9930    0.9759      1287\n",
      "           1     0.9921    0.9545    0.9730      1188\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9758    0.9738    0.9745      2475\n",
      "weighted avg     0.9751    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.70226526260376e-05, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9710    0.9881    0.9795      1256\n",
      "           1     0.9875    0.9696    0.9785      1219\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9793    0.9789    0.9790      2475\n",
      "weighted avg     0.9791    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010044423016634855, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.9924    0.9772      1320\n",
      "           1     0.9910    0.9558    0.9731      1155\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9768    0.9741    0.9752      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012946904608697604, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9907    0.9779      1295\n",
      "           1     0.9895    0.9610    0.9751      1180\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9775    0.9759    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012635235533569797, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.9915    0.9738      1293\n",
      "           1     0.9903    0.9509    0.9702      1182\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9735    0.9712    0.9720      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.370054861511846e-05, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9715    0.9906    0.9809      1273\n",
      "           1     0.9898    0.9692    0.9794      1202\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9806    0.9799    0.9802      2475\n",
      "weighted avg     0.9804    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001284657373572841, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9938    0.9785      1280\n",
      "           1     0.9931    0.9598    0.9762      1195\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9784    0.9768    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013283595593288692, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9589    0.9946    0.9764      1290\n",
      "           1     0.9938    0.9536    0.9733      1185\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9764    0.9741    0.9749      2475\n",
      "weighted avg     0.9756    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013320869869656033, Accuracy: 98.38383838383838%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9757    0.9938    0.9847      1293\n",
      "           1     0.9931    0.9729    0.9829      1182\n",
      "\n",
      "    accuracy                         0.9838      2475\n",
      "   macro avg     0.9844    0.9834    0.9838      2475\n",
      "weighted avg     0.9840    0.9838    0.9838      2475\n",
      "\n",
      "created model_classifier_config_58.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013903844537157002, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9678    0.9893    0.9784      1307\n",
      "           1     0.9877    0.9632    0.9753      1168\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9778    0.9762    0.9769      2475\n",
      "weighted avg     0.9772    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.824332865801724e-05, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9693    0.9890    0.9790      1275\n",
      "           1     0.9881    0.9667    0.9773      1200\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9787    0.9778    0.9781      2475\n",
      "weighted avg     0.9784    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012718979156378543, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.9932    0.9754      1315\n",
      "           1     0.9919    0.9509    0.9710      1160\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9750    0.9720    0.9732      2475\n",
      "weighted avg     0.9740    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.94624031914605e-05, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9924    0.9806      1322\n",
      "           1     0.9911    0.9636    0.9771      1153\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9800    0.9780    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010583801703019576, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.9900    0.9791      1299\n",
      "           1     0.9887    0.9643    0.9763      1176\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9771    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011678371766600946, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9892    0.9772      1298\n",
      "           1     0.9878    0.9609    0.9742      1177\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9766    0.9751    0.9757      2475\n",
      "weighted avg     0.9760    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001194547222118185, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9707    0.9914    0.9809      1272\n",
      "           1     0.9906    0.9684    0.9794      1203\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9807    0.9799    0.9802      2475\n",
      "weighted avg     0.9804    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010989013946417607, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9555    0.9912    0.9730      1256\n",
      "           1     0.9906    0.9524    0.9711      1219\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9731    0.9718    0.9721      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013288635798174925, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9521    0.9945    0.9728      1278\n",
      "           1     0.9939    0.9465    0.9696      1197\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9730    0.9705    0.9712      2475\n",
      "weighted avg     0.9723    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010947750975387265, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.9920    0.9737      1248\n",
      "           1     0.9915    0.9535    0.9722      1227\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9738    0.9728    0.9729      2475\n",
      "weighted avg     0.9736    0.9729    0.9729      2475\n",
      "\n",
      "created model_classifier_config_59.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012417529568527685, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9521    0.9945    0.9729      1280\n",
      "           1     0.9938    0.9464    0.9696      1195\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9730    0.9705    0.9712      2475\n",
      "weighted avg     0.9723    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012174561168208266, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9604    0.9954    0.9776      1292\n",
      "           1     0.9947    0.9552    0.9746      1183\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9776    0.9753    0.9761      2475\n",
      "weighted avg     0.9768    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001130200455887149, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9564    0.9891    0.9725      1286\n",
      "           1     0.9878    0.9512    0.9692      1189\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9721    0.9702    0.9708      2475\n",
      "weighted avg     0.9715    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010832616777131052, Accuracy: 98.34343434343434%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9755    0.9930    0.9842      1285\n",
      "           1     0.9923    0.9731    0.9826      1190\n",
      "\n",
      "    accuracy                         0.9834      2475\n",
      "   macro avg     0.9839    0.9831    0.9834      2475\n",
      "weighted avg     0.9836    0.9834    0.9834      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.606243013131498e-05, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.9946    0.9801      1288\n",
      "           1     0.9939    0.9621    0.9777      1187\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9800    0.9783    0.9789      2475\n",
      "weighted avg     0.9794    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000110344865707436, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9506    0.9922    0.9710      1281\n",
      "           1     0.9912    0.9447    0.9674      1194\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9709    0.9685    0.9692      2475\n",
      "weighted avg     0.9702    0.9693    0.9693      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012247664157790368, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.9969    0.9792      1300\n",
      "           1     0.9965    0.9566    0.9761      1175\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9793    0.9768    0.9777      2475\n",
      "weighted avg     0.9784    0.9778    0.9777      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010413879095905959, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9678    0.9922    0.9798      1274\n",
      "           1     0.9914    0.9650    0.9781      1201\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9796    0.9786    0.9790      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014495028991891881, Accuracy: 96.8080808080808%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    0.9903    0.9710      1334\n",
      "           1     0.9881    0.9422    0.9646      1141\n",
      "\n",
      "    accuracy                         0.9681      2475\n",
      "   macro avg     0.9702    0.9662    0.9678      2475\n",
      "weighted avg     0.9688    0.9681    0.9680      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012550384107262198, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9611    0.9888    0.9748      1250\n",
      "           1     0.9882    0.9592    0.9735      1225\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9747    0.9740    0.9741      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "created model_classifier_config_60.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012488107789646497, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.9909    0.9783      1321\n",
      "           1     0.9893    0.9601    0.9745      1154\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9777    0.9755    0.9764      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010648078689671527, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9637    0.9899    0.9766      1288\n",
      "           1     0.9887    0.9596    0.9739      1187\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9762    0.9747    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010284325992218172, Accuracy: 98.3030303030303%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9742    0.9938    0.9839      1293\n",
      "           1     0.9931    0.9712    0.9820      1182\n",
      "\n",
      "    accuracy                         0.9830      2475\n",
      "   macro avg     0.9837    0.9825    0.9830      2475\n",
      "weighted avg     0.9832    0.9830    0.9830      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001244742189994966, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9659    0.9961    0.9808      1280\n",
      "           1     0.9957    0.9623    0.9787      1195\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9808    0.9792    0.9797      2475\n",
      "weighted avg     0.9803    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011270329506710322, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9602    0.9890    0.9744      1269\n",
      "           1     0.9880    0.9569    0.9722      1206\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9741    0.9729    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012853869886109324, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.9953    0.9737      1266\n",
      "           1     0.9948    0.9487    0.9712      1209\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9739    0.9720    0.9725      2475\n",
      "weighted avg     0.9735    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001271639990084099, Accuracy: 96.8080808080808%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9585    0.9803    0.9693      1272\n",
      "           1     0.9787    0.9551    0.9668      1203\n",
      "\n",
      "    accuracy                         0.9681      2475\n",
      "   macro avg     0.9686    0.9677    0.9680      2475\n",
      "weighted avg     0.9683    0.9681    0.9681      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011290201936105285, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9619    0.9931    0.9772      1297\n",
      "           1     0.9921    0.9567    0.9741      1178\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9770    0.9749    0.9757      2475\n",
      "weighted avg     0.9763    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011834211722768918, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9893    0.9782      1314\n",
      "           1     0.9876    0.9621    0.9747      1161\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9774    0.9757    0.9764      2475\n",
      "weighted avg     0.9768    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001256798283018247, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9510    0.9937    0.9719      1270\n",
      "           1     0.9930    0.9461    0.9690      1205\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9720    0.9699    0.9704      2475\n",
      "weighted avg     0.9715    0.9705    0.9705      2475\n",
      "\n",
      "created model_classifier_config_61.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.664957270477758e-05, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9736    0.9916    0.9825      1302\n",
      "           1     0.9904    0.9702    0.9802      1173\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9820    0.9809    0.9813      2475\n",
      "weighted avg     0.9816    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011791826799662426, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9969    0.9816      1286\n",
      "           1     0.9965    0.9630    0.9795      1189\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9817    0.9799    0.9805      2475\n",
      "weighted avg     0.9811    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010549399888876713, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9763    0.9868    0.9815      1292\n",
      "           1     0.9855    0.9738    0.9796      1183\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9809    0.9803    0.9806      2475\n",
      "weighted avg     0.9807    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010543561945057879, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9692    0.9893    0.9791      1305\n",
      "           1     0.9878    0.9650    0.9762      1170\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9771    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001354438578239595, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9587    0.9946    0.9763      1306\n",
      "           1     0.9938    0.9521    0.9725      1169\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9762    0.9734    0.9744      2475\n",
      "weighted avg     0.9752    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013597733745671282, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9906    0.9752      1271\n",
      "           1     0.9897    0.9568    0.9730      1204\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9750    0.9737    0.9741      2475\n",
      "weighted avg     0.9746    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011461186589616718, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9511    0.9945    0.9723      1270\n",
      "           1     0.9939    0.9461    0.9694      1205\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9725    0.9703    0.9708      2475\n",
      "weighted avg     0.9719    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011453549368212922, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9575    0.9932    0.9750      1315\n",
      "           1     0.9919    0.9500    0.9705      1160\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9747    0.9716    0.9727      2475\n",
      "weighted avg     0.9736    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001163129433236941, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9921    0.9782      1266\n",
      "           1     0.9915    0.9620    0.9765      1209\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9781    0.9770    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011551427720773099, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9905    0.9746      1257\n",
      "           1     0.9898    0.9565    0.9729      1218\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9745    0.9735    0.9737      2475\n",
      "weighted avg     0.9742    0.9737    0.9737      2475\n",
      "\n",
      "created model_classifier_config_62.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001000738956711509, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9643    0.9930    0.9784      1279\n",
      "           1     0.9922    0.9607    0.9762      1196\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9783    0.9768    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011116045593011259, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9696    0.9899    0.9797      1290\n",
      "           1     0.9888    0.9662    0.9774      1185\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9792    0.9781    0.9785      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010222490086699977, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9681    0.9922    0.9800      1283\n",
      "           1     0.9914    0.9648    0.9779      1192\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9797    0.9785    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011498997909854157, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9921    0.9763      1264\n",
      "           1     0.9915    0.9579    0.9744      1211\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9762    0.9750    0.9753      2475\n",
      "weighted avg     0.9759    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011138025558356083, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9681    0.9891    0.9785      1287\n",
      "           1     0.9879    0.9646    0.9761      1188\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9780    0.9769    0.9773      2475\n",
      "weighted avg     0.9776    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011950388099208023, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9587    0.9866    0.9724      1269\n",
      "           1     0.9855    0.9552    0.9701      1206\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9721    0.9709    0.9713      2475\n",
      "weighted avg     0.9717    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013295861807736484, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9946    0.9782      1307\n",
      "           1     0.9938    0.9563    0.9747      1168\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9780    0.9755    0.9764      2475\n",
      "weighted avg     0.9771    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010722891850904985, Accuracy: 98.34343434343434%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9775    0.9916    0.9845      1313\n",
      "           1     0.9904    0.9742    0.9822      1162\n",
      "\n",
      "    accuracy                         0.9834      2475\n",
      "   macro avg     0.9839    0.9829    0.9834      2475\n",
      "weighted avg     0.9835    0.9834    0.9834      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012232571840286254, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.9922    0.9746      1276\n",
      "           1     0.9913    0.9533    0.9719      1199\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9745    0.9727    0.9733      2475\n",
      "weighted avg     0.9740    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011741926272710164, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.9931    0.9747      1302\n",
      "           1     0.9920    0.9506    0.9708      1173\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9745    0.9718    0.9728      2475\n",
      "weighted avg     0.9736    0.9729    0.9729      2475\n",
      "\n",
      "created model_classifier_config_63.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010591136084662543, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9574    0.9898    0.9733      1273\n",
      "           1     0.9888    0.9534    0.9708      1202\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9731    0.9716    0.9721      2475\n",
      "weighted avg     0.9727    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011430555521839797, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.9953    0.9752      1265\n",
      "           1     0.9948    0.9521    0.9730      1210\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9754    0.9737    0.9741      2475\n",
      "weighted avg     0.9750    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001022244252339758, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9711    0.9899    0.9804      1288\n",
      "           1     0.9888    0.9680    0.9783      1187\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9799    0.9789    0.9793      2475\n",
      "weighted avg     0.9796    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011495653125974866, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9633    0.9890    0.9760      1275\n",
      "           1     0.9880    0.9600    0.9738      1200\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9757    0.9745    0.9749      2475\n",
      "weighted avg     0.9753    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011051737298869123, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9740    0.9868    0.9804      1291\n",
      "           1     0.9854    0.9713    0.9783      1184\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9797    0.9791    0.9793      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013838584976966936, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9547    0.9932    0.9736      1317\n",
      "           1     0.9919    0.9465    0.9686      1158\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9733    0.9698    0.9711      2475\n",
      "weighted avg     0.9721    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.698976470966532e-05, Accuracy: 98.18181818181819%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9719    0.9928    0.9823      1256\n",
      "           1     0.9924    0.9705    0.9813      1219\n",
      "\n",
      "    accuracy                         0.9818      2475\n",
      "   macro avg     0.9822    0.9817    0.9818      2475\n",
      "weighted avg     0.9820    0.9818    0.9818      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013560890850394664, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9497    0.9946    0.9716      1290\n",
      "           1     0.9938    0.9426    0.9675      1185\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9717    0.9686    0.9696      2475\n",
      "weighted avg     0.9708    0.9697    0.9696      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011830156198655716, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.9939    0.9749      1308\n",
      "           1     0.9928    0.9494    0.9707      1167\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9747    0.9717    0.9728      2475\n",
      "weighted avg     0.9737    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010861840814051002, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9916    0.9763      1307\n",
      "           1     0.9902    0.9555    0.9725      1168\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9758    0.9735    0.9744      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "created model_classifier_config_64.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010656475418745869, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9610    0.9924    0.9765      1317\n",
      "           1     0.9910    0.9542    0.9723      1158\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9760    0.9733    0.9744      2475\n",
      "weighted avg     0.9751    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001085342662503021, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9642    0.9954    0.9796      1300\n",
      "           1     0.9947    0.9591    0.9766      1175\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9795    0.9773    0.9781      2475\n",
      "weighted avg     0.9787    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.538884114737463e-05, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9715    0.9921    0.9817      1269\n",
      "           1     0.9915    0.9693    0.9803      1206\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9815    0.9807    0.9810      2475\n",
      "weighted avg     0.9812    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012466548669217814, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9485    0.9938    0.9706      1280\n",
      "           1     0.9929    0.9423    0.9669      1195\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9707    0.9680    0.9688      2475\n",
      "weighted avg     0.9700    0.9689    0.9688      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001130505854433233, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9879    0.9784      1327\n",
      "           1     0.9857    0.9634    0.9744      1148\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9773    0.9757    0.9764      2475\n",
      "weighted avg     0.9767    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012150550731504807, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9766    0.9886    0.9826      1311\n",
      "           1     0.9869    0.9734    0.9801      1164\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9818    0.9810    0.9813      2475\n",
      "weighted avg     0.9815    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.55118163667544e-05, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9637    0.9930    0.9781      1284\n",
      "           1     0.9922    0.9597    0.9757      1191\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9780    0.9763    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014746282437835077, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9459    0.9945    0.9696      1283\n",
      "           1     0.9938    0.9388    0.9655      1192\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9698    0.9667    0.9675      2475\n",
      "weighted avg     0.9690    0.9677    0.9676      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014375554792808764, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.9887    0.9722      1239\n",
      "           1     0.9883    0.9547    0.9712      1236\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9723    0.9717    0.9717      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001310811440149943, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.9913    0.9746      1260\n",
      "           1     0.9906    0.9556    0.9728      1215\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9746    0.9734    0.9737      2475\n",
      "weighted avg     0.9743    0.9737    0.9737      2475\n",
      "\n",
      "created model_classifier_config_65.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011258471192735614, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9687    0.9946    0.9815      1308\n",
      "           1     0.9938    0.9640    0.9787      1167\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9813    0.9793    0.9801      2475\n",
      "weighted avg     0.9806    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001158950033814016, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9733    0.9876    0.9804      1292\n",
      "           1     0.9863    0.9704    0.9783      1183\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9798    0.9790    0.9793      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011439426378770308, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9551    0.9929    0.9736      1265\n",
      "           1     0.9922    0.9512    0.9713      1210\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9737    0.9721    0.9725      2475\n",
      "weighted avg     0.9733    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012513821474229446, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9530    0.9931    0.9726      1306\n",
      "           1     0.9919    0.9453    0.9680      1169\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9724    0.9692    0.9703      2475\n",
      "weighted avg     0.9714    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012185690378901934, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9877    0.9764      1300\n",
      "           1     0.9860    0.9609    0.9733      1175\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9757    0.9743    0.9749      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011735470306993735, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9569    0.9898    0.9731      1279\n",
      "           1     0.9887    0.9523    0.9702      1196\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9728    0.9711    0.9716      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011711518270800813, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9641    0.9890    0.9764      1277\n",
      "           1     0.9880    0.9608    0.9742      1198\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9761    0.9749    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012599119333305743, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9899    0.9762      1283\n",
      "           1     0.9888    0.9589    0.9736      1192\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9758    0.9744    0.9749      2475\n",
      "weighted avg     0.9753    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012438849668310146, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9913    0.9758      1263\n",
      "           1     0.9906    0.9579    0.9740      1212\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9757    0.9746    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.33260177121018e-05, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9714    0.9938    0.9825      1297\n",
      "           1     0.9930    0.9677    0.9802      1178\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9822    0.9808    0.9813      2475\n",
      "weighted avg     0.9817    0.9814    0.9814      2475\n",
      "\n",
      "created model_classifier_config_66.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.909628617643106e-05, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.9925    0.9770      1329\n",
      "           1     0.9909    0.9546    0.9724      1146\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9765    0.9736    0.9747      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011818181384693492, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9511    0.9920    0.9711      1255\n",
      "           1     0.9914    0.9475    0.9690      1220\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9713    0.9698    0.9701      2475\n",
      "weighted avg     0.9710    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001005030581445405, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9631    0.9897    0.9762      1265\n",
      "           1     0.9889    0.9603    0.9744      1210\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9760    0.9750    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011964136903936213, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9691    0.9902    0.9795      1330\n",
      "           1     0.9884    0.9633    0.9757      1145\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9787    0.9768    0.9776      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001198398374547862, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9901    0.9738      1312\n",
      "           1     0.9884    0.9510    0.9693      1163\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9732    0.9705    0.9715      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.573356370733241e-05, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9914    0.9779      1272\n",
      "           1     0.9906    0.9618    0.9760      1203\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9777    0.9766    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000101680171610129, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9611    0.9960    0.9782      1241\n",
      "           1     0.9958    0.9595    0.9773      1234\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9777    0.9778      2475\n",
      "weighted avg     0.9784    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011109126938713922, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9626    0.9948    0.9784      1344\n",
      "           1     0.9936    0.9540    0.9734      1131\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9781    0.9744    0.9759      2475\n",
      "weighted avg     0.9767    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001324074286403078, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9604    0.9921    0.9760      1270\n",
      "           1     0.9914    0.9568    0.9738      1205\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9745    0.9749      2475\n",
      "weighted avg     0.9755    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011817714481642752, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9526    0.9960    0.9738      1252\n",
      "           1     0.9957    0.9493    0.9720      1223\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9742    0.9727    0.9729      2475\n",
      "weighted avg     0.9739    0.9729    0.9729      2475\n",
      "\n",
      "created model_classifier_config_67.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013748957954271874, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9901    0.9755      1308\n",
      "           1     0.9885    0.9554    0.9717      1167\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9749    0.9728    0.9736      2475\n",
      "weighted avg     0.9742    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012091854907045461, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9514    0.9946    0.9725      1298\n",
      "           1     0.9937    0.9439    0.9682      1177\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9726    0.9693    0.9703      2475\n",
      "weighted avg     0.9715    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013244188494152494, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.9895    0.9738      1241\n",
      "           1     0.9891    0.9571    0.9728      1234\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9739    0.9733    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.041806062062582e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9678    0.9898    0.9787      1276\n",
      "           1     0.9889    0.9650    0.9768      1199\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9784    0.9774    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012710000228400182, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9555    0.9900    0.9725      1302\n",
      "           1     0.9885    0.9488    0.9682      1173\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9720    0.9694    0.9704      2475\n",
      "weighted avg     0.9711    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012594752540492048, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9931    0.9783      1295\n",
      "           1     0.9921    0.9593    0.9754      1180\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9781    0.9762    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.97009384752524e-05, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9727    0.9884    0.9805      1296\n",
      "           1     0.9870    0.9695    0.9782      1179\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9799    0.9789    0.9793      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011560400026013153, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.9962    0.9812      1311\n",
      "           1     0.9956    0.9613    0.9781      1164\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9811    0.9788    0.9797      2475\n",
      "weighted avg     0.9803    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010859798000316428, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9672    0.9901    0.9785      1309\n",
      "           1     0.9885    0.9623    0.9752      1166\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9779    0.9762    0.9769      2475\n",
      "weighted avg     0.9772    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011311318838235103, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9652    0.9903    0.9776      1234\n",
      "           1     0.9901    0.9645    0.9771      1241\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9777    0.9774    0.9774      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "created model_classifier_config_68.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011411308339147856, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9569    0.9908    0.9735      1300\n",
      "           1     0.9894    0.9506    0.9696      1175\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9731    0.9707    0.9716      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.442200865408386e-05, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9605    0.9883    0.9742      1281\n",
      "           1     0.9870    0.9564    0.9715      1194\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9738    0.9724    0.9729      2475\n",
      "weighted avg     0.9733    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012455434811235678, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9555    0.9875    0.9713      1284\n",
      "           1     0.9861    0.9505    0.9679      1191\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9708    0.9690    0.9696      2475\n",
      "weighted avg     0.9702    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012075926920380255, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9968    0.9816      1256\n",
      "           1     0.9966    0.9647    0.9804      1219\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9817    0.9808    0.9810      2475\n",
      "weighted avg     0.9815    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001151044320578527, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9906    0.9775      1273\n",
      "           1     0.9897    0.9617    0.9755      1202\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9773    0.9762    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013916167044880415, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9550    0.9952    0.9747      1258\n",
      "           1     0.9948    0.9515    0.9727      1217\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9749    0.9734    0.9737      2475\n",
      "weighted avg     0.9746    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010279832765309498, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9946    0.9794      1290\n",
      "           1     0.9939    0.9603    0.9768      1185\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9793    0.9775    0.9781      2475\n",
      "weighted avg     0.9787    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012435483511048133, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9900    0.9728      1301\n",
      "           1     0.9885    0.9497    0.9687      1174\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9723    0.9699    0.9708      2475\n",
      "weighted avg     0.9715    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010612233118577437, Accuracy: 98.46464646464646%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9772    0.9938    0.9854      1294\n",
      "           1     0.9931    0.9746    0.9838      1181\n",
      "\n",
      "    accuracy                         0.9846      2475\n",
      "   macro avg     0.9852    0.9842    0.9846      2475\n",
      "weighted avg     0.9848    0.9846    0.9846      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.294167311504634e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9699    0.9910    0.9803      1333\n",
      "           1     0.9892    0.9641    0.9765      1142\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9796    0.9775    0.9784      2475\n",
      "weighted avg     0.9788    0.9786    0.9786      2475\n",
      "\n",
      "created model_classifier_config_69.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012000648361263853, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9569    0.9961    0.9761      1271\n",
      "           1     0.9957    0.9527    0.9737      1204\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9763    0.9744    0.9749      2475\n",
      "weighted avg     0.9758    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013253167422130855, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9931    0.9781      1305\n",
      "           1     0.9920    0.9581    0.9748      1170\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9778    0.9756    0.9764      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011431008276313243, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9574    0.9892    0.9730      1295\n",
      "           1     0.9877    0.9517    0.9694      1180\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9725    0.9704    0.9712      2475\n",
      "weighted avg     0.9718    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001280176489040105, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9946    0.9758      1297\n",
      "           1     0.9938    0.9516    0.9722      1178\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9757    0.9731    0.9740      2475\n",
      "weighted avg     0.9749    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011511379420155227, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9870    0.9769      1309\n",
      "           1     0.9851    0.9623    0.9735      1166\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9761    0.9746    0.9752      2475\n",
      "weighted avg     0.9755    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.455248562976567e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9875    0.9784      1284\n",
      "           1     0.9863    0.9664    0.9763      1191\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9779    0.9770    0.9773      2475\n",
      "weighted avg     0.9775    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011897232797410753, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9601    0.9874    0.9735      1266\n",
      "           1     0.9864    0.9570    0.9715      1209\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9732    0.9722    0.9725      2475\n",
      "weighted avg     0.9729    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012435157190669667, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9633    0.9946    0.9787      1292\n",
      "           1     0.9939    0.9586    0.9759      1183\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9786    0.9766    0.9773      2475\n",
      "weighted avg     0.9779    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010946304509134004, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9946    0.9750      1295\n",
      "           1     0.9938    0.9500    0.9714      1180\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9750    0.9723    0.9732      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012624350160059302, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9470    0.9952    0.9705      1256\n",
      "           1     0.9948    0.9426    0.9680      1219\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9709    0.9689    0.9692      2475\n",
      "weighted avg     0.9705    0.9693    0.9693      2475\n",
      "\n",
      "created model_classifier_config_70.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012701242560088033, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9538    0.9904    0.9718      1251\n",
      "           1     0.9898    0.9510    0.9700      1224\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9718    0.9707    0.9709      2475\n",
      "weighted avg     0.9716    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013302415007292623, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9665    0.9941    0.9801      1362\n",
      "           1     0.9926    0.9578    0.9749      1113\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9795    0.9759    0.9775      2475\n",
      "weighted avg     0.9782    0.9778    0.9777      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011531764208668411, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9868    0.9773      1288\n",
      "           1     0.9854    0.9646    0.9749      1187\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9767    0.9757    0.9761      2475\n",
      "weighted avg     0.9763    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012675767595117743, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9938    0.9787      1292\n",
      "           1     0.9930    0.9594    0.9759      1183\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9785    0.9766    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012780530886216597, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9548    0.9899    0.9720      1281\n",
      "           1     0.9887    0.9497    0.9688      1194\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9717    0.9698    0.9704      2475\n",
      "weighted avg     0.9711    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.86853596176764e-05, Accuracy: 98.54545454545455%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9779    0.9946    0.9862      1292\n",
      "           1     0.9940    0.9755    0.9846      1183\n",
      "\n",
      "    accuracy                         0.9855      2475\n",
      "   macro avg     0.9860    0.9850    0.9854      2475\n",
      "weighted avg     0.9856    0.9855    0.9854      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010383809756751012, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9877    0.9764      1299\n",
      "           1     0.9860    0.9609    0.9733      1176\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9757    0.9743    0.9749      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013042787409792042, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9575    0.9945    0.9756      1269\n",
      "           1     0.9939    0.9536    0.9733      1206\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9757    0.9740    0.9745      2475\n",
      "weighted avg     0.9753    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011939508445335157, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9532    0.9952    0.9737      1248\n",
      "           1     0.9949    0.9503    0.9721      1227\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9740    0.9727    0.9729      2475\n",
      "weighted avg     0.9739    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013669722911083338, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9558    0.9899    0.9725      1288\n",
      "           1     0.9886    0.9503    0.9691      1187\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9722    0.9701    0.9708      2475\n",
      "weighted avg     0.9715    0.9709    0.9709      2475\n",
      "\n",
      "created model_classifier_config_71.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001149263767280964, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9907    0.9763      1290\n",
      "           1     0.9895    0.9578    0.9734      1185\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9743    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012576654703930172, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9564    0.9914    0.9736      1283\n",
      "           1     0.9904    0.9513    0.9705      1192\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9734    0.9714    0.9720      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012405493343719328, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9558    0.9925    0.9738      1330\n",
      "           1     0.9909    0.9467    0.9683      1145\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9733    0.9696    0.9710      2475\n",
      "weighted avg     0.9720    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012119013251680316, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9914    0.9796      1282\n",
      "           1     0.9905    0.9648    0.9775      1193\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9793    0.9781    0.9785      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012344530435523602, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9569    0.9898    0.9731      1279\n",
      "           1     0.9887    0.9523    0.9702      1196\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9728    0.9711    0.9716      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.797828366058042e-05, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9930    0.9778      1285\n",
      "           1     0.9922    0.9588    0.9752      1190\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9776    0.9759    0.9765      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.780016812411221e-05, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9682    0.9961    0.9819      1282\n",
      "           1     0.9957    0.9648    0.9800      1193\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9819    0.9804    0.9810      2475\n",
      "weighted avg     0.9814    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012363513912817445, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9616    0.9894    0.9753      1316\n",
      "           1     0.9875    0.9551    0.9711      1159\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9746    0.9722    0.9732      2475\n",
      "weighted avg     0.9737    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010443908096563937, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9906    0.9758      1281\n",
      "           1     0.9896    0.9573    0.9732      1194\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9755    0.9740    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011947781750650117, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9903    0.9754      1242\n",
      "           1     0.9900    0.9594    0.9745      1233\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9754    0.9749    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "created model_classifier_config_72.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011137792558381051, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9536    0.9899    0.9714      1287\n",
      "           1     0.9886    0.9478    0.9678      1188\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9711    0.9689    0.9696      2475\n",
      "weighted avg     0.9704    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001268781887160407, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9878    0.9773      1310\n",
      "           1     0.9859    0.9622    0.9739      1165\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9765    0.9750    0.9756      2475\n",
      "weighted avg     0.9760    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001327875948915578, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9913    0.9758      1263\n",
      "           1     0.9906    0.9579    0.9740      1212\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9757    0.9746    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.797467426820234e-05, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9725    0.9861    0.9793      1293\n",
      "           1     0.9845    0.9695    0.9770      1182\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9785    0.9778    0.9781      2475\n",
      "weighted avg     0.9783    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010211678165377992, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9953    0.9819      1281\n",
      "           1     0.9948    0.9657    0.9800      1194\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9818    0.9805    0.9810      2475\n",
      "weighted avg     0.9814    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001114203833570384, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9591    0.9932    0.9758      1322\n",
      "           1     0.9919    0.9514    0.9712      1153\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9755    0.9723    0.9735      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013754152589374118, Accuracy: 96.64646464646465%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9447    0.9929    0.9682      1273\n",
      "           1     0.9921    0.9384    0.9645      1202\n",
      "\n",
      "    accuracy                         0.9665      2475\n",
      "   macro avg     0.9684    0.9657    0.9664      2475\n",
      "weighted avg     0.9677    0.9665    0.9664      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012178281039902658, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9589    0.9920    0.9752      1248\n",
      "           1     0.9916    0.9568    0.9739      1227\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9753    0.9744    0.9745      2475\n",
      "weighted avg     0.9751    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012777363411103836, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.9938    0.9757      1292\n",
      "           1     0.9930    0.9527    0.9724      1183\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9756    0.9732    0.9740      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012668523824576177, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9892    0.9769      1301\n",
      "           1     0.9877    0.9600    0.9737      1174\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9762    0.9746    0.9753      2475\n",
      "weighted avg     0.9757    0.9754    0.9753      2475\n",
      "\n",
      "created model_classifier_config_73.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.96454429385638e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9884    0.9790      1298\n",
      "           1     0.9870    0.9660    0.9764      1177\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9784    0.9772    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010592129194375241, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9640    0.9954    0.9795      1293\n",
      "           1     0.9947    0.9594    0.9767      1182\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9794    0.9774    0.9781      2475\n",
      "weighted avg     0.9787    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001189490400179468, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9545    0.9910    0.9724      1228\n",
      "           1     0.9908    0.9535    0.9718      1247\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9727    0.9723    0.9721      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001151402701031078, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9561    0.9947    0.9750      1314\n",
      "           1     0.9937    0.9483    0.9705      1161\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9749    0.9715    0.9727      2475\n",
      "weighted avg     0.9737    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012442792003804988, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9938    0.9791      1299\n",
      "           1     0.9930    0.9600    0.9762      1176\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9789    0.9769    0.9777      2475\n",
      "weighted avg     0.9782    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010050245607742155, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9670    0.9873    0.9770      1334\n",
      "           1     0.9847    0.9606    0.9725      1141\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9758    0.9739    0.9747      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010992227178631407, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9758    0.9850    0.9804      1270\n",
      "           1     0.9841    0.9743    0.9791      1205\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9799    0.9797    0.9798      2475\n",
      "weighted avg     0.9798    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001184304796084009, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9870    0.9757      1304\n",
      "           1     0.9851    0.9599    0.9723      1171\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9749    0.9734    0.9740      2475\n",
      "weighted avg     0.9744    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012691185931966762, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.9945    0.9761      1272\n",
      "           1     0.9939    0.9543    0.9737      1203\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9761    0.9744    0.9749      2475\n",
      "weighted avg     0.9756    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012296787416092074, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9652    0.9913    0.9780      1258\n",
      "           1     0.9907    0.9630    0.9767      1217\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9779    0.9771    0.9774      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "created model_classifier_config_74.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.708906062925705e-05, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9650    0.9923    0.9785      1307\n",
      "           1     0.9912    0.9598    0.9752      1168\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9781    0.9761    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001098902327845795, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9735    0.9900    0.9817      1300\n",
      "           1     0.9887    0.9702    0.9794      1175\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9811    0.9801    0.9805      2475\n",
      "weighted avg     0.9807    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012893538282375143, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9650    0.9883    0.9765      1283\n",
      "           1     0.9871    0.9614    0.9741      1192\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9760    0.9749    0.9753      2475\n",
      "weighted avg     0.9756    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011490801368096862, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9877    0.9776      1306\n",
      "           1     0.9860    0.9632    0.9745      1169\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9769    0.9755    0.9761      2475\n",
      "weighted avg     0.9764    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010875085387567077, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9752    0.9890    0.9820      1272\n",
      "           1     0.9882    0.9734    0.9807      1203\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9817    0.9812    0.9814      2475\n",
      "weighted avg     0.9815    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010948609523098879, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9930    0.9805      1292\n",
      "           1     0.9922    0.9645    0.9781      1183\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9802    0.9788    0.9793      2475\n",
      "weighted avg     0.9797    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012482317710163618, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9578    0.9911    0.9742      1237\n",
      "           1     0.9908    0.9564    0.9733      1238\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9743    0.9737    0.9737      2475\n",
      "weighted avg     0.9743    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010686245229509142, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9604    0.9954    0.9776      1291\n",
      "           1     0.9947    0.9552    0.9746      1184\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9776    0.9753    0.9761      2475\n",
      "weighted avg     0.9768    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011206074796541773, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9672    0.9863    0.9767      1315\n",
      "           1     0.9841    0.9621    0.9730      1160\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9757    0.9742    0.9748      2475\n",
      "weighted avg     0.9751    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010961557578558874, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9633    0.9937    0.9782      1267\n",
      "           1     0.9932    0.9603    0.9764      1208\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9782    0.9770    0.9773      2475\n",
      "weighted avg     0.9779    0.9774    0.9774      2475\n",
      "\n",
      "created model_classifier_config_75.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011551549940398245, Accuracy: 98.38383838383838%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9740    0.9962    0.9850      1315\n",
      "           1     0.9956    0.9698    0.9825      1160\n",
      "\n",
      "    accuracy                         0.9838      2475\n",
      "   macro avg     0.9848    0.9830    0.9837      2475\n",
      "weighted avg     0.9841    0.9838    0.9838      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010229077303048336, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9888    0.9741      1255\n",
      "           1     0.9882    0.9574    0.9725      1220\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9740    0.9731    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001235530051318082, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9908    0.9788      1305\n",
      "           1     0.9895    0.9624    0.9757      1170\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9783    0.9766    0.9773      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012873007492585615, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9881    0.9737      1256\n",
      "           1     0.9873    0.9573    0.9721      1219\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9735    0.9727    0.9729      2475\n",
      "weighted avg     0.9733    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001324283294003419, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9927    0.9774      1239\n",
      "           1     0.9925    0.9612    0.9766      1236\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9775    0.9770    0.9770      2475\n",
      "weighted avg     0.9774    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011932625011964277, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9608    0.9925    0.9764      1334\n",
      "           1     0.9909    0.9527    0.9714      1141\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9758    0.9726    0.9739      2475\n",
      "weighted avg     0.9747    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011528199369257146, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9705    0.9877    0.9790      1300\n",
      "           1     0.9861    0.9668    0.9764      1175\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9783    0.9773    0.9777      2475\n",
      "weighted avg     0.9779    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013016357867404668, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9578    0.9908    0.9740      1306\n",
      "           1     0.9893    0.9512    0.9699      1169\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9736    0.9710    0.9720      2475\n",
      "weighted avg     0.9727    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011729271423937095, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.9907    0.9786      1290\n",
      "           1     0.9896    0.9629    0.9760      1185\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9782    0.9768    0.9773      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001130984527896149, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9574    0.9921    0.9745      1270\n",
      "           1     0.9914    0.9535    0.9721      1205\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9744    0.9728    0.9733      2475\n",
      "weighted avg     0.9740    0.9733    0.9733      2475\n",
      "\n",
      "created model_classifier_config_76.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011152724726031525, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9932    0.9751      1321\n",
      "           1     0.9919    0.9497    0.9703      1154\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9748    0.9715    0.9727      2475\n",
      "weighted avg     0.9736    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013281799627072884, Accuracy: 96.24242424242425%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9401    0.9915    0.9651      1297\n",
      "           1     0.9901    0.9304    0.9593      1178\n",
      "\n",
      "    accuracy                         0.9624      2475\n",
      "   macro avg     0.9651    0.9610    0.9622      2475\n",
      "weighted avg     0.9639    0.9624    0.9623      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.98334511361941e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9659    0.9952    0.9803      1251\n",
      "           1     0.9949    0.9641    0.9793      1224\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9804    0.9796    0.9798      2475\n",
      "weighted avg     0.9802    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010610555157516942, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9806    0.9764      1286\n",
      "           1     0.9788    0.9697    0.9742      1189\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9755    0.9751    0.9753      2475\n",
      "weighted avg     0.9754    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.668889069798017e-05, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9729    0.9862    0.9795      1309\n",
      "           1     0.9843    0.9691    0.9767      1166\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9786    0.9777    0.9781      2475\n",
      "weighted avg     0.9783    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011770772512512977, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9953    0.9763      1285\n",
      "           1     0.9947    0.9529    0.9734      1190\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9764    0.9741    0.9749      2475\n",
      "weighted avg     0.9757    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.605461900884455e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9670    0.9925    0.9796      1330\n",
      "           1     0.9910    0.9607    0.9756      1145\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9790    0.9766    0.9776      2475\n",
      "weighted avg     0.9781    0.9778    0.9777      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010302540629801124, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9775    0.9831    0.9803      1240\n",
      "           1     0.9829    0.9773    0.9801      1235\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9802    0.9802    0.9802      2475\n",
      "weighted avg     0.9802    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010782897171348032, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9938    0.9748      1284\n",
      "           1     0.9930    0.9513    0.9717      1191\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9748    0.9725    0.9732      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00015049779053890344, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9432    0.9968    0.9693      1267\n",
      "           1     0.9965    0.9371    0.9659      1208\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9699    0.9670    0.9676      2475\n",
      "weighted avg     0.9692    0.9677    0.9676      2475\n",
      "\n",
      "created model_classifier_config_77.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012554720495686387, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9554    0.9907    0.9727      1297\n",
      "           1     0.9894    0.9491    0.9688      1178\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9724    0.9699    0.9708      2475\n",
      "weighted avg     0.9716    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001305534562679252, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.9915    0.9743      1299\n",
      "           1     0.9903    0.9515    0.9705      1176\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9739    0.9715    0.9724      2475\n",
      "weighted avg     0.9731    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011481355236034201, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9610    0.9954    0.9779      1311\n",
      "           1     0.9946    0.9545    0.9741      1164\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9778    0.9749    0.9760      2475\n",
      "weighted avg     0.9768    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001247862884492585, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9513    0.9923    0.9714      1299\n",
      "           1     0.9911    0.9439    0.9669      1176\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9712    0.9681    0.9691      2475\n",
      "weighted avg     0.9702    0.9693    0.9692      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011321286360422771, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.9880    0.9762      1246\n",
      "           1     0.9875    0.9634    0.9753      1229\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9761    0.9757    0.9757      2475\n",
      "weighted avg     0.9760    0.9758    0.9758      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001208060227259241, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9929    0.9743      1262\n",
      "           1     0.9923    0.9530    0.9722      1213\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9744    0.9729    0.9733      2475\n",
      "weighted avg     0.9740    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011072054354831425, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9908    0.9750      1300\n",
      "           1     0.9894    0.9540    0.9714      1175\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9746    0.9724    0.9732      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011254534576878403, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.9893    0.9732      1211\n",
      "           1     0.9894    0.9581    0.9735      1264\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9735    0.9737    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001101415115173417, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9638    0.9932    0.9783      1315\n",
      "           1     0.9920    0.9578    0.9746      1160\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9779    0.9755    0.9764      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011488000250825978, Accuracy: 98.34343434343434%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9771    0.9925    0.9847      1330\n",
      "           1     0.9911    0.9729    0.9819      1145\n",
      "\n",
      "    accuracy                         0.9834      2475\n",
      "   macro avg     0.9841    0.9827    0.9833      2475\n",
      "weighted avg     0.9836    0.9834    0.9834      2475\n",
      "\n",
      "created model_classifier_config_78.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001066884518873812, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.9929    0.9753      1273\n",
      "           1     0.9922    0.9542    0.9729      1202\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9753    0.9736    0.9741      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010563756781395035, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9894    0.9743      1323\n",
      "           1     0.9874    0.9523    0.9695      1152\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9735    0.9708    0.9719      2475\n",
      "weighted avg     0.9726    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014031271139780681, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    0.9915    0.9743      1300\n",
      "           1     0.9903    0.9515    0.9705      1175\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9740    0.9715    0.9724      2475\n",
      "weighted avg     0.9731    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010745308615944602, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.9929    0.9774      1265\n",
      "           1     0.9923    0.9595    0.9756      1210\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9774    0.9762    0.9765      2475\n",
      "weighted avg     0.9770    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010189690975227742, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9727    0.9877    0.9801      1297\n",
      "           1     0.9862    0.9694    0.9777      1178\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9794    0.9786    0.9789      2475\n",
      "weighted avg     0.9791    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012120411853597621, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9951    0.9739      1236\n",
      "           1     0.9949    0.9516    0.9728      1239\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9742    0.9734    0.9733      2475\n",
      "weighted avg     0.9742    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011545327576723966, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.9937    0.9779      1272\n",
      "           1     0.9931    0.9593    0.9759      1203\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9779    0.9765    0.9769      2475\n",
      "weighted avg     0.9775    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011864689865497628, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9662    0.9932    0.9795      1323\n",
      "           1     0.9919    0.9601    0.9757      1152\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9791    0.9766    0.9776      2475\n",
      "weighted avg     0.9782    0.9778    0.9777      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001337212263935744, Accuracy: 96.84848484848484%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9538    0.9867    0.9700      1276\n",
      "           1     0.9853    0.9491    0.9669      1199\n",
      "\n",
      "    accuracy                         0.9685      2475\n",
      "   macro avg     0.9695    0.9679    0.9684      2475\n",
      "weighted avg     0.9690    0.9685    0.9685      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013165797549064714, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9946    0.9752      1305\n",
      "           1     0.9937    0.9496    0.9712      1170\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9751    0.9721    0.9732      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "created model_classifier_config_79.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000124404261810611, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9931    0.9769      1299\n",
      "           1     0.9921    0.9558    0.9736      1176\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9767    0.9744    0.9752      2475\n",
      "weighted avg     0.9759    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011469940043459035, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9931    0.9801      1312\n",
      "           1     0.9920    0.9622    0.9769      1163\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9797    0.9777    0.9785      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012973027698921435, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9954    0.9784      1298\n",
      "           1     0.9947    0.9567    0.9753      1177\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9784    0.9760    0.9769      2475\n",
      "weighted avg     0.9776    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001005533126869587, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9874    0.9775      1274\n",
      "           1     0.9864    0.9650    0.9756      1201\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9770    0.9762    0.9765      2475\n",
      "weighted avg     0.9768    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014139295828462852, Accuracy: 96.60606060606061%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9451    0.9922    0.9681      1284\n",
      "           1     0.9911    0.9379    0.9638      1191\n",
      "\n",
      "    accuracy                         0.9661      2475\n",
      "   macro avg     0.9681    0.9650    0.9659      2475\n",
      "weighted avg     0.9673    0.9661    0.9660      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.025386186561199e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9650    0.9929    0.9788      1276\n",
      "           1     0.9923    0.9616    0.9767      1199\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9786    0.9773    0.9777      2475\n",
      "weighted avg     0.9782    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011739028824700249, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9947    0.9812      1309\n",
      "           1     0.9938    0.9631    0.9782      1166\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9809    0.9789    0.9797      2475\n",
      "weighted avg     0.9802    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001196440030830075, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9527    0.9913    0.9716      1260\n",
      "           1     0.9905    0.9490    0.9693      1215\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9716    0.9701    0.9705      2475\n",
      "weighted avg     0.9713    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012877889353819568, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9892    0.9779      1295\n",
      "           1     0.9878    0.9627    0.9751      1180\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9773    0.9760    0.9765      2475\n",
      "weighted avg     0.9768    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012671491714439008, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9541    0.9865    0.9700      1263\n",
      "           1     0.9855    0.9505    0.9677      1212\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9698    0.9685    0.9688      2475\n",
      "weighted avg     0.9694    0.9689    0.9689      2475\n",
      "\n",
      "created model_classifier_config_80.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001298492725449379, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9590    0.9920    0.9752      1249\n",
      "           1     0.9915    0.9568    0.9738      1226\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9753    0.9744    0.9745      2475\n",
      "weighted avg     0.9751    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011497150165866119, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9922    0.9787      1275\n",
      "           1     0.9914    0.9625    0.9767      1200\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9773    0.9777      2475\n",
      "weighted avg     0.9781    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011510920645010592, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9859    0.9727      1281\n",
      "           1     0.9845    0.9556    0.9698      1194\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9721    0.9708    0.9712      2475\n",
      "weighted avg     0.9717    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.174336989720662e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9639    0.9929    0.9782      1264\n",
      "           1     0.9923    0.9612    0.9765      1211\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9781    0.9770    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011241199994328046, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9564    0.9914    0.9736      1282\n",
      "           1     0.9904    0.9514    0.9705      1193\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9734    0.9714    0.9720      2475\n",
      "weighted avg     0.9728    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012612484621279168, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9930    0.9753      1291\n",
      "           1     0.9921    0.9527    0.9720      1184\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9751    0.9729    0.9736      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013553342734924471, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9895    0.9782      1337\n",
      "           1     0.9874    0.9605    0.9737      1138\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9772    0.9750    0.9760      2475\n",
      "weighted avg     0.9764    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014480246437920463, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9606    0.9906    0.9754      1281\n",
      "           1     0.9896    0.9564    0.9727      1194\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9751    0.9735    0.9741      2475\n",
      "weighted avg     0.9746    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013237230404458865, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9916    0.9801      1313\n",
      "           1     0.9903    0.9639    0.9769      1162\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9795    0.9777    0.9785      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011113941067396992, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9662    0.9931    0.9795      1297\n",
      "           1     0.9921    0.9618    0.9767      1178\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9792    0.9774    0.9781      2475\n",
      "weighted avg     0.9786    0.9782    0.9782      2475\n",
      "\n",
      "created model_classifier_config_81.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.610538530831385e-05, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9912    0.9761      1257\n",
      "           1     0.9907    0.9589    0.9746      1218\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9760    0.9751    0.9753      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00015126846956484244, Accuracy: 96.68686868686869%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9431    0.9961    0.9689      1282\n",
      "           1     0.9955    0.9355    0.9646      1193\n",
      "\n",
      "    accuracy                         0.9669      2475\n",
      "   macro avg     0.9693    0.9658    0.9667      2475\n",
      "weighted avg     0.9684    0.9669    0.9668      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001238098590060918, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9925    0.9767      1329\n",
      "           1     0.9909    0.9538    0.9720      1146\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9762    0.9731    0.9743      2475\n",
      "weighted avg     0.9751    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011137198017101095, Accuracy: 98.22222222222223%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9714    0.9945    0.9828      1265\n",
      "           1     0.9941    0.9694    0.9816      1210\n",
      "\n",
      "    accuracy                         0.9822      2475\n",
      "   macro avg     0.9827    0.9819    0.9822      2475\n",
      "weighted avg     0.9825    0.9822    0.9822      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001228048163230973, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9701    0.9883    0.9791      1282\n",
      "           1     0.9872    0.9673    0.9771      1193\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9787    0.9778    0.9781      2475\n",
      "weighted avg     0.9783    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010114467806286282, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9905    0.9763      1267\n",
      "           1     0.9898    0.9594    0.9744      1208\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9761    0.9750    0.9753      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012845409036886814, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9520    0.9954    0.9732      1315\n",
      "           1     0.9945    0.9431    0.9681      1160\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9733    0.9693    0.9707      2475\n",
      "weighted avg     0.9719    0.9709    0.9708      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013536014039107044, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9542    0.9891    0.9713      1284\n",
      "           1     0.9878    0.9488    0.9679      1191\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9710    0.9689    0.9696      2475\n",
      "weighted avg     0.9703    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010381965926199248, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9891    0.9789      1290\n",
      "           1     0.9879    0.9654    0.9765      1185\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9784    0.9773    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011970509483356668, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9599    0.9946    0.9769      1299\n",
      "           1     0.9938    0.9541    0.9735      1176\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9768    0.9743    0.9752      2475\n",
      "weighted avg     0.9760    0.9754    0.9753      2475\n",
      "\n",
      "created model_classifier_config_82.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014036944117208923, Accuracy: 96.8080808080808%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9489    0.9914    0.9697      1275\n",
      "           1     0.9904    0.9433    0.9663      1200\n",
      "\n",
      "    accuracy                         0.9681      2475\n",
      "   macro avg     0.9697    0.9674    0.9680      2475\n",
      "weighted avg     0.9690    0.9681    0.9680      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010417449052887733, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9608    0.9945    0.9774      1281\n",
      "           1     0.9939    0.9564    0.9748      1194\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9773    0.9755    0.9761      2475\n",
      "weighted avg     0.9768    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010206431150436401, Accuracy: 98.22222222222223%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9719    0.9946    0.9831      1287\n",
      "           1     0.9940    0.9689    0.9812      1188\n",
      "\n",
      "    accuracy                         0.9822      2475\n",
      "   macro avg     0.9829    0.9817    0.9822      2475\n",
      "weighted avg     0.9825    0.9822    0.9822      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00015870643986596, Accuracy: 96.56565656565657%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9446    0.9914    0.9674      1272\n",
      "           1     0.9904    0.9385    0.9637      1203\n",
      "\n",
      "    accuracy                         0.9657      2475\n",
      "   macro avg     0.9675    0.9649    0.9656      2475\n",
      "weighted avg     0.9668    0.9657    0.9656      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.894591088246818e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9665    0.9939    0.9800      1308\n",
      "           1     0.9929    0.9614    0.9769      1167\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9797    0.9777    0.9785      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001310049102763937, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9591    0.9914    0.9750      1278\n",
      "           1     0.9905    0.9549    0.9724      1197\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9748    0.9731    0.9737      2475\n",
      "weighted avg     0.9743    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011235515878658102, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9890    0.9755      1267\n",
      "           1     0.9881    0.9594    0.9735      1208\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9752    0.9742    0.9745      2475\n",
      "weighted avg     0.9749    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011051748738144384, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9692    0.9923    0.9806      1300\n",
      "           1     0.9913    0.9651    0.9780      1175\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9802    0.9787    0.9793      2475\n",
      "weighted avg     0.9797    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012419149129077643, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9906    0.9746      1280\n",
      "           1     0.9896    0.9548    0.9719      1195\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9744    0.9727    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.386253477347018e-05, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9711    0.9917    0.9813      1322\n",
      "           1     0.9902    0.9662    0.9781      1153\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9807    0.9789    0.9797      2475\n",
      "weighted avg     0.9800    0.9798    0.9798      2475\n",
      "\n",
      "created model_classifier_config_83.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010897703845091541, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9679    0.9933    0.9804      1334\n",
      "           1     0.9919    0.9614    0.9764      1141\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9799    0.9773    0.9784      2475\n",
      "weighted avg     0.9789    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011321380282893326, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9532    0.9896    0.9711      1256\n",
      "           1     0.9889    0.9500    0.9690      1219\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9711    0.9698    0.9701      2475\n",
      "weighted avg     0.9708    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001310016651346226, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.9890    0.9731      1278\n",
      "           1     0.9879    0.9532    0.9702      1197\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9727    0.9711    0.9716      2475\n",
      "weighted avg     0.9722    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012969420413778284, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9532    0.9900    0.9712      1295\n",
      "           1     0.9885    0.9466    0.9671      1180\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9708    0.9683    0.9692      2475\n",
      "weighted avg     0.9700    0.9693    0.9693      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010974660365268437, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9914    0.9762      1282\n",
      "           1     0.9905    0.9573    0.9736      1193\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9759    0.9743    0.9749      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.291751818223434e-05, Accuracy: 98.26262626262626%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9728    0.9955    0.9840      1327\n",
      "           1     0.9946    0.9678    0.9810      1148\n",
      "\n",
      "    accuracy                         0.9826      2475\n",
      "   macro avg     0.9837    0.9816    0.9825      2475\n",
      "weighted avg     0.9829    0.9826    0.9826      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011280816311788077, Accuracy: 98.22222222222223%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9730    0.9929    0.9828      1268\n",
      "           1     0.9924    0.9710    0.9816      1207\n",
      "\n",
      "    accuracy                         0.9822      2475\n",
      "   macro avg     0.9827    0.9820    0.9822      2475\n",
      "weighted avg     0.9824    0.9822    0.9822      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013376574323634908, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9548    0.9928    0.9735      1256\n",
      "           1     0.9923    0.9516    0.9715      1219\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9736    0.9722    0.9725      2475\n",
      "weighted avg     0.9733    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012033527246629348, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9541    0.9961    0.9747      1274\n",
      "           1     0.9956    0.9492    0.9719      1201\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9749    0.9726    0.9733      2475\n",
      "weighted avg     0.9743    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010930697424243195, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9923    0.9784      1300\n",
      "           1     0.9912    0.9600    0.9754      1175\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9780    0.9762    0.9769      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "created model_classifier_config_84.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011291434066464203, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9877    0.9761      1304\n",
      "           1     0.9860    0.9599    0.9727      1171\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9754    0.9738    0.9744      2475\n",
      "weighted avg     0.9748    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.92897898500616e-05, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9743    0.9889    0.9816      1265\n",
      "           1     0.9882    0.9727    0.9804      1210\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9813    0.9808    0.9810      2475\n",
      "weighted avg     0.9811    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011330299004159792, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9570    0.9938    0.9751      1298\n",
      "           1     0.9929    0.9507    0.9714      1177\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9749    0.9723    0.9732      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011770141245138765, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.9859    0.9719      1279\n",
      "           1     0.9845    0.9540    0.9690      1196\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9713    0.9700    0.9704      2475\n",
      "weighted avg     0.9709    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012769222259521485, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.9869    0.9712      1299\n",
      "           1     0.9850    0.9498    0.9671      1176\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9705    0.9684    0.9692      2475\n",
      "weighted avg     0.9698    0.9693    0.9693      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010939048697250058, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9585    0.9916    0.9747      1303\n",
      "           1     0.9902    0.9522    0.9709      1172\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9743    0.9719    0.9728      2475\n",
      "weighted avg     0.9735    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.435990242042927e-05, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9701    0.9946    0.9822      1307\n",
      "           1     0.9938    0.9658    0.9796      1168\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9820    0.9802    0.9809      2475\n",
      "weighted avg     0.9813    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012969641673444497, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9495    0.9953    0.9719      1285\n",
      "           1     0.9947    0.9429    0.9681      1190\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9721    0.9691    0.9700      2475\n",
      "weighted avg     0.9712    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.346976424708511e-05, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9720    0.9886    0.9803      1231\n",
      "           1     0.9886    0.9719    0.9801      1244\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9803    0.9802    0.9802      2475\n",
      "weighted avg     0.9803    0.9802    0.9802      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012859987490104906, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9728    0.9923    0.9825      1299\n",
      "           1     0.9913    0.9694    0.9802      1176\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9821    0.9808    0.9813      2475\n",
      "weighted avg     0.9816    0.9814    0.9814      2475\n",
      "\n",
      "created model_classifier_config_85.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014024392221913194, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9516    0.9953    0.9730      1283\n",
      "           1     0.9947    0.9455    0.9695      1192\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9731    0.9704    0.9712      2475\n",
      "weighted avg     0.9723    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011833943802900988, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.9898    0.9745      1273\n",
      "           1     0.9888    0.9559    0.9721      1202\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9742    0.9728    0.9733      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000159586084009421, Accuracy: 96.72727272727273%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9507    0.9884    0.9692      1288\n",
      "           1     0.9868    0.9444    0.9651      1187\n",
      "\n",
      "    accuracy                         0.9673      2475\n",
      "   macro avg     0.9688    0.9664    0.9671      2475\n",
      "weighted avg     0.9680    0.9673    0.9672      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001247575879096985, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9713    0.9902    0.9807      1331\n",
      "           1     0.9884    0.9659    0.9770      1144\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9798    0.9781    0.9788      2475\n",
      "weighted avg     0.9792    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001278270525161666, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9516    0.9953    0.9730      1285\n",
      "           1     0.9947    0.9454    0.9694      1190\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9732    0.9704    0.9712      2475\n",
      "weighted avg     0.9723    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010550758754364167, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9931    0.9778      1311\n",
      "           1     0.9920    0.9570    0.9742      1164\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9775    0.9751    0.9760      2475\n",
      "weighted avg     0.9766    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013511205562437422, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9885    0.9765      1305\n",
      "           1     0.9868    0.9598    0.9731      1170\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9758    0.9742    0.9748      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010804020997249718, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9944    0.9781      1259\n",
      "           1     0.9940    0.9597    0.9766      1216\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9782    0.9771    0.9773      2475\n",
      "weighted avg     0.9779    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012183513605233395, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9897    0.9781      1264\n",
      "           1     0.9890    0.9645    0.9766      1211\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9779    0.9771    0.9773      2475\n",
      "weighted avg     0.9776    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011685373807194257, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9553    0.9913    0.9730      1271\n",
      "           1     0.9905    0.9510    0.9703      1204\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9729    0.9712    0.9717      2475\n",
      "weighted avg     0.9724    0.9717    0.9717      2475\n",
      "\n",
      "created model_classifier_config_86.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.966106727869823e-05, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9781    0.9858    0.9820      1271\n",
      "           1     0.9849    0.9767    0.9808      1204\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9815    0.9813    0.9814      2475\n",
      "weighted avg     0.9814    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012790601361881604, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9692    0.9878    0.9784      1307\n",
      "           1     0.9860    0.9649    0.9753      1168\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9776    0.9763    0.9769      2475\n",
      "weighted avg     0.9771    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013640130108053035, Accuracy: 96.44444444444444%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9418    0.9930    0.9667      1287\n",
      "           1     0.9919    0.9335    0.9618      1188\n",
      "\n",
      "    accuracy                         0.9644      2475\n",
      "   macro avg     0.9669    0.9633    0.9643      2475\n",
      "weighted avg     0.9659    0.9644    0.9644      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001168696777989166, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9657    0.9954    0.9803      1301\n",
      "           1     0.9947    0.9608    0.9775      1174\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9802    0.9781    0.9789      2475\n",
      "weighted avg     0.9795    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012986388772425026, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.9907    0.9758      1284\n",
      "           1     0.9896    0.9572    0.9731      1191\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9755    0.9739    0.9745      2475\n",
      "weighted avg     0.9750    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 8.383284464026942e-05, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9914    0.9800      1284\n",
      "           1     0.9905    0.9656    0.9779      1191\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9797    0.9785    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011729288281816425, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9897    0.9727      1258\n",
      "           1     0.9889    0.9532    0.9707      1217\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9726    0.9714    0.9717      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010729365577601424, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9946    0.9780      1298\n",
      "           1     0.9938    0.9567    0.9749      1177\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9779    0.9756    0.9765      2475\n",
      "weighted avg     0.9771    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010102060106065538, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9953    0.9771      1267\n",
      "           1     0.9948    0.9561    0.9751      1208\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9772    0.9757    0.9761      2475\n",
      "weighted avg     0.9768    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001345275387619481, Accuracy: 96.88888888888889%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9504    0.9931    0.9713      1313\n",
      "           1     0.9918    0.9415    0.9660      1162\n",
      "\n",
      "    accuracy                         0.9689      2475\n",
      "   macro avg     0.9711    0.9673    0.9687      2475\n",
      "weighted avg     0.9699    0.9689    0.9688      2475\n",
      "\n",
      "created model_classifier_config_87.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001452399112961509, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9914    0.9773      1280\n",
      "           1     0.9905    0.9598    0.9749      1195\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9770    0.9756    0.9761      2475\n",
      "weighted avg     0.9766    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001297410630216502, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9598    0.9946    0.9769      1295\n",
      "           1     0.9938    0.9542    0.9736      1180\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9768    0.9744    0.9752      2475\n",
      "weighted avg     0.9760    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.268578555848863e-05, Accuracy: 98.58585858585859%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9777    0.9962    0.9869      1319\n",
      "           1     0.9956    0.9740    0.9847      1156\n",
      "\n",
      "    accuracy                         0.9859      2475\n",
      "   macro avg     0.9866    0.9851    0.9858      2475\n",
      "weighted avg     0.9860    0.9859    0.9858      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011249069914673314, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9514    0.9945    0.9725      1280\n",
      "           1     0.9938    0.9456    0.9691      1195\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9726    0.9701    0.9708      2475\n",
      "weighted avg     0.9719    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012720409366819593, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9660    0.9930    0.9793      1288\n",
      "           1     0.9922    0.9621    0.9769      1187\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9791    0.9776    0.9781      2475\n",
      "weighted avg     0.9786    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012411087149321432, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9686    0.9891    0.9787      1279\n",
      "           1     0.9880    0.9657    0.9767      1196\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9783    0.9774    0.9777      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011824903464076495, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9646    0.9874    0.9759      1269\n",
      "           1     0.9864    0.9619    0.9740      1206\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9755    0.9746    0.9749      2475\n",
      "weighted avg     0.9752    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.118817370347303e-05, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9859    0.9767      1276\n",
      "           1     0.9847    0.9650    0.9747      1199\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9762    0.9754    0.9757      2475\n",
      "weighted avg     0.9759    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011460337976012568, Accuracy: 96.52525252525253%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9507    0.9855    0.9678      1312\n",
      "           1     0.9830    0.9424    0.9622      1163\n",
      "\n",
      "    accuracy                         0.9653      2475\n",
      "   macro avg     0.9668    0.9640    0.9650      2475\n",
      "weighted avg     0.9659    0.9653    0.9652      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010880578045893196, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9642    0.9945    0.9791      1272\n",
      "           1     0.9940    0.9609    0.9772      1203\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9791    0.9777    0.9781      2475\n",
      "weighted avg     0.9787    0.9782    0.9782      2475\n",
      "\n",
      "created model_classifier_config_88.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001417712430761318, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9538    0.9928    0.9729      1249\n",
      "           1     0.9923    0.9511    0.9713      1226\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9731    0.9719    0.9721      2475\n",
      "weighted avg     0.9729    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.88376923281737e-05, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9721    0.9905    0.9812      1268\n",
      "           1     0.9899    0.9702    0.9799      1207\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9810    0.9804    0.9806      2475\n",
      "weighted avg     0.9808    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001082464059193929, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9899    0.9752      1292\n",
      "           1     0.9886    0.9560    0.9721      1183\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9748    0.9730    0.9736      2475\n",
      "weighted avg     0.9742    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012545079594910747, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9679    0.9931    0.9803      1306\n",
      "           1     0.9921    0.9632    0.9774      1169\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9800    0.9782    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011089390877521399, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9922    0.9739      1277\n",
      "           1     0.9913    0.9516    0.9710      1198\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9738    0.9719    0.9725      2475\n",
      "weighted avg     0.9732    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011244322916474005, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.9886    0.9756      1316\n",
      "           1     0.9867    0.9569    0.9715      1159\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9748    0.9727    0.9736      2475\n",
      "weighted avg     0.9741    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010638455248842335, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.9908    0.9737      1306\n",
      "           1     0.9893    0.9504    0.9695      1169\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9732    0.9706    0.9716      2475\n",
      "weighted avg     0.9723    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011681499505283857, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9662    0.9938    0.9798      1294\n",
      "           1     0.9930    0.9619    0.9772      1181\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9796    0.9779    0.9785      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010951165900085912, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9705    0.9907    0.9805      1293\n",
      "           1     0.9896    0.9670    0.9782      1182\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9800    0.9789    0.9793      2475\n",
      "weighted avg     0.9796    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010685560980228463, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9587    0.9890    0.9736      1269\n",
      "           1     0.9880    0.9552    0.9713      1206\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9734    0.9721    0.9725      2475\n",
      "weighted avg     0.9730    0.9725    0.9725      2475\n",
      "\n",
      "created model_classifier_config_89.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010875019160183993, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9946    0.9798      1291\n",
      "           1     0.9939    0.9611    0.9772      1184\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9796    0.9779    0.9785      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011374865818505336, Accuracy: 97.97979797979798%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9676    0.9955    0.9813      1321\n",
      "           1     0.9946    0.9619    0.9780      1154\n",
      "\n",
      "    accuracy                         0.9798      2475\n",
      "   macro avg     0.9811    0.9787    0.9797      2475\n",
      "weighted avg     0.9802    0.9798    0.9798      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010555522309409248, Accuracy: 98.46464646464646%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9756    0.9953    0.9854      1284\n",
      "           1     0.9948    0.9731    0.9839      1191\n",
      "\n",
      "    accuracy                         0.9846      2475\n",
      "   macro avg     0.9852    0.9842    0.9846      2475\n",
      "weighted avg     0.9848    0.9846    0.9846      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013712903465887513, Accuracy: 96.96969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9520    0.9914    0.9713      1281\n",
      "           1     0.9904    0.9464    0.9679      1194\n",
      "\n",
      "    accuracy                         0.9697      2475\n",
      "   macro avg     0.9712    0.9689    0.9696      2475\n",
      "weighted avg     0.9705    0.9697    0.9697      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012147535579373138, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.9923    0.9752      1306\n",
      "           1     0.9911    0.9521    0.9712      1169\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9748    0.9722    0.9732      2475\n",
      "weighted avg     0.9739    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011594101636096684, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9584    0.9875    0.9728      1284\n",
      "           1     0.9861    0.9538    0.9697      1191\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9723    0.9707    0.9712      2475\n",
      "weighted avg     0.9717    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014939795238803132, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.9900    0.9739      1300\n",
      "           1     0.9885    0.9523    0.9701      1175\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9734    0.9712    0.9720      2475\n",
      "weighted avg     0.9726    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00016674524605876268, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9549    0.9936    0.9739      1257\n",
      "           1     0.9931    0.9516    0.9719      1218\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9740    0.9726    0.9729      2475\n",
      "weighted avg     0.9737    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.380703020577479e-05, Accuracy: 97.45454545454545%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9585    0.9937    0.9758      1277\n",
      "           1     0.9930    0.9541    0.9732      1198\n",
      "\n",
      "    accuracy                         0.9745      2475\n",
      "   macro avg     0.9758    0.9739    0.9745      2475\n",
      "weighted avg     0.9752    0.9745    0.9745      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.343255649913441e-05, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9675    0.9866    0.9770      1269\n",
      "           1     0.9856    0.9652    0.9753      1206\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9766    0.9759    0.9761      2475\n",
      "weighted avg     0.9763    0.9762    0.9762      2475\n",
      "\n",
      "created model_classifier_config_90.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014264214520502572, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9523    0.9930    0.9722      1287\n",
      "           1     0.9921    0.9461    0.9685      1188\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9722    0.9696    0.9704      2475\n",
      "weighted avg     0.9714    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010461281044314606, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.9904    0.9730      1256\n",
      "           1     0.9898    0.9532    0.9712      1219\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9730    0.9718    0.9721      2475\n",
      "weighted avg     0.9727    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010224554875884393, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9617    0.9947    0.9779      1313\n",
      "           1     0.9937    0.9552    0.9741      1162\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9777    0.9750    0.9760      2475\n",
      "weighted avg     0.9767    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010559349048017251, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9946    0.9795      1298\n",
      "           1     0.9938    0.9601    0.9767      1177\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9794    0.9773    0.9781      2475\n",
      "weighted avg     0.9787    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012126259731523919, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9568    0.9904    0.9733      1252\n",
      "           1     0.9898    0.9542    0.9717      1223\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9733    0.9723    0.9725      2475\n",
      "weighted avg     0.9731    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011562981388785623, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9716    0.9922    0.9818      1276\n",
      "           1     0.9915    0.9691    0.9802      1199\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9815    0.9807    0.9810      2475\n",
      "weighted avg     0.9812    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012207826580664123, Accuracy: 96.60606060606061%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9505    0.9850    0.9674      1267\n",
      "           1     0.9836    0.9462    0.9646      1208\n",
      "\n",
      "    accuracy                         0.9661      2475\n",
      "   macro avg     0.9671    0.9656    0.9660      2475\n",
      "weighted avg     0.9667    0.9661    0.9660      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011327885317079949, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9638    0.9896    0.9765      1344\n",
      "           1     0.9872    0.9558    0.9712      1131\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9755    0.9727    0.9739      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011556022697024875, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9643    0.9953    0.9796      1277\n",
      "           1     0.9948    0.9608    0.9775      1198\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9796    0.9780    0.9785      2475\n",
      "weighted avg     0.9791    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00017157974267246746, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9542    0.9938    0.9736      1300\n",
      "           1     0.9929    0.9472    0.9695      1175\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9735    0.9705    0.9716      2475\n",
      "weighted avg     0.9726    0.9717    0.9717      2475\n",
      "\n",
      "created model_classifier_config_91.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001339853803316752, Accuracy: 98.14141414141415%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9727    0.9923    0.9824      1295\n",
      "           1     0.9913    0.9695    0.9803      1180\n",
      "\n",
      "    accuracy                         0.9814      2475\n",
      "   macro avg     0.9820    0.9809    0.9814      2475\n",
      "weighted avg     0.9816    0.9814    0.9814      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012375382461933174, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9631    0.9930    0.9778      1288\n",
      "           1     0.9922    0.9587    0.9751      1187\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9776    0.9759    0.9765      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011255841965627189, Accuracy: 98.1010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9699    0.9937    0.9816      1263\n",
      "           1     0.9932    0.9678    0.9804      1212\n",
      "\n",
      "    accuracy                         0.9810      2475\n",
      "   macro avg     0.9815    0.9807    0.9810      2475\n",
      "weighted avg     0.9813    0.9810    0.9810      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001314167994441408, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.9939    0.9753      1309\n",
      "           1     0.9928    0.9503    0.9711      1166\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9751    0.9721    0.9732      2475\n",
      "weighted avg     0.9741    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012506094243791368, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9618    0.9869    0.9742      1302\n",
      "           1     0.9851    0.9565    0.9706      1173\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9735    0.9717    0.9724      2475\n",
      "weighted avg     0.9728    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012386383432330507, Accuracy: 96.8080808080808%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9465    0.9945    0.9699      1280\n",
      "           1     0.9938    0.9397    0.9660      1195\n",
      "\n",
      "    accuracy                         0.9681      2475\n",
      "   macro avg     0.9701    0.9671    0.9680      2475\n",
      "weighted avg     0.9693    0.9681    0.9680      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.342598493653115e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9746    0.9822    0.9784      1289\n",
      "           1     0.9804    0.9722    0.9763      1186\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9775    0.9772    0.9773      2475\n",
      "weighted avg     0.9774    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011394943552787858, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9673    0.9914    0.9792      1282\n",
      "           1     0.9905    0.9640    0.9771      1193\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9789    0.9777    0.9781      2475\n",
      "weighted avg     0.9785    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001114922912433894, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9521    0.9921    0.9717      1261\n",
      "           1     0.9914    0.9481    0.9693      1214\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9717    0.9701    0.9705      2475\n",
      "weighted avg     0.9713    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011057900659965747, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9908    0.9791      1301\n",
      "           1     0.9895    0.9634    0.9763      1174\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9786    0.9771    0.9777      2475\n",
      "weighted avg     0.9781    0.9778    0.9778      2475\n",
      "\n",
      "created model_classifier_config_92.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012302432698432845, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9932    0.9788      1328\n",
      "           1     0.9919    0.9582    0.9747      1147\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9784    0.9757    0.9768      2475\n",
      "weighted avg     0.9774    0.9770    0.9769      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013059167548863575, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9930    0.9779      1290\n",
      "           1     0.9921    0.9586    0.9751      1185\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9776    0.9758    0.9765      2475\n",
      "weighted avg     0.9770    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011975087902762673, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.9929    0.9750      1275\n",
      "           1     0.9922    0.9533    0.9724      1200\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9749    0.9731    0.9737      2475\n",
      "weighted avg     0.9744    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012887616350193217, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9536    0.9921    0.9725      1264\n",
      "           1     0.9914    0.9496    0.9701      1211\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9725    0.9709    0.9713      2475\n",
      "weighted avg     0.9721    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014341609947609178, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9618    0.9900    0.9757      1297\n",
      "           1     0.9886    0.9567    0.9724      1178\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9752    0.9733    0.9740      2475\n",
      "weighted avg     0.9746    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011337959104114109, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9872    0.9777      1331\n",
      "           1     0.9848    0.9624    0.9735      1144\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9766    0.9748    0.9756      2475\n",
      "weighted avg     0.9759    0.9758    0.9757      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001365923279463643, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9499    0.9961    0.9725      1276\n",
      "           1     0.9956    0.9441    0.9692      1199\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9728    0.9701    0.9708      2475\n",
      "weighted avg     0.9721    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014653962067883423, Accuracy: 96.56565656565657%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9444    0.9913    0.9673      1268\n",
      "           1     0.9904    0.9387    0.9638      1207\n",
      "\n",
      "    accuracy                         0.9657      2475\n",
      "   macro avg     0.9674    0.9650    0.9656      2475\n",
      "weighted avg     0.9668    0.9657    0.9656      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011588335639298564, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.9922    0.9800      1281\n",
      "           1     0.9914    0.9648    0.9779      1194\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9797    0.9785    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.668868599515973e-05, Accuracy: 98.02020202020202%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9937    0.9808      1260\n",
      "           1     0.9932    0.9663    0.9796      1215\n",
      "\n",
      "    accuracy                         0.9802      2475\n",
      "   macro avg     0.9808    0.9800    0.9802      2475\n",
      "weighted avg     0.9805    0.9802    0.9802      2475\n",
      "\n",
      "created model_classifier_config_93.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010684638613402242, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9922    0.9783      1274\n",
      "           1     0.9914    0.9617    0.9763      1201\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9782    0.9769    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012758953703774346, Accuracy: 97.21212121212122%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9528    0.9935    0.9728      1240\n",
      "           1     0.9932    0.9506    0.9715      1235\n",
      "\n",
      "    accuracy                         0.9721      2475\n",
      "   macro avg     0.9730    0.9721    0.9721      2475\n",
      "weighted avg     0.9730    0.9721    0.9721      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011975032512587731, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9594    0.9907    0.9748      1289\n",
      "           1     0.9895    0.9545    0.9717      1186\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9745    0.9726    0.9732      2475\n",
      "weighted avg     0.9738    0.9733    0.9733      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001450235675079654, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9652    0.9938    0.9793      1284\n",
      "           1     0.9931    0.9614    0.9770      1191\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9791    0.9776    0.9781      2475\n",
      "weighted avg     0.9786    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010754965471498894, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9702    0.9852    0.9777      1288\n",
      "           1     0.9837    0.9671    0.9754      1187\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9770    0.9762    0.9765      2475\n",
      "weighted avg     0.9767    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013121672049917356, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9536    0.9930    0.9729      1284\n",
      "           1     0.9921    0.9479    0.9695      1191\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9729    0.9705    0.9712      2475\n",
      "weighted avg     0.9721    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011381927162709862, Accuracy: 97.61616161616162%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9638    0.9924    0.9779      1315\n",
      "           1     0.9911    0.9578    0.9741      1160\n",
      "\n",
      "    accuracy                         0.9762      2475\n",
      "   macro avg     0.9774    0.9751    0.9760      2475\n",
      "weighted avg     0.9766    0.9762    0.9761      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.911294537361222e-05, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9652    0.9945    0.9796      1281\n",
      "           1     0.9939    0.9615    0.9774      1194\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9795    0.9780    0.9785      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012211710816681986, Accuracy: 97.13131313131314%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9585    0.9885    0.9733      1310\n",
      "           1     0.9867    0.9519    0.9690      1165\n",
      "\n",
      "    accuracy                         0.9713      2475\n",
      "   macro avg     0.9726    0.9702    0.9712      2475\n",
      "weighted avg     0.9718    0.9713    0.9713      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011652548806835907, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9593    0.9931    0.9759      1305\n",
      "           1     0.9920    0.9530    0.9721      1170\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9756    0.9730    0.9740      2475\n",
      "weighted avg     0.9747    0.9741    0.9741      2475\n",
      "\n",
      "created model_classifier_config_94.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001273249074666187, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.9938    0.9758      1296\n",
      "           1     0.9929    0.9525    0.9723      1179\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9756    0.9732    0.9740      2475\n",
      "weighted avg     0.9748    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012437008547060418, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9903    0.9766      1346\n",
      "           1     0.9881    0.9548    0.9712      1129\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9756    0.9726    0.9739      2475\n",
      "weighted avg     0.9745    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012989368402596677, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9501    0.9951    0.9721      1225\n",
      "           1     0.9950    0.9488    0.9713      1250\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9725    0.9720    0.9717      2475\n",
      "weighted avg     0.9728    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013061679071850246, Accuracy: 98.06060606060606%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9664    0.9969    0.9814      1270\n",
      "           1     0.9966    0.9635    0.9797      1205\n",
      "\n",
      "    accuracy                         0.9806      2475\n",
      "   macro avg     0.9815    0.9802    0.9806      2475\n",
      "weighted avg     0.9811    0.9806    0.9806      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011456674096560238, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9540    0.9908    0.9720      1298\n",
      "           1     0.9894    0.9473    0.9679      1177\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9717    0.9690    0.9700      2475\n",
      "weighted avg     0.9708    0.9701    0.9701      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011110752820968628, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9881    0.9784      1262\n",
      "           1     0.9874    0.9670    0.9771      1213\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9781    0.9776    0.9778      2475\n",
      "weighted avg     0.9780    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010876305777617175, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9829    0.9775      1283\n",
      "           1     0.9813    0.9698    0.9755      1192\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9768    0.9763    0.9765      2475\n",
      "weighted avg     0.9766    0.9766    0.9766      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010194738705952963, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.9924    0.9771      1314\n",
      "           1     0.9911    0.9561    0.9733      1161\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9767    0.9742    0.9752      2475\n",
      "weighted avg     0.9758    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012837528881400523, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9606    0.9922    0.9761      1278\n",
      "           1     0.9913    0.9566    0.9736      1197\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9760    0.9744    0.9749      2475\n",
      "weighted avg     0.9755    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011877040369342072, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9529    0.9977    0.9748      1298\n",
      "           1     0.9973    0.9456    0.9708      1177\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9751    0.9717    0.9728      2475\n",
      "weighted avg     0.9740    0.9729    0.9729      2475\n",
      "\n",
      "created model_classifier_config_95.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011553245662438749, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9594    0.9899    0.9744      1288\n",
      "           1     0.9887    0.9545    0.9713      1187\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9740    0.9722    0.9728      2475\n",
      "weighted avg     0.9734    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012361714033165362, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9644    0.9914    0.9777      1284\n",
      "           1     0.9905    0.9605    0.9753      1191\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9774    0.9760    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00016293222253972834, Accuracy: 96.28282828282828%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9409    0.9932    0.9663      1330\n",
      "           1     0.9916    0.9275    0.9585      1145\n",
      "\n",
      "    accuracy                         0.9628      2475\n",
      "   macro avg     0.9662    0.9604    0.9624      2475\n",
      "weighted avg     0.9643    0.9628    0.9627      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013519892186829538, Accuracy: 97.4949494949495%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9631    0.9909    0.9768      1317\n",
      "           1     0.9893    0.9568    0.9728      1158\n",
      "\n",
      "    accuracy                         0.9749      2475\n",
      "   macro avg     0.9762    0.9739    0.9748      2475\n",
      "weighted avg     0.9754    0.9749    0.9749      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.634693162609833e-05, Accuracy: 98.3030303030303%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9778    0.9899    0.9839      1293\n",
      "           1     0.9889    0.9755    0.9821      1182\n",
      "\n",
      "    accuracy                         0.9830      2475\n",
      "   macro avg     0.9833    0.9827    0.9830      2475\n",
      "weighted avg     0.9831    0.9830    0.9830      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012544537132436578, Accuracy: 97.41414141414141%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.9945    0.9755      1280\n",
      "           1     0.9939    0.9523    0.9726      1195\n",
      "\n",
      "    accuracy                         0.9741      2475\n",
      "   macro avg     0.9755    0.9734    0.9741      2475\n",
      "weighted avg     0.9749    0.9741    0.9741      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.594070790994047e-05, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9638    0.9936    0.9785      1258\n",
      "           1     0.9932    0.9614    0.9770      1217\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9785    0.9775    0.9778      2475\n",
      "weighted avg     0.9782    0.9778    0.9778      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.342910364420727e-05, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9669    0.9907    0.9787      1297\n",
      "           1     0.9895    0.9626    0.9759      1178\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9782    0.9767    0.9773      2475\n",
      "weighted avg     0.9777    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011981816002816865, Accuracy: 97.29292929292929%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9899    0.9743      1282\n",
      "           1     0.9887    0.9547    0.9714      1193\n",
      "\n",
      "    accuracy                         0.9729      2475\n",
      "   macro avg     0.9739    0.9723    0.9729      2475\n",
      "weighted avg     0.9734    0.9729    0.9729      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001306106827475808, Accuracy: 96.8080808080808%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9469    0.9919    0.9689      1241\n",
      "           1     0.9915    0.9441    0.9672      1234\n",
      "\n",
      "    accuracy                         0.9681      2475\n",
      "   macro avg     0.9692    0.9680    0.9681      2475\n",
      "weighted avg     0.9691    0.9681    0.9681      2475\n",
      "\n",
      "created model_classifier_config_96.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010821510746021463, Accuracy: 97.57575757575758%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9880    0.9763      1252\n",
      "           1     0.9874    0.9632    0.9752      1223\n",
      "\n",
      "    accuracy                         0.9758      2475\n",
      "   macro avg     0.9762    0.9756    0.9757      2475\n",
      "weighted avg     0.9760    0.9758    0.9758      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010759254597654247, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9645    0.9930    0.9786      1287\n",
      "           1     0.9922    0.9604    0.9760      1188\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9784    0.9767    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012947494333440606, Accuracy: 97.01010101010101%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9518    0.9939    0.9724      1312\n",
      "           1     0.9928    0.9433    0.9674      1163\n",
      "\n",
      "    accuracy                         0.9701      2475\n",
      "   macro avg     0.9723    0.9686    0.9699      2475\n",
      "weighted avg     0.9711    0.9701    0.9700      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012189023723505964, Accuracy: 97.77777777777777%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9939    0.9794      1318\n",
      "           1     0.9928    0.9594    0.9758      1157\n",
      "\n",
      "    accuracy                         0.9778      2475\n",
      "   macro avg     0.9791    0.9767    0.9776      2475\n",
      "weighted avg     0.9782    0.9778    0.9777      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011575123276373352, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9520    0.9944    0.9728      1257\n",
      "           1     0.9940    0.9483    0.9706      1218\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9730    0.9714    0.9717      2475\n",
      "weighted avg     0.9727    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014051727875314578, Accuracy: 97.8989898989899%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9681    0.9922    0.9800      1286\n",
      "           1     0.9914    0.9647    0.9778      1189\n",
      "\n",
      "    accuracy                         0.9790      2475\n",
      "   macro avg     0.9797    0.9785    0.9789      2475\n",
      "weighted avg     0.9793    0.9790    0.9790      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.817194758039533e-05, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9891    0.9739      1285\n",
      "           1     0.9878    0.9546    0.9709      1190\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9735    0.9719    0.9724      2475\n",
      "weighted avg     0.9730    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001265437885968372, Accuracy: 97.0909090909091%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9561    0.9900    0.9728      1299\n",
      "           1     0.9885    0.9498    0.9688      1176\n",
      "\n",
      "    accuracy                         0.9709      2475\n",
      "   macro avg     0.9723    0.9699    0.9708      2475\n",
      "weighted avg     0.9715    0.9709    0.9709      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012422855454261858, Accuracy: 97.05050505050505%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    0.9930    0.9723      1290\n",
      "           1     0.9920    0.9460    0.9685      1185\n",
      "\n",
      "    accuracy                         0.9705      2475\n",
      "   macro avg     0.9722    0.9695    0.9704      2475\n",
      "weighted avg     0.9714    0.9705    0.9705      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012351552645365396, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9587    0.9953    0.9767      1284\n",
      "           1     0.9947    0.9538    0.9739      1191\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9767    0.9746    0.9753      2475\n",
      "weighted avg     0.9761    0.9754    0.9753      2475\n",
      "\n",
      "created model_classifier_config_97.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001077134290126839, Accuracy: 97.53535353535354%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9594    0.9945    0.9766      1282\n",
      "           1     0.9939    0.9547    0.9739      1193\n",
      "\n",
      "    accuracy                         0.9754      2475\n",
      "   macro avg     0.9766    0.9746    0.9753      2475\n",
      "weighted avg     0.9760    0.9754    0.9753      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013804385156342478, Accuracy: 96.72727272727273%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9517    0.9877    0.9693      1296\n",
      "           1     0.9858    0.9449    0.9649      1179\n",
      "\n",
      "    accuracy                         0.9673      2475\n",
      "   macro avg     0.9688    0.9663    0.9671      2475\n",
      "weighted avg     0.9679    0.9673    0.9672      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010670156490923179, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9915    0.9795      1298\n",
      "           1     0.9904    0.9635    0.9767      1177\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9790    0.9775    0.9781      2475\n",
      "weighted avg     0.9785    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 9.186595377295908e-05, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9709    0.9886    0.9796      1314\n",
      "           1     0.9868    0.9664    0.9765      1161\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9788    0.9775    0.9781      2475\n",
      "weighted avg     0.9783    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00010968035218691585, Accuracy: 97.85858585858585%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9945    0.9795      1272\n",
      "           1     0.9940    0.9618    0.9776      1203\n",
      "\n",
      "    accuracy                         0.9786      2475\n",
      "   macro avg     0.9794    0.9781    0.9785      2475\n",
      "weighted avg     0.9790    0.9786    0.9786      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001303757591681047, Accuracy: 97.37373737373737%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.9852    0.9749      1282\n",
      "           1     0.9837    0.9614    0.9724      1193\n",
      "\n",
      "    accuracy                         0.9737      2475\n",
      "   macro avg     0.9743    0.9733    0.9737      2475\n",
      "weighted avg     0.9739    0.9737    0.9737      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001348772103136236, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9604    0.9992    0.9795      1288\n",
      "           1     0.9991    0.9553    0.9767      1187\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9798    0.9773    0.9781      2475\n",
      "weighted avg     0.9790    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011401393798866658, Accuracy: 97.93939393939394%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9743    0.9858    0.9800      1268\n",
      "           1     0.9849    0.9727    0.9787      1207\n",
      "\n",
      "    accuracy                         0.9794      2475\n",
      "   macro avg     0.9796    0.9792    0.9794      2475\n",
      "weighted avg     0.9795    0.9794    0.9794      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011408888631396823, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9595    0.9976    0.9782      1259\n",
      "           1     0.9974    0.9564    0.9765      1216\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9785    0.9770    0.9773      2475\n",
      "weighted avg     0.9781    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001337567302915785, Accuracy: 96.92929292929293%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9550    0.9886    0.9715      1311\n",
      "           1     0.9866    0.9476    0.9667      1164\n",
      "\n",
      "    accuracy                         0.9693      2475\n",
      "   macro avg     0.9708    0.9681    0.9691      2475\n",
      "weighted avg     0.9699    0.9693    0.9692      2475\n",
      "\n",
      "created model_classifier_config_98.\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.000101112551761396, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9638    0.9929    0.9781      1260\n",
      "           1     0.9924    0.9613    0.9766      1215\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9781    0.9771    0.9773      2475\n",
      "weighted avg     0.9778    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001189448225377786, Accuracy: 97.6969696969697%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.9915    0.9783      1293\n",
      "           1     0.9904    0.9611    0.9755      1182\n",
      "\n",
      "    accuracy                         0.9770      2475\n",
      "   macro avg     0.9779    0.9763    0.9769      2475\n",
      "weighted avg     0.9773    0.9770    0.9770      2475\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013389920646494086, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9552    0.9946    0.9745      1308\n",
      "           1     0.9937    0.9477    0.9702      1167\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9745    0.9712    0.9724      2475\n",
      "weighted avg     0.9734    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00014468720464995413, Accuracy: 97.25252525252525%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9579    0.9916    0.9745      1309\n",
      "           1     0.9902    0.9511    0.9703      1166\n",
      "\n",
      "    accuracy                         0.9725      2475\n",
      "   macro avg     0.9741    0.9714    0.9724      2475\n",
      "weighted avg     0.9731    0.9725    0.9725      2475\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012196237992758703, Accuracy: 97.73737373737374%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9676    0.9890    0.9782      1269\n",
      "           1     0.9881    0.9652    0.9765      1206\n",
      "\n",
      "    accuracy                         0.9774      2475\n",
      "   macro avg     0.9779    0.9771    0.9773      2475\n",
      "weighted avg     0.9776    0.9774    0.9774      2475\n",
      "\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00012690768097386215, Accuracy: 97.65656565656566%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.9915    0.9780      1299\n",
      "           1     0.9904    0.9600    0.9750      1176\n",
      "\n",
      "    accuracy                         0.9766      2475\n",
      "   macro avg     0.9776    0.9758    0.9765      2475\n",
      "weighted avg     0.9769    0.9766    0.9765      2475\n",
      "\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011142504034620343, Accuracy: 97.81818181818181%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9686    0.9888    0.9786      1248\n",
      "           1     0.9883    0.9674    0.9778      1227\n",
      "\n",
      "    accuracy                         0.9782      2475\n",
      "   macro avg     0.9785    0.9781    0.9782      2475\n",
      "weighted avg     0.9784    0.9782    0.9782      2475\n",
      "\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00013268368713783494, Accuracy: 96.76767676767676%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9496    0.9916    0.9701      1310\n",
      "           1     0.9901    0.9408    0.9648      1165\n",
      "\n",
      "    accuracy                         0.9677      2475\n",
      "   macro avg     0.9698    0.9662    0.9675      2475\n",
      "weighted avg     0.9686    0.9677    0.9676      2475\n",
      "\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.00011974421414462003, Accuracy: 97.17171717171718%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9929    0.9728      1261\n",
      "           1     0.9923    0.9498    0.9705      1214\n",
      "\n",
      "    accuracy                         0.9717      2475\n",
      "   macro avg     0.9729    0.9713    0.9717      2475\n",
      "weighted avg     0.9725    0.9717    0.9717      2475\n",
      "\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch: 5, Validation loss: 0.0001234485705693563, Accuracy: 97.33333333333333%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9548    0.9970    0.9754      1313\n",
      "           1     0.9964    0.9466    0.9709      1162\n",
      "\n",
      "    accuracy                         0.9733      2475\n",
      "   macro avg     0.9756    0.9718    0.9731      2475\n",
      "weighted avg     0.9743    0.9733    0.9733      2475\n",
      "\n",
      "created model_classifier_config_99.\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"mps is available.\")\n",
    "\n",
    "# hyper parameter\n",
    "LEARNING_RATE = 0.00001\n",
    "target_size = 2\n",
    "grad_clip = 0.1\n",
    "norm_type = 2\n",
    "epochs = 5\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "niter = 100\n",
    "\n",
    "# y1s_mean, y2s_mean = np.empty(nconf), np.empty(nconf)\n",
    "for iter in range(niter):\n",
    "    for fold, (train_data, valid_data) in enumerate(kfold.split(dataset)):\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "        train_subsampler = SubsetRandomSampler(train_data)\n",
    "        valid_subsampler = SubsetRandomSampler(valid_data)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            dataset, batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "        valid_loader = DataLoader(\n",
    "            dataset, batch_size=BATCH_SIZE, sampler=valid_subsampler)\n",
    "\n",
    "        model = CNNClassifier(target_size).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        train_loss_list, vaild_loss_list, accuracy_list = [], [], []\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for data, _, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target.type(torch.long))\n",
    "                train_loss += loss.item()\n",
    "                loss.backward()\n",
    "                del loss\n",
    "                nn.utils.clip_grad_norm_(\n",
    "                    parameters=model.parameters(), max_norm=grad_clip, norm_type=norm_type)\n",
    "                optimizer.step()\n",
    "            # train_loss_list.append(train_loss)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss = 0\n",
    "                correct = 0\n",
    "                answer, prediction = [], []\n",
    "                for data, _, target in valid_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    valid_loss += criterion(output, target.type(torch.long)).item()\n",
    "                    pred = output.argmax(dim=1, keepdim=True)\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                    prediction += list(pred.cpu().numpy())\n",
    "                    answer += list(target.cpu().numpy())\n",
    "\n",
    "            valid_loss /= len(valid_loader.sampler.indices)\n",
    "            accuracy = 100 * correct / len(valid_loader.sampler.indices)\n",
    "\n",
    "            vaild_loss_list.append(valid_loss)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if epoch == epochs - 1:\n",
    "                print(f'Epoch: {epoch+1}, Validation loss: {valid_loss}, Accuracy: {accuracy}%')\n",
    "                print(\"Classification Report:\\n\", classification_report(answer, prediction, digits=4))\n",
    "    torch.save(model, f\"../models/2d_Ising_spin_list/2d_Ising_model_classifier_{iter}.pth\")\n",
    "    print(f\"created model_classifier_config_{iter}.\")\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1s_mean, y2s_mean = np.empty(nconf), np.empty(nconf)\n",
    "niter = 10\n",
    "for iter in range(niter):\n",
    "    model = torch.load(f\"../models/2d_Ising_config/2d_Ising_model_classifier_{iter}.pth\")\n",
    "    # model = torch.load(f\"../models/2d_Ising_spin_list/2d_Ising_model_classifier_{iter}.pth\")\n",
    "    model.eval()\n",
    "    answer_test, prediction_test, temps = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for data, temp, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=False)\n",
    "            prediction_test += list(pred.cpu().numpy())\n",
    "            answer_test += list(target.cpu().numpy())\n",
    "            temps += list(temp.cpu().numpy())\n",
    "    xs, y1s, y2s = inference(len(test_dataset), temps, prediction_test, target_size)\n",
    "    y1s_mean += y1s\n",
    "    y2s_mean += y2s\n",
    "y1s_mean /= niter\n",
    "y2s_mean /= niter\n",
    "plt.axvline(x=T_cr, ymin=0, ymax=1, ls=\"dashed\", color=\"gray\", label=r\"$T_c={}$\".format(T_cr))\n",
    "plt.xlim(t_start,t_end)\n",
    "plt.ylim(-0.03,1.03)\n",
    "plt.plot(xs, y1s_mean, label=r\"強磁性相\", color=\"red\")\n",
    "plt.plot(xs, y2s_mean, label=r\"常磁性相\", color=\"blue\")\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$T$\")\n",
    "plt.ylabel(r\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0004e466adf40374ab7179c2dbfe52366f7166937f5d122ace80e46d2b93611d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
